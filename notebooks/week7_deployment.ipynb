{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WEEK 7: MODEL DEPLOYMENT WITH FASTAPI\n",
      "============================================================\n",
      "Project Root: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\n",
      "Timestamp: 2025-12-04 02:46:30\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Imports and Setup\n",
    "# =============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import subprocess\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import joblib\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Display header\n",
    "print(\"=\" * 60)\n",
    "print(\"WEEK 7: MODEL DEPLOYMENT WITH FASTAPI\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ Checking Dependencies...\n",
      "----------------------------------------\n",
      "  âœ… FastAPI: 0.119.0\n",
      "  âœ… Uvicorn: 0.37.0\n",
      "  âœ… Pydantic: 2.12.2\n",
      "  âœ… HTTPX: 0.28.1\n",
      "  âœ… Requests: 2.32.5\n",
      "  âœ… Joblib: 1.5.2\n",
      "  âœ… Scikit-learn: 1.7.2\n",
      "\n",
      "âœ… All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Check Dependencies\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nğŸ“¦ Checking Dependencies...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "dependencies = {\n",
    "    'fastapi': 'FastAPI',\n",
    "    'uvicorn': 'Uvicorn',\n",
    "    'pydantic': 'Pydantic',\n",
    "    'httpx': 'HTTPX',\n",
    "    'requests': 'Requests',\n",
    "    'joblib': 'Joblib',\n",
    "    'sklearn': 'Scikit-learn',\n",
    "}\n",
    "\n",
    "missing_deps = []\n",
    "\n",
    "for module, name in dependencies.items():\n",
    "    try:\n",
    "        imported = __import__(module)\n",
    "        version = getattr(imported, '__version__', 'installed')\n",
    "        print(f\"  âœ… {name}: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"  âŒ {name}: NOT INSTALLED\")\n",
    "        missing_deps.append(module)\n",
    "\n",
    "if missing_deps:\n",
    "    print(f\"\\nâš ï¸  Missing: {', '.join(missing_deps)}\")\n",
    "    print(f\"   Run: pip install {' '.join(missing_deps)}\")\n",
    "else:\n",
    "    print(\"\\nâœ… All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e1a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Model Directories:\n",
      "   Tuned: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\models\\tuned\n",
      "   Baseline: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\models\\baseline\n",
      "   Production: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\models\\production\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: Define Model Paths\n",
    "# =============================================================================\n",
    "\n",
    "# Define directory paths\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "TUNED_MODELS_DIR = MODELS_DIR / \"tuned\"\n",
    "BASELINE_MODELS_DIR = MODELS_DIR / \"baseline\"\n",
    "PRODUCTION_DIR = MODELS_DIR / \"production\"\n",
    "\n",
    "# Create production directory if it doesn't exist\n",
    "PRODUCTION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“ Model Directories:\")\n",
    "print(f\"   Tuned: {TUNED_MODELS_DIR}\")\n",
    "print(f\"   Baseline: {BASELINE_MODELS_DIR}\")\n",
    "print(f\"   Production: {PRODUCTION_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6764763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Available Models:\n",
      "----------------------------------------\n",
      "\n",
      "Tuned models (1):\n",
      "   â€¢ random_forest_tuned.joblib (162101.9 KB)\n",
      "\n",
      "Baseline models (6):\n",
      "   â€¢ decision_tree.joblib (6.2 KB)\n",
      "   â€¢ gradient_boosting.joblib (426.7 KB)\n",
      "   â€¢ logistic_regression.joblib (1.2 KB)\n",
      "   â€¢ random_forest.joblib (8836.6 KB)\n",
      "   â€¢ xgboost.joblib (253.6 KB)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: Find Available Models\n",
    "# =============================================================================\n",
    "\n",
    "def find_models(directory: Path, pattern: str = \"*.joblib\") -> List[Path]:\n",
    "    \"\"\"Find all model files in a directory.\"\"\"\n",
    "    if directory.exists():\n",
    "        return list(directory.glob(pattern))\n",
    "    return []\n",
    "\n",
    "# Find models\n",
    "tuned_models = find_models(TUNED_MODELS_DIR, \"*_tuned.joblib\")\n",
    "baseline_models = find_models(BASELINE_MODELS_DIR, \"*.joblib\")\n",
    "\n",
    "print(\"\\nğŸ” Available Models:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"\\nTuned models ({len(tuned_models)}):\")\n",
    "for m in tuned_models:\n",
    "    size_kb = m.stat().st_size / 1024\n",
    "    print(f\"   â€¢ {m.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nBaseline models ({len(baseline_models)}):\")\n",
    "for m in baseline_models:\n",
    "    if 'preprocessor' not in m.name.lower():\n",
    "        size_kb = m.stat().st_size / 1024\n",
    "        print(f\"   â€¢ {m.name} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Selected Model: random_forest\n",
      "   Path: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\models\\tuned\\random_forest_tuned.joblib\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: Select Best Model for Production\n",
    "# =============================================================================\n",
    "\n",
    "# Model priority order\n",
    "MODEL_PRIORITY = ['xgboost', 'random_forest', 'gradient_boosting', 'logistic_regression']\n",
    "\n",
    "selected_model_path = None\n",
    "selected_model_name = None\n",
    "\n",
    "# Check tuned models first\n",
    "for model_name in MODEL_PRIORITY:\n",
    "    for model_path in tuned_models:\n",
    "        if model_name in model_path.name.lower():\n",
    "            selected_model_path = model_path\n",
    "            selected_model_name = model_name\n",
    "            break\n",
    "    if selected_model_path:\n",
    "        break\n",
    "\n",
    "# Fall back to baseline models\n",
    "if not selected_model_path:\n",
    "    for model_name in MODEL_PRIORITY:\n",
    "        for model_path in baseline_models:\n",
    "            if model_name in model_path.name.lower() and 'preprocessor' not in model_path.name.lower():\n",
    "                selected_model_path = model_path\n",
    "                selected_model_name = model_name\n",
    "                break\n",
    "        if selected_model_path:\n",
    "            break\n",
    "\n",
    "# Display result\n",
    "if selected_model_path:\n",
    "    print(f\"\\nâœ… Selected Model: {selected_model_name}\")\n",
    "    print(f\"   Path: {selected_model_path}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No trained model found - will create demo model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca331972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ Loading model from: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\models\\tuned\\random_forest_tuned.joblib\n",
      "   Type: Pipeline\n",
      "   âœ… Copied to: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\models\\production\\model.joblib\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: Prepare Production Model\n",
    "# =============================================================================\n",
    "\n",
    "model = None\n",
    "\n",
    "if selected_model_path and selected_model_path.exists():\n",
    "    # Load existing model\n",
    "    print(f\"\\nğŸ“¦ Loading model from: {selected_model_path}\")\n",
    "    model = joblib.load(selected_model_path)\n",
    "    print(f\"   Type: {type(model).__name__}\")\n",
    "    \n",
    "    # Copy to production directory\n",
    "    production_model_path = PRODUCTION_DIR / \"model.joblib\"\n",
    "    shutil.copy(selected_model_path, production_model_path)\n",
    "    print(f\"   âœ… Copied to: {production_model_path}\")\n",
    "    \n",
    "else:\n",
    "    # Create demo model\n",
    "    print(\"\\nğŸ“¦ Creating demonstration model...\")\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    X_dummy = np.random.rand(1000, 15)\n",
    "    y_dummy = np.random.randint(0, 2, 1000)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_dummy, y_dummy)\n",
    "    \n",
    "    selected_model_name = \"random_forest_demo\"\n",
    "    \n",
    "    # Save demo model\n",
    "    production_model_path = PRODUCTION_DIR / \"model.joblib\"\n",
    "    joblib.dump(model, production_model_path)\n",
    "    print(f\"   âœ… Demo model saved to: {production_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e536114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessor copied from: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\models\\baseline\\preprocessor.joblib\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: Copy Preprocessor\n",
    "# =============================================================================\n",
    "\n",
    "preprocessor_sources = [\n",
    "    TUNED_MODELS_DIR / \"preprocessor.joblib\",\n",
    "    BASELINE_MODELS_DIR / \"preprocessor.joblib\",\n",
    "]\n",
    "\n",
    "preprocessor_copied = False\n",
    "\n",
    "for preprocessor_path in preprocessor_sources:\n",
    "    if preprocessor_path.exists():\n",
    "        production_preprocessor_path = PRODUCTION_DIR / \"preprocessor.joblib\"\n",
    "        shutil.copy(preprocessor_path, production_preprocessor_path)\n",
    "        print(f\"âœ… Preprocessor copied from: {preprocessor_path}\")\n",
    "        preprocessor_copied = True\n",
    "        break\n",
    "\n",
    "if not preprocessor_copied:\n",
    "    print(\"âš ï¸ No preprocessor found - API will use simplified processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca8736c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Metadata saved to: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\models\\production\\model_metadata.json\n",
      "\n",
      "ğŸ“‹ Model Metadata:\n",
      "{\n",
      "  \"model_name\": \"random_forest\",\n",
      "  \"model_version\": \"1.0.0\",\n",
      "  \"model_type\": \"Pipeline\",\n",
      "  \"created_at\": \"2025-12-04T02:46:32.483748\",\n",
      "  \"created_by\": \"Week 7 Deployment Notebook\",\n",
      "  \"source_path\": \"c:\\\\Users\\\\samue\\\\Desktop\\\\NSP\\\\healthcare-appointments\\\\models\\\\tuned\\\\random_forest_tuned.joblib\",\n",
      "  \"description\": \"Production model for healthcare no-show prediction\",\n",
      "  \"input_features\": {\n",
      "    \"required\": [\n",
      "      \"age\",\n",
      "      \"gender\",\n",
      "      \"lead_days\"\n",
      "    ],\n",
      "    \"optional\": [\n",
      "      \"scholarship\",\n",
      "      \"hypertension\",\n",
      "      \"diabetes\",\n",
      "      \"alcoholism\",\n",
      "      \"handicap\",\n",
      "      \"sms_received\",\n",
      "      \"neighbourhood\",\n",
      "      \"appointment_weekday\"\n",
      "    ]\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"prediction\": \"Binary (0=show, 1=no-show)\",\n",
      "    \"probability\": \"Float (0-1)\",\n",
      "    \"risk_tier\": \"MINIMAL/LOW/MEDIUM/HIGH/CRITICAL\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: Create Model Metadata\n",
    "# =============================================================================\n",
    "\n",
    "model_metadata = {\n",
    "    \"model_name\": selected_model_name,\n",
    "    \"model_version\": \"1.0.0\",\n",
    "    \"model_type\": type(model).__name__ if model else \"Unknown\",\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "    \"created_by\": \"Week 7 Deployment Notebook\",\n",
    "    \"source_path\": str(selected_model_path) if selected_model_path else \"generated\",\n",
    "    \"description\": \"Production model for healthcare no-show prediction\",\n",
    "    \"input_features\": {\n",
    "        \"required\": [\"age\", \"gender\", \"lead_days\"],\n",
    "        \"optional\": [\n",
    "            \"scholarship\", \"hypertension\", \"diabetes\",\n",
    "            \"alcoholism\", \"handicap\", \"sms_received\",\n",
    "            \"neighbourhood\", \"appointment_weekday\"\n",
    "        ]\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"prediction\": \"Binary (0=show, 1=no-show)\",\n",
    "        \"probability\": \"Float (0-1)\",\n",
    "        \"risk_tier\": \"MINIMAL/LOW/MEDIUM/HIGH/CRITICAL\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add model-specific attributes\n",
    "if model and hasattr(model, 'n_estimators'):\n",
    "    model_metadata['n_estimators'] = model.n_estimators\n",
    "if model and hasattr(model, 'max_depth'):\n",
    "    model_metadata['max_depth'] = model.max_depth\n",
    "if model and hasattr(model, 'feature_importances_'):\n",
    "    model_metadata['n_features'] = len(model.feature_importances_)\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = PRODUCTION_DIR / \"model_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Metadata saved to: {metadata_path}\")\n",
    "print(\"\\nğŸ“‹ Model Metadata:\")\n",
    "print(json.dumps(model_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PRODUCTION DIRECTORY CONTENTS\n",
      "============================================================\n",
      "   feature_importance.json: 2.2 KB\n",
      "   model.joblib: 162101.9 KB\n",
      "   model_metadata.json: 0.8 KB\n",
      "   preprocessor.joblib: 13.0 KB\n",
      "   shap_explainer.joblib: 0.0 KB\n",
      "\n",
      "   Total size: 162118.0 KB\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: Verify Production Directory\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRODUCTION DIRECTORY CONTENTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_size = 0\n",
    "for f in sorted(PRODUCTION_DIR.iterdir()):\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    total_size += size_kb\n",
    "    print(f\"   {f.name}: {size_kb:.1f} KB\")\n",
    "\n",
    "print(f\"\\n   Total size: {total_size:.1f} KB\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9c7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "API SERVER CONFIGURATION\n",
      "============================================================\n",
      "   Host: 127.0.0.1\n",
      "   Port: 8000\n",
      "   Base URL: http://127.0.0.1:8000\n",
      "   Docs URL: http://127.0.0.1:8000/docs\n",
      "   Health URL: http://127.0.0.1:8000/health\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: API Configuration\n",
    "# =============================================================================\n",
    "\n",
    "# API Settings\n",
    "API_HOST = \"127.0.0.1\"\n",
    "API_PORT = 8000\n",
    "API_URL = f\"http://{API_HOST}:{API_PORT}\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"API SERVER CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   Host: {API_HOST}\")\n",
    "print(f\"   Port: {API_PORT}\")\n",
    "print(f\"   Base URL: {API_URL}\")\n",
    "print(f\"   Docs URL: {API_URL}/docs\")\n",
    "print(f\"   Health URL: {API_URL}/health\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c003736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: API Status Check Functions\n",
    "# =============================================================================\n",
    "\n",
    "def check_api_status(url: str = API_URL, timeout: int = 2) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Check if the API is running and return status information.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Base URL of the API\n",
    "    timeout : int\n",
    "        Request timeout in seconds\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Status information including running, healthy, and data/error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{url}/health\", timeout=timeout)\n",
    "        if response.status_code == 200:\n",
    "            return {\n",
    "                \"running\": True,\n",
    "                \"healthy\": True,\n",
    "                \"data\": response.json()\n",
    "            }\n",
    "        return {\n",
    "            \"running\": True,\n",
    "            \"healthy\": False,\n",
    "            \"status_code\": response.status_code\n",
    "        }\n",
    "    except requests.ConnectionError:\n",
    "        return {\"running\": False, \"healthy\": False, \"error\": \"Connection refused\"}\n",
    "    except requests.Timeout:\n",
    "        return {\"running\": False, \"healthy\": False, \"error\": \"Timeout\"}\n",
    "    except Exception as e:\n",
    "        return {\"running\": False, \"healthy\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def wait_for_api(url: str = API_URL, max_wait: int = 30) -> bool:\n",
    "    \"\"\"\n",
    "    Wait for API to become available.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Base URL of the API\n",
    "    max_wait : int\n",
    "        Maximum seconds to wait\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if API is ready, False otherwise\n",
    "    \"\"\"\n",
    "    print(f\"Waiting for API at {url}...\")\n",
    "    for i in range(max_wait):\n",
    "        status = check_api_status(url)\n",
    "        if status[\"running\"] and status[\"healthy\"]:\n",
    "            print(f\"âœ… API ready after {i} seconds\")\n",
    "            return True\n",
    "        time.sleep(1)\n",
    "        if i > 0 and i % 5 == 0:\n",
    "            print(f\"   Still waiting... ({i}s)\")\n",
    "    print(f\"âŒ API not ready after {max_wait} seconds\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be0c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¡ Current API Status:\n",
      "----------------------------------------\n",
      "   âœ… API is running\n",
      "   âœ… Health check passed\n",
      "   Model loaded: unknown\n",
      "   Version: unknown\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: Check Current API Status\n",
    "# =============================================================================\n",
    "\n",
    "status = check_api_status()\n",
    "\n",
    "print(\"\\nğŸ“¡ Current API Status:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if status[\"running\"]:\n",
    "    print(\"   âœ… API is running\")\n",
    "    if status[\"healthy\"]:\n",
    "        print(\"   âœ… Health check passed\")\n",
    "        if \"data\" in status:\n",
    "            data = status[\"data\"]\n",
    "            print(f\"   Model loaded: {data.get('model_loaded', 'unknown')}\")\n",
    "            print(f\"   Version: {data.get('version', 'unknown')}\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ Health check failed (status: {status.get('status_code', 'unknown')})\")\n",
    "else:\n",
    "    print(\"   âŒ API is NOT running\")\n",
    "    print(f\"   Error: {status.get('error', 'unknown')}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âš ï¸  PLEASE START THE API SERVER\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\"\"\n",
    "Open a new terminal and run:\n",
    "\n",
    "    cd {PROJECT_ROOT}\n",
    "    python serve_model.py --reload\n",
    "\n",
    "Then continue with the next cells.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd5495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test helper decorator defined\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: Test Helper Decorator\n",
    "# =============================================================================\n",
    "\n",
    "def api_test(test_name: str):\n",
    "    \"\"\"\n",
    "    Decorator to wrap API tests with consistent formatting and error handling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_name : str\n",
    "        Name of the test for display\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(f\"TEST: {test_name}\")\n",
    "            print('=' * 60)\n",
    "            \n",
    "            if not check_api_status()[\"running\"]:\n",
    "                print(\"âš ï¸ API not running - skipping test\")\n",
    "                print(\"   Start server with: python serve_model.py\")\n",
    "                return None\n",
    "            \n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                print(\"âŒ Connection error - API may have stopped\")\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Test failed: {type(e).__name__}: {e}\")\n",
    "                return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "print(\"âœ… Test helper decorator defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c5281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Health Check Endpoint\n",
      "============================================================\n",
      "Status Code: 200\n",
      "\n",
      "ğŸ“Š Health Status:\n",
      "   Status: healthy\n",
      "   Model Loaded: unknown\n",
      "   Version: unknown\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 14: Test Health Endpoint\n",
    "# =============================================================================\n",
    "\n",
    "@api_test(\"Health Check Endpoint\")\n",
    "def test_health_endpoint():\n",
    "    \"\"\"Test the /health endpoint.\"\"\"\n",
    "    \n",
    "    response = requests.get(f\"{API_URL}/health\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Health Status:\")\n",
    "        print(f\"   Status: {data.get('status', 'unknown')}\")\n",
    "        print(f\"   Model Loaded: {data.get('model_loaded', 'unknown')}\")\n",
    "        print(f\"   Version: {data.get('version', 'unknown')}\")\n",
    "        \n",
    "        if data.get('model_info'):\n",
    "            print(f\"\\nğŸ“¦ Model Info:\")\n",
    "            model_info = data['model_info']\n",
    "            print(f\"   Name: {model_info.get('name', 'unknown')}\")\n",
    "            print(f\"   Type: {model_info.get('type', 'unknown')}\")\n",
    "            print(f\"   Features: {model_info.get('features', 'unknown')}\")\n",
    "        \n",
    "        return data\n",
    "    else:\n",
    "        print(f\"âŒ Unexpected response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "health_result = test_health_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Readiness and Liveness Probes\n",
      "============================================================\n",
      "1. Readiness Probe (/ready):\n",
      "   Status Code: 200\n",
      "   Ready: True\n",
      "   Timestamp: 2025-12-04T02:46:32.786937\n",
      "\n",
      "2. Liveness Probe (/live):\n",
      "   Status Code: 200\n",
      "   Alive: True\n",
      "   Timestamp: 2025-12-04T02:46:32.789468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 15: Test Kubernetes-Style Probes\n",
    "# =============================================================================\n",
    "\n",
    "@api_test(\"Readiness and Liveness Probes\")\n",
    "def test_probes():\n",
    "    \"\"\"Test /ready and /live endpoints for Kubernetes compatibility.\"\"\"\n",
    "    \n",
    "    # Readiness probe\n",
    "    print(\"1. Readiness Probe (/ready):\")\n",
    "    response = requests.get(f\"{API_URL}/ready\")\n",
    "    print(f\"   Status Code: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"   Ready: {data.get('ready', 'unknown')}\")\n",
    "        print(f\"   Timestamp: {data.get('timestamp', 'unknown')}\")\n",
    "    \n",
    "    # Liveness probe\n",
    "    print(\"\\n2. Liveness Probe (/live):\")\n",
    "    response = requests.get(f\"{API_URL}/live\")\n",
    "    print(f\"   Status Code: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"   Alive: {data.get('alive', 'unknown')}\")\n",
    "        print(f\"   Timestamp: {data.get('timestamp', 'unknown')}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "test_probes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1439b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Single Prediction\n",
      "============================================================\n",
      "ğŸ“ Request Body:\n",
      "{\n",
      "  \"age\": 35,\n",
      "  \"gender\": \"F\",\n",
      "  \"scholarship\": 0,\n",
      "  \"hypertension\": 0,\n",
      "  \"diabetes\": 0,\n",
      "  \"alcoholism\": 0,\n",
      "  \"handicap\": 0,\n",
      "  \"sms_received\": 1,\n",
      "  \"lead_days\": 7\n",
      "}\n",
      "\n",
      "ğŸ“¬ Response Status: 200\n",
      "\n",
      "ğŸ“Š Prediction Result:\n",
      "   Prediction: Will Attend\n",
      "   Probability: 27.7%\n",
      "\n",
      "ğŸ¯ Risk Assessment:\n",
      "   Tier: LOW ğŸŸ¢\n",
      "   Confidence: Moderate\n",
      "   Color: #2ecc71\n",
      "\n",
      "ğŸ’¡ Recommended Intervention:\n",
      "   Action: Standard SMS reminder\n",
      "   SMS Reminders: 1\n",
      "   Phone Call: False\n",
      "   Priority: normal\n",
      "\n",
      "ğŸ“‹ Metadata:\n",
      "   Model Version: 2.1.0\n",
      "   Prediction ID: c64bfc50\n",
      "   Timestamp: 2025-12-04T02:46:32.823314\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 16: Test Single Prediction Endpoint\n",
    "# =============================================================================\n",
    "\n",
    "@api_test(\"Single Prediction\")\n",
    "def test_single_prediction():\n",
    "    \"\"\"Test POST /api/v1/predict with a sample appointment.\"\"\"\n",
    "    \n",
    "    # Sample appointment data\n",
    "    appointment = {\n",
    "        \"age\": 35,\n",
    "        \"gender\": \"F\",\n",
    "        \"scholarship\": 0,\n",
    "        \"hypertension\": 0,\n",
    "        \"diabetes\": 0,\n",
    "        \"alcoholism\": 0,\n",
    "        \"handicap\": 0,\n",
    "        \"sms_received\": 1,\n",
    "        \"lead_days\": 7\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ“ Request Body:\")\n",
    "    print(json.dumps(appointment, indent=2))\n",
    "    \n",
    "    # Make request\n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/api/v1/predict\",\n",
    "        json=appointment,\n",
    "        headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ“¬ Response Status: {response.status_code}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        \n",
    "        # Display prediction\n",
    "        prediction_text = \"No-Show\" if result['prediction'] == 1 else \"Will Attend\"\n",
    "        print(f\"\\nğŸ“Š Prediction Result:\")\n",
    "        print(f\"   Prediction: {prediction_text}\")\n",
    "        print(f\"   Probability: {result['probability']:.1%}\")\n",
    "        \n",
    "        # Display risk assessment\n",
    "        risk = result.get('risk', {})\n",
    "        print(f\"\\nğŸ¯ Risk Assessment:\")\n",
    "        print(f\"   Tier: {risk.get('tier', 'unknown')} {risk.get('emoji', '')}\")\n",
    "        print(f\"   Confidence: {risk.get('confidence', 'unknown')}\")\n",
    "        print(f\"   Color: {risk.get('color', 'unknown')}\")\n",
    "        \n",
    "        # Display intervention\n",
    "        intervention = result.get('intervention', {})\n",
    "        print(f\"\\nğŸ’¡ Recommended Intervention:\")\n",
    "        print(f\"   Action: {intervention.get('action', 'unknown')}\")\n",
    "        print(f\"   SMS Reminders: {intervention.get('sms_reminders', 'unknown')}\")\n",
    "        print(f\"   Phone Call: {intervention.get('phone_call', 'unknown')}\")\n",
    "        print(f\"   Priority: {intervention.get('priority', 'unknown')}\")\n",
    "        \n",
    "        # Display metadata\n",
    "        print(f\"\\nğŸ“‹ Metadata:\")\n",
    "        print(f\"   Model Version: {result.get('model_version', 'unknown')}\")\n",
    "        print(f\"   Prediction ID: {result.get('prediction_id', 'unknown')}\")\n",
    "        print(f\"   Timestamp: {result.get('timestamp', 'unknown')}\")\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        print(f\"âŒ Error Response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "prediction_result = test_single_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51bd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Multiple Risk Scenarios\n",
      "============================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Scenario 1: Low Risk - Senior with chronic condition\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Input: age=68, lead_days=2, sms=1\n",
      "   â†’ Probability: 19.7%\n",
      "   â†’ Risk Tier: LOW ğŸŸ¢\n",
      "   â†’ Action: Standard SMS reminder\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Scenario 2: Medium Risk - Adult, moderate lead time\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Input: age=42, lead_days=12, sms=1\n",
      "   â†’ Probability: 29.6%\n",
      "   â†’ Risk Tier: LOW ğŸŸ¢\n",
      "   â†’ Action: Standard SMS reminder\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Scenario 3: High Risk - Young adult, long lead time, no SMS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Input: age=23, lead_days=28, sms=0\n",
      "   â†’ Probability: 45.0%\n",
      "   â†’ Risk Tier: MEDIUM ğŸŸ¡\n",
      "   â†’ Action: Double SMS reminder\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Scenario 4: First-time patient\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Input: age=30, lead_days=14, sms=1\n",
      "   â†’ Probability: 32.0%\n",
      "   â†’ Risk Tier: MEDIUM ğŸŸ¡\n",
      "   â†’ Action: Double SMS reminder\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 17: Test Multiple Risk Scenarios\n",
    "# =============================================================================\n",
    "\n",
    "@api_test(\"Multiple Risk Scenarios\")\n",
    "def test_risk_scenarios():\n",
    "    \"\"\"Test predictions across different risk profiles.\"\"\"\n",
    "    \n",
    "    scenarios = [\n",
    "        {\n",
    "            \"name\": \"Low Risk - Senior with chronic condition\",\n",
    "            \"data\": {\n",
    "                \"age\": 68,\n",
    "                \"gender\": \"F\",\n",
    "                \"lead_days\": 2,\n",
    "                \"hypertension\": 1,\n",
    "                \"diabetes\": 1,\n",
    "                \"sms_received\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Medium Risk - Adult, moderate lead time\",\n",
    "            \"data\": {\n",
    "                \"age\": 42,\n",
    "                \"gender\": \"M\",\n",
    "                \"lead_days\": 12,\n",
    "                \"sms_received\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"High Risk - Young adult, long lead time, no SMS\",\n",
    "            \"data\": {\n",
    "                \"age\": 23,\n",
    "                \"gender\": \"M\",\n",
    "                \"lead_days\": 28,\n",
    "                \"sms_received\": 0,\n",
    "                \"scholarship\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"First-time patient\",\n",
    "            \"data\": {\n",
    "                \"age\": 30,\n",
    "                \"gender\": \"F\",\n",
    "                \"lead_days\": 14,\n",
    "                \"sms_received\": 1\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, scenario in enumerate(scenarios, 1):\n",
    "        print(f\"\\n{'â”€' * 50}\")\n",
    "        print(f\"Scenario {i}: {scenario['name']}\")\n",
    "        print(f\"{'â”€' * 50}\")\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/v1/predict\",\n",
    "            json=scenario[\"data\"]\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            print(f\"   Input: age={scenario['data']['age']}, \"\n",
    "                  f\"lead_days={scenario['data']['lead_days']}, \"\n",
    "                  f\"sms={scenario['data'].get('sms_received', 0)}\")\n",
    "            print(f\"   â†’ Probability: {result['probability']:.1%}\")\n",
    "            print(f\"   â†’ Risk Tier: {result['risk']['tier']} {result['risk']['emoji']}\")\n",
    "            print(f\"   â†’ Action: {result['intervention']['action']}\")\n",
    "            \n",
    "            results.append({\n",
    "                \"scenario\": scenario[\"name\"],\n",
    "                \"probability\": result['probability'],\n",
    "                \"risk_tier\": result['risk']['tier']\n",
    "            })\n",
    "        else:\n",
    "            print(f\"   âŒ Error: {response.status_code}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the test\n",
    "scenario_results = test_risk_scenarios()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Batch Prediction\n",
      "============================================================\n",
      "ğŸ“¦ Sending batch of 8 appointments...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "\n",
      "ğŸ“Š Batch Results Summary:\n",
      "   Total Appointments: 8\n",
      "   Predicted No-Shows: 0\n",
      "   Predicted Shows: 8\n",
      "   Average Probability: 28.3%\n",
      "   Processing Time: 118.4ms\n",
      "\n",
      "ğŸ“ˆ Risk Distribution:\n",
      "   CRITICAL   â”‚                      â”‚ 0 (0.0%)\n",
      "   HIGH       â”‚                      â”‚ 0 (0.0%)\n",
      "   MEDIUM     â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                â”‚ 2 (25.0%)\n",
      "   LOW        â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      â”‚ 6 (75.0%)\n",
      "   MINIMAL    â”‚                      â”‚ 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 18: Test Batch Prediction Endpoint\n",
    "# =============================================================================\n",
    "\n",
    "@api_test(\"Batch Prediction\")\n",
    "def test_batch_prediction():\n",
    "    \"\"\"Test POST /api/v1/predict/batch with multiple appointments.\"\"\"\n",
    "    \n",
    "    # Create diverse batch\n",
    "    batch_appointments = [\n",
    "        {\"age\": 22, \"gender\": \"M\", \"lead_days\": 1, \"sms_received\": 1},\n",
    "        {\"age\": 28, \"gender\": \"F\", \"lead_days\": 5, \"sms_received\": 1},\n",
    "        {\"age\": 35, \"gender\": \"M\", \"lead_days\": 10, \"sms_received\": 0},\n",
    "        {\"age\": 42, \"gender\": \"F\", \"lead_days\": 14, \"sms_received\": 1, \"hypertension\": 1},\n",
    "        {\"age\": 55, \"gender\": \"M\", \"lead_days\": 21, \"sms_received\": 1, \"diabetes\": 1},\n",
    "        {\"age\": 65, \"gender\": \"F\", \"lead_days\": 7, \"sms_received\": 1, \"hypertension\": 1},\n",
    "        {\"age\": 75, \"gender\": \"M\", \"lead_days\": 3, \"sms_received\": 1},\n",
    "        {\"age\": 18, \"gender\": \"F\", \"lead_days\": 30, \"sms_received\": 0, \"scholarship\": 1},\n",
    "    ]\n",
    "    \n",
    "    print(f\"ğŸ“¦ Sending batch of {len(batch_appointments)} appointments...\")\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/api/v1/predict/batch\",\n",
    "        json={\"appointments\": batch_appointments}\n",
    "    )\n",
    "    \n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        summary = result[\"summary\"]\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Batch Results Summary:\")\n",
    "        print(f\"   Total Appointments: {summary['total']}\")\n",
    "        print(f\"   Predicted No-Shows: {summary['predicted_noshows']}\")\n",
    "        print(f\"   Predicted Shows: {summary['predicted_shows']}\")\n",
    "        print(f\"   Average Probability: {summary['avg_probability']:.1%}\")\n",
    "        print(f\"   Processing Time: {result['processing_time_ms']:.1f}ms\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ Risk Distribution:\")\n",
    "        risk_dist = summary['risk_distribution']\n",
    "        total = summary['total']\n",
    "        \n",
    "        for tier in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'MINIMAL']:\n",
    "            count = risk_dist.get(tier, 0)\n",
    "            pct = count / total * 100 if total > 0 else 0\n",
    "            bar = 'â–ˆ' * int(pct / 5)\n",
    "            print(f\"   {tier:10} â”‚ {bar:20} â”‚ {count} ({pct:.1f}%)\")\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        print(f\"âŒ Error: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "batch_result = test_batch_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7785bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Input Validation\n",
      "============================================================\n",
      "âœ… Negative age\n",
      "   Expected: 422, Got: 422\n",
      "âœ… Age too high (>120)\n",
      "   Expected: 422, Got: 422\n",
      "âœ… Invalid gender\n",
      "   Expected: 422, Got: 422\n",
      "âœ… Negative lead days\n",
      "   Expected: 422, Got: 422\n",
      "âœ… Missing required field (lead_days)\n",
      "   Expected: 422, Got: 422\n",
      "âœ… Invalid binary field (sms_received=5)\n",
      "   Expected: 422, Got: 422\n",
      "\n",
      "ğŸ“Š Validation Tests: 6/6 passed\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 19: Test Input Validation\n",
    "# =============================================================================\n",
    "\n",
    "@api_test(\"Input Validation\")\n",
    "def test_input_validation():\n",
    "    \"\"\"Test that the API properly validates input data.\"\"\"\n",
    "    \n",
    "    invalid_cases = [\n",
    "        {\n",
    "            \"name\": \"Negative age\",\n",
    "            \"data\": {\"age\": -5, \"gender\": \"F\", \"lead_days\": 7},\n",
    "            \"expected_status\": 422\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Age too high (>120)\",\n",
    "            \"data\": {\"age\": 150, \"gender\": \"F\", \"lead_days\": 7},\n",
    "            \"expected_status\": 422\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Invalid gender\",\n",
    "            \"data\": {\"age\": 35, \"gender\": \"X\", \"lead_days\": 7},\n",
    "            \"expected_status\": 422\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Negative lead days\",\n",
    "            \"data\": {\"age\": 35, \"gender\": \"F\", \"lead_days\": -1},\n",
    "            \"expected_status\": 422\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Missing required field (lead_days)\",\n",
    "            \"data\": {\"age\": 35, \"gender\": \"F\"},\n",
    "            \"expected_status\": 422\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Invalid binary field (sms_received=5)\",\n",
    "            \"data\": {\"age\": 35, \"gender\": \"F\", \"lead_days\": 7, \"sms_received\": 5},\n",
    "            \"expected_status\": 422\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    passed = 0\n",
    "    failed = 0\n",
    "    \n",
    "    for case in invalid_cases:\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/v1/predict\",\n",
    "            json=case[\"data\"]\n",
    "        )\n",
    "        \n",
    "        is_passed = response.status_code == case[\"expected_status\"]\n",
    "        icon = \"âœ…\" if is_passed else \"âŒ\"\n",
    "        \n",
    "        print(f\"{icon} {case['name']}\")\n",
    "        print(f\"   Expected: {case['expected_status']}, Got: {response.status_code}\")\n",
    "        \n",
    "        if is_passed:\n",
    "            passed += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "        \n",
    "        results.append({\n",
    "            \"case\": case[\"name\"],\n",
    "            \"passed\": is_passed,\n",
    "            \"expected\": case[\"expected_status\"],\n",
    "            \"actual\": response.status_code\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Validation Tests: {passed}/{len(invalid_cases)} passed\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the test\n",
    "validation_results = test_input_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Quick Prediction (Query Parameters)\n",
      "============================================================\n",
      "ğŸ“ Query Parameters:\n",
      "   age=35\n",
      "   gender=F\n",
      "   lead_days=7\n",
      "   sms_received=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Status Code: 200\n",
      "\n",
      "ğŸ“Š Quick Prediction Result:\n",
      "   Probability: 27.7%\n",
      "   Prediction: Will Attend\n",
      "   Risk Tier: LOW\n",
      "   Intervention: Standard SMS reminder\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 20: Test Quick Prediction Endpoint\n",
    "# =============================================================================\n",
    "\n",
    "@api_test(\"Quick Prediction (Query Parameters)\")\n",
    "def test_quick_prediction():\n",
    "    \"\"\"Test POST /api/v1/predict/quick using query parameters.\"\"\"\n",
    "    \n",
    "    params = {\n",
    "        \"age\": 35,\n",
    "        \"gender\": \"F\",\n",
    "        \"lead_days\": 7,\n",
    "        \"sms_received\": 1\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ“ Query Parameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"   {key}={value}\")\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/api/v1/predict/quick\",\n",
    "        params=params\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nStatus Code: {response.status_code}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Quick Prediction Result:\")\n",
    "        print(f\"   Probability: {result.get('probability', 0):.1%}\")\n",
    "        print(f\"   Prediction: {result.get('prediction', 'unknown')}\")\n",
    "        print(f\"   Risk Tier: {result.get('risk_tier', 'unknown')}\")\n",
    "        print(f\"   Intervention: {result.get('intervention', 'unknown')}\")\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        print(f\"âŒ Error: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "quick_result = test_quick_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Model Information Endpoints\n",
      "============================================================\n",
      "1. Model Information (/api/v1/model):\n",
      "----------------------------------------\n",
      "   Name: unknown\n",
      "   Version: unknown\n",
      "   Type: unknown\n",
      "   Features: unknown\n",
      "\n",
      "2. Feature Information (/api/v1/model/features):\n",
      "----------------------------------------\n",
      "   Required: ['age', 'gender', 'lead_days']\n",
      "   Optional: 10 features\n",
      "            ['handicap', 'scholarship', 'alcoholism', 'is_first_appointment', 'diabetes']...\n",
      "\n",
      "3. Threshold Information (/api/v1/predict/thresholds):\n",
      "----------------------------------------\n",
      "   Default Threshold: 0.5\n",
      "   Risk Tiers Defined: 5\n",
      "      â€¢ CRITICAL: min_prob=0.7\n",
      "      â€¢ HIGH: min_prob=0.5\n",
      "      â€¢ MEDIUM: min_prob=0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 21: Test Model Information Endpoints\n",
    "# =============================================================================\n",
    "\n",
    "@api_test(\"Model Information Endpoints\")\n",
    "def test_model_info():\n",
    "    \"\"\"Test model information and feature endpoints.\"\"\"\n",
    "    \n",
    "    # 1. Model info\n",
    "    print(\"1. Model Information (/api/v1/model):\")\n",
    "    print(\"-\" * 40)\n",
    "    response = requests.get(f\"{API_URL}/api/v1/model\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"   Name: {data.get('name', 'unknown')}\")\n",
    "        print(f\"   Version: {data.get('version', 'unknown')}\")\n",
    "        print(f\"   Type: {data.get('type', 'unknown')}\")\n",
    "        print(f\"   Features: {data.get('features', 'unknown')}\")\n",
    "    else:\n",
    "        print(f\"   âŒ Error: {response.status_code}\")\n",
    "    \n",
    "    # 2. Features info\n",
    "    print(\"\\n2. Feature Information (/api/v1/model/features):\")\n",
    "    print(\"-\" * 40)\n",
    "    response = requests.get(f\"{API_URL}/api/v1/model/features\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"   Required: {data.get('required', [])}\")\n",
    "        optional = data.get('optional', [])\n",
    "        print(f\"   Optional: {len(optional)} features\")\n",
    "        if optional:\n",
    "            print(f\"            {optional[:5]}...\")\n",
    "    else:\n",
    "        print(f\"   âŒ Error: {response.status_code}\")\n",
    "    \n",
    "    # 3. Threshold info\n",
    "    print(\"\\n3. Threshold Information (/api/v1/predict/thresholds):\")\n",
    "    print(\"-\" * 40)\n",
    "    response = requests.get(f\"{API_URL}/api/v1/predict/thresholds\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"   Default Threshold: {data.get('default_threshold', 'unknown')}\")\n",
    "        tiers = data.get('risk_tiers', {})\n",
    "        print(f\"   Risk Tiers Defined: {len(tiers)}\")\n",
    "        for tier_name, tier_info in list(tiers.items())[:3]:\n",
    "            print(f\"      â€¢ {tier_name}: min_prob={tier_info.get('min_probability', 'unknown')}\")\n",
    "    else:\n",
    "        print(f\"   âŒ Error: {response.status_code}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run the test\n",
    "test_model_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1f202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST: Performance Benchmarks\n",
      "============================================================\n",
      "1. Single Request Latency (20 requests):\n",
      "----------------------------------------\n",
      "   Mean:    17.7ms\n",
      "   Median:  17.8ms\n",
      "   Std Dev: 1.6ms\n",
      "   Min:     15.1ms\n",
      "   Max:     20.0ms\n",
      "\n",
      "2. Batch Request Performance:\n",
      "----------------------------------------\n",
      "    10 items:  227.8ms total, 22.78ms/item\n",
      "    50 items:  694.1ms total, 13.88ms/item\n",
      "   100 items: 1437.0ms total, 14.37ms/item\n",
      "\n",
      "3. Concurrent Requests (10 simultaneous):\n",
      "----------------------------------------\n",
      "   Successful: 10/10\n",
      "   Mean Latency: 132.6ms\n",
      "   Max Latency: 161.2ms\n",
      "   Est. Throughput: 62 req/sec\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 22: Performance Benchmarks\n",
    "# =============================================================================\n",
    "\n",
    "import statistics\n",
    "import concurrent.futures\n",
    "\n",
    "@api_test(\"Performance Benchmarks\")\n",
    "def test_performance():\n",
    "    \"\"\"Measure API performance metrics.\"\"\"\n",
    "    \n",
    "    sample_appointment = {\n",
    "        \"age\": 35,\n",
    "        \"gender\": \"F\",\n",
    "        \"lead_days\": 7,\n",
    "        \"sms_received\": 1\n",
    "    }\n",
    "    \n",
    "    # 1. Single request latency\n",
    "    print(\"1. Single Request Latency (20 requests):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    latencies = []\n",
    "    for i in range(20):\n",
    "        start = time.time()\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/v1/predict\",\n",
    "            json=sample_appointment\n",
    "        )\n",
    "        elapsed = (time.time() - start) * 1000  # Convert to ms\n",
    "        if response.status_code == 200:\n",
    "            latencies.append(elapsed)\n",
    "    \n",
    "    if latencies:\n",
    "        print(f\"   Mean:    {statistics.mean(latencies):.1f}ms\")\n",
    "        print(f\"   Median:  {statistics.median(latencies):.1f}ms\")\n",
    "        print(f\"   Std Dev: {statistics.stdev(latencies):.1f}ms\")\n",
    "        print(f\"   Min:     {min(latencies):.1f}ms\")\n",
    "        print(f\"   Max:     {max(latencies):.1f}ms\")\n",
    "    \n",
    "    # 2. Batch request performance\n",
    "    print(\"\\n2. Batch Request Performance:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    batch_sizes = [10, 50, 100]\n",
    "    for size in batch_sizes:\n",
    "        appointments = [sample_appointment.copy() for _ in range(size)]\n",
    "        \n",
    "        start = time.time()\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/v1/predict/batch\",\n",
    "            json={\"appointments\": appointments}\n",
    "        )\n",
    "        elapsed = (time.time() - start) * 1000\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            per_item = elapsed / size\n",
    "            print(f\"   {size:3} items: {elapsed:6.1f}ms total, {per_item:.2f}ms/item\")\n",
    "    \n",
    "    # 3. Concurrent requests\n",
    "    print(\"\\n3. Concurrent Requests (10 simultaneous):\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    def make_single_request():\n",
    "        start = time.time()\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/v1/predict\",\n",
    "            json=sample_appointment\n",
    "        )\n",
    "        return (time.time() - start) * 1000, response.status_code\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(make_single_request) for _ in range(10)]\n",
    "        results = [f.result() for f in futures]\n",
    "    \n",
    "    times = [r[0] for r in results]\n",
    "    success_count = sum(1 for r in results if r[1] == 200)\n",
    "    \n",
    "    print(f\"   Successful: {success_count}/10\")\n",
    "    print(f\"   Mean Latency: {statistics.mean(times):.1f}ms\")\n",
    "    print(f\"   Max Latency: {max(times):.1f}ms\")\n",
    "    \n",
    "    # Estimate throughput\n",
    "    if times:\n",
    "        throughput = len(times) / (max(times) / 1000)\n",
    "        print(f\"   Est. Throughput: {throughput:.0f} req/sec\")\n",
    "    \n",
    "    return {\n",
    "        \"single_latency_ms\": statistics.mean(latencies) if latencies else None,\n",
    "        \"concurrent_success\": success_count\n",
    "    }\n",
    "\n",
    "# Run the test\n",
    "performance_results = test_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0177a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PYTHON CLIENT LIBRARY DEMO\n",
      "============================================================\n",
      "âœ… API Client imported successfully\n",
      "\n",
      "ğŸ“‹ Client Health Check:\n",
      "   âœ… API is healthy\n",
      "\n",
      "ğŸ“Š Making Prediction with Client:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction: WILL ATTEND\n",
      "Probability: 27.7%\n",
      "Risk Tier: LOW\n",
      "Intervention: Standard SMS reminder\n",
      "\n",
      "ğŸ“‹ Additional Properties:\n",
      "   result.will_show: True\n",
      "   result.will_noshow: False\n",
      "   result.probability: 0.2771\n",
      "   result.risk_tier: LOW\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 23: Python API Client Demonstration\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PYTHON CLIENT LIBRARY DEMO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Try to import and use the client\n",
    "try:\n",
    "    # Add scripts directory to path\n",
    "    scripts_path = PROJECT_ROOT / \"scripts\"\n",
    "    if scripts_path.exists():\n",
    "        sys.path.insert(0, str(scripts_path))\n",
    "    \n",
    "    from api_client import NoShowAPIClient, PredictionResult\n",
    "    \n",
    "    print(\"âœ… API Client imported successfully\\n\")\n",
    "    \n",
    "    # Check if API is running\n",
    "    if check_api_status()[\"running\"]:\n",
    "        # Create client instance\n",
    "        client = NoShowAPIClient(API_URL)\n",
    "        \n",
    "        # Health check\n",
    "        print(\"ğŸ“‹ Client Health Check:\")\n",
    "        if client.is_healthy():\n",
    "            print(\"   âœ… API is healthy\\n\")\n",
    "        else:\n",
    "            print(\"   âš ï¸ API health check failed\\n\")\n",
    "        \n",
    "        # Make a prediction using the client\n",
    "        print(\"ğŸ“Š Making Prediction with Client:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        result = client.predict(\n",
    "            age=35,\n",
    "            gender=\"F\",\n",
    "            lead_days=7,\n",
    "            sms_received=1,\n",
    "            hypertension=0,\n",
    "            diabetes=0\n",
    "        )\n",
    "        \n",
    "        # Display result using the PredictionResult object\n",
    "        print(f\"\\n{result}\")\n",
    "        \n",
    "        # Access specific properties\n",
    "        print(f\"\\nğŸ“‹ Additional Properties:\")\n",
    "        print(f\"   result.will_show: {result.will_show}\")\n",
    "        print(f\"   result.will_noshow: {result.will_noshow}\")\n",
    "        print(f\"   result.probability: {result.probability:.4f}\")\n",
    "        print(f\"   result.risk_tier: {result.risk_tier}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âš ï¸ API not running - cannot demonstrate client\")\n",
    "        print(\"   Start server with: python serve_model.py\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Could not import API client: {e}\")\n",
    "    print(\"   Ensure scripts/api_client.py exists\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4774552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BATCH PREDICTION WITH CLIENT\n",
      "============================================================\n",
      "\n",
      "ğŸ“¦ Sending 4 appointments...\n",
      "\n",
      "ğŸ“Š Batch Results:\n",
      "   Total: 4\n",
      "   Predicted No-Shows: 0\n",
      "   Predicted Shows: 4\n",
      "   Average Probability: 26.8%\n",
      "   Processing Time: 61.5ms\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 24: Batch Prediction with Client\n",
    "# =============================================================================\n",
    "\n",
    "if check_api_status()[\"running\"]:\n",
    "    try:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"BATCH PREDICTION WITH CLIENT\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create list of appointments\n",
    "        appointments = [\n",
    "            {\"age\": 25, \"gender\": \"M\", \"lead_days\": 3, \"sms_received\": 1},\n",
    "            {\"age\": 40, \"gender\": \"F\", \"lead_days\": 10, \"sms_received\": 1},\n",
    "            {\"age\": 55, \"gender\": \"M\", \"lead_days\": 20, \"sms_received\": 0},\n",
    "            {\"age\": 70, \"gender\": \"F\", \"lead_days\": 5, \"sms_received\": 1, \"hypertension\": 1},\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nğŸ“¦ Sending {len(appointments)} appointments...\")\n",
    "        \n",
    "        # Use client for batch prediction\n",
    "        result = client.predict_batch(appointments)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Batch Results:\")\n",
    "        print(f\"   Total: {result['summary']['total']}\")\n",
    "        print(f\"   Predicted No-Shows: {result['summary']['predicted_noshows']}\")\n",
    "        print(f\"   Predicted Shows: {result['summary']['predicted_shows']}\")\n",
    "        print(f\"   Average Probability: {result['summary']['avg_probability']:.1%}\")\n",
    "        print(f\"   Processing Time: {result['processing_time_ms']:.1f}ms\")\n",
    "        \n",
    "    except NameError:\n",
    "        print(\"âš ï¸ Client not defined - run the previous cell first\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {type(e).__name__}: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ API not running - skipping batch demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DOCKER DEPLOYMENT STATUS\n",
      "============================================================\n",
      "âœ… Docker is installed\n",
      "   Docker version 28.4.0, build d8eb465\n",
      "âœ… Docker Compose is available\n",
      "\n",
      "ğŸ“ Docker Files:\n",
      "   Dockerfile: âœ… exists\n",
      "   docker-compose.yaml: âœ… exists\n",
      "\n",
      "ğŸ“‹ Docker Commands Reference:\n",
      "----------------------------------------\n",
      "\n",
      "# Build image\n",
      "docker build -t noshow-api:latest .\n",
      "\n",
      "# Run container\n",
      "docker run -d --name noshow-api -p 8000:8000 \\\n",
      "    -v $(pwd)/models/production:/app/models/production:ro \\\n",
      "    noshow-api:latest\n",
      "\n",
      "# View logs\n",
      "docker logs -f noshow-api\n",
      "\n",
      "# Stop and remove\n",
      "docker stop noshow-api && docker rm noshow-api\n",
      "\n",
      "# Using Docker Compose\n",
      "docker-compose up -d        # Start\n",
      "docker-compose logs -f      # View logs\n",
      "docker-compose down         # Stop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 25: Docker Status Check\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DOCKER DEPLOYMENT STATUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if Docker is available\n",
    "docker_path = shutil.which(\"docker\")\n",
    "docker_available = docker_path is not None\n",
    "\n",
    "if docker_available:\n",
    "    print(\"âœ… Docker is installed\")\n",
    "    \n",
    "    # Get Docker version\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"docker\", \"--version\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        print(f\"   {result.stdout.strip()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Could not get version: {e}\")\n",
    "    \n",
    "    # Check for docker-compose\n",
    "    compose_path = shutil.which(\"docker-compose\")\n",
    "    if compose_path:\n",
    "        print(\"âœ… Docker Compose is available\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Docker Compose not found in PATH\")\n",
    "    \n",
    "    # Check for project Docker files\n",
    "    dockerfile = PROJECT_ROOT / \"Dockerfile\"\n",
    "    composefile = PROJECT_ROOT / \"docker-compose.yaml\"\n",
    "    \n",
    "    print(f\"\\nğŸ“ Docker Files:\")\n",
    "    print(f\"   Dockerfile: {'âœ… exists' if dockerfile.exists() else 'âŒ not found'}\")\n",
    "    print(f\"   docker-compose.yaml: {'âœ… exists' if composefile.exists() else 'âŒ not found'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Docker is NOT installed\")\n",
    "    print(\"   Install from: https://docs.docker.com/get-docker/\")\n",
    "\n",
    "# Display Docker commands reference\n",
    "print(\"\\nğŸ“‹ Docker Commands Reference:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\"\"\n",
    "# Build image\n",
    "docker build -t noshow-api:latest .\n",
    "\n",
    "# Run container\n",
    "docker run -d --name noshow-api -p 8000:8000 \\\\\n",
    "    -v $(pwd)/models/production:/app/models/production:ro \\\\\n",
    "    noshow-api:latest\n",
    "\n",
    "# View logs\n",
    "docker logs -f noshow-api\n",
    "\n",
    "# Stop and remove\n",
    "docker stop noshow-api && docker rm noshow-api\n",
    "\n",
    "# Using Docker Compose\n",
    "docker-compose up -d        # Start\n",
    "docker-compose logs -f      # View logs\n",
    "docker-compose down         # Stop\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70460678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "API DOCUMENTATION\n",
      "============================================================\n",
      "\n",
      "ğŸ“š OpenAPI Specification:\n",
      "   Title: Healthcare No-Show Prediction API\n",
      "   Version: 1.0.0\n",
      "   OpenAPI Version: 3.1.0\n",
      "\n",
      "ğŸ“‹ Endpoints Summary:\n",
      "   Total Paths: 52\n",
      "   DELETE: 2 endpoints\n",
      "   GET: 28 endpoints\n",
      "   POST: 22 endpoints\n",
      "\n",
      "ğŸ“‘ All Endpoints:\n",
      "   GET    /api/v1/auth/callback/oidc\n",
      "          â””â”€ Callback Oidc\n",
      "   GET    /api/v1/auth/login/oidc\n",
      "          â””â”€ Login Oidc\n",
      "   POST   /api/v1/auth/token\n",
      "          â””â”€ Login For Access Token\n",
      "   GET    /api/v1/auth/users/me\n",
      "          â””â”€ Read Users Me\n",
      "   GET    /api/v1/compliance/audit\n",
      "          â””â”€ View Audit Logs\n",
      "   POST   /api/v1/compliance/consent\n",
      "          â””â”€ Record Consent\n",
      "   POST   /api/v1/compliance/forget-patient\n",
      "          â””â”€ Forget Patient\n",
      "   POST   /api/v1/feedback/\n",
      "          â””â”€ Submit Feedback\n",
      "   GET    /api/v1/feedback/stats/{endpoint}\n",
      "          â””â”€ Get Feedback Stats\n",
      "   GET    /api/v1/feedback/summary\n",
      "          â””â”€ Get Overall Feedback Summary\n",
      "   GET    /api/v1/health\n",
      "          â””â”€ Health Check\n",
      "   GET    /api/v1/live\n",
      "          â””â”€ Liveness Check\n",
      "   POST   /api/v1/llm/agent\n",
      "          â””â”€ Chat with Agent (Tool-enabled)\n",
      "   POST   /api/v1/llm/chat\n",
      "          â””â”€ Chat with Healthcare Assistant\n",
      "   POST   /api/v1/llm/explain\n",
      "          â””â”€ Explain Prediction\n",
      "   GET    /api/v1/llm/health\n",
      "          â””â”€ Health Check\n",
      "   POST   /api/v1/llm/intervention\n",
      "          â””â”€ Get Intervention Recommendation\n",
      "   GET    /api/v1/llm/metrics\n",
      "          â””â”€ Get LLM Metrics\n",
      "   POST   /api/v1/llm/predict-and-explain\n",
      "          â””â”€ Predict and Explain\n",
      "   GET    /api/v1/llm/sessions\n",
      "          â””â”€ List Active Sessions\n",
      "   DELETE /api/v1/llm/sessions/{session_id}\n",
      "          â””â”€ Delete Session\n",
      "   GET    /api/v1/llm/sessions/{session_id}/history\n",
      "          â””â”€ Get Session History\n",
      "   GET    /api/v1/model\n",
      "          â””â”€ Get Model Information\n",
      "   GET    /api/v1/model/features\n",
      "          â””â”€ Get Feature Information\n",
      "   GET    /api/v1/model/history\n",
      "          â””â”€ Get Historical Data\n",
      "   GET    /api/v1/model/metrics\n",
      "          â””â”€ Get Model Metrics\n",
      "   POST   /api/v1/model/reload\n",
      "          â””â”€ Reload Model\n",
      "   POST   /api/v1/monitoring/analyze\n",
      "          â””â”€ Trigger drift analysis\n",
      "   GET    /api/v1/monitoring/drift\n",
      "          â””â”€ Get data drift metrics\n",
      "   GET    /api/v1/monitoring/metrics\n",
      "          â””â”€ Prometheus metrics endpoint\n",
      "   POST   /api/v1/monitoring/reference\n",
      "          â””â”€ Update reference dataset\n",
      "   POST   /api/v1/predict\n",
      "          â””â”€ Predict No-Show\n",
      "   POST   /api/v1/predict/batch\n",
      "          â””â”€ Batch Predict No-Shows\n",
      "   POST   /api/v1/predict/quick\n",
      "          â””â”€ Quick Prediction\n",
      "   GET    /api/v1/predict/tasks/{task_id}\n",
      "          â””â”€ Get Task Status\n",
      "   GET    /api/v1/predict/thresholds\n",
      "          â””â”€ Get Threshold Information\n",
      "   POST   /api/v1/rag/ask\n",
      "          â””â”€ Ask Policy Question\n",
      "   POST   /api/v1/rag/ask/batch\n",
      "          â””â”€ Batch Policy Questions\n",
      "   POST   /api/v1/rag/evaluate\n",
      "          â””â”€ Evaluate RAG\n",
      "   POST   /api/v1/rag/index/add-document\n",
      "          â””â”€ Add Document\n",
      "   POST   /api/v1/rag/index/create\n",
      "          â””â”€ Create Index\n",
      "   POST   /api/v1/rag/index/load\n",
      "          â””â”€ Load Index\n",
      "   GET    /api/v1/rag/index/status\n",
      "          â””â”€ Index Status\n",
      "   GET    /api/v1/rag/search\n",
      "          â””â”€ Search Policies\n",
      "   POST   /api/v1/rag/sessions\n",
      "          â””â”€ Create Session\n",
      "   DELETE /api/v1/rag/sessions/{session_id}\n",
      "          â””â”€ Clear Session\n",
      "   GET    /api/v1/rag/sessions/{session_id}/history\n",
      "          â””â”€ Get Session History\n",
      "   GET    /api/v1/ready\n",
      "          â””â”€ Readiness Check\n",
      "   GET    /health\n",
      "          â””â”€ Health Check\n",
      "   GET    /live\n",
      "          â””â”€ Liveness Check\n",
      "   GET    /metrics\n",
      "          â””â”€ Metrics\n",
      "   GET    /ready\n",
      "          â””â”€ Readiness Check\n",
      "\n",
      "ğŸŒ Documentation URLs:\n",
      "   Swagger UI: http://127.0.0.1:8000/docs\n",
      "   ReDoc:      http://127.0.0.1:8000/redoc\n",
      "   OpenAPI:    http://127.0.0.1:8000/openapi.json\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 26: API Documentation Overview\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"API DOCUMENTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if check_api_status()[\"running\"]:\n",
    "    try:\n",
    "        # Fetch OpenAPI specification\n",
    "        response = requests.get(f\"{API_URL}/openapi.json\", timeout=5)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            openapi = response.json()\n",
    "            \n",
    "            print(f\"\\nğŸ“š OpenAPI Specification:\")\n",
    "            print(f\"   Title: {openapi['info']['title']}\")\n",
    "            print(f\"   Version: {openapi['info']['version']}\")\n",
    "            print(f\"   OpenAPI Version: {openapi.get('openapi', 'unknown')}\")\n",
    "            \n",
    "            # Count endpoints by method\n",
    "            methods = {}\n",
    "            for path, path_info in openapi['paths'].items():\n",
    "                for method in path_info.keys():\n",
    "                    if method.upper() in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH']:\n",
    "                        methods[method.upper()] = methods.get(method.upper(), 0) + 1\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ Endpoints Summary:\")\n",
    "            print(f\"   Total Paths: {len(openapi['paths'])}\")\n",
    "            for method, count in sorted(methods.items()):\n",
    "                print(f\"   {method}: {count} endpoints\")\n",
    "            \n",
    "            # List all endpoints\n",
    "            print(f\"\\nğŸ“‘ All Endpoints:\")\n",
    "            for path, path_info in sorted(openapi['paths'].items()):\n",
    "                for method, details in path_info.items():\n",
    "                    if method.upper() in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH']:\n",
    "                        summary = details.get('summary', 'No description')\n",
    "                        print(f\"   {method.upper():6} {path}\")\n",
    "                        print(f\"          â””â”€ {summary}\")\n",
    "            \n",
    "            print(f\"\\nğŸŒ Documentation URLs:\")\n",
    "            print(f\"   Swagger UI: {API_URL}/docs\")\n",
    "            print(f\"   ReDoc:      {API_URL}/redoc\")\n",
    "            print(f\"   OpenAPI:    {API_URL}/openapi.json\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error fetching OpenAPI spec: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ API not running - cannot fetch documentation\")\n",
    "    print(f\"\\n   Start server, then visit:\")\n",
    "    print(f\"   Swagger UI: {API_URL}/docs\")\n",
    "    print(f\"   ReDoc:      {API_URL}/redoc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIMULATION: Daily Appointment Processing\n",
      "============================================================\n",
      "\n",
      "ğŸ“… Generating 100 appointments for today...\n",
      "ğŸ”® Getting predictions from API...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“Š DAILY OPERATIONS SUMMARY\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Total Appointments: 100\n",
      "   Processing Time: 1381ms\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Expected No-Shows: 0\n",
      "   Expected Attendance: 100\n",
      "   No-Show Rate: 0.0%\n",
      "   Average Risk Score: 26.1%\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“ˆ RISK DISTRIBUTION\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   CRITICAL   â”‚                         â”‚   0 (  0.0%)\n",
      "   HIGH       â”‚                         â”‚   0 (  0.0%)\n",
      "   MEDIUM     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚  35 ( 35.0%)\n",
      "   LOW        â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚  59 ( 59.0%)\n",
      "   MINIMAL    â”‚â–ˆâ–ˆâ–ˆ                      â”‚   6 (  6.0%)\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ’¡ INTERVENTION PLAN\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   ğŸ“ Phone calls needed:    0\n",
      "   ğŸ“± Extra SMS reminders:   35\n",
      "   ğŸ’° Deposits to request:   0\n",
      "   â­ Priority scheduling:   0\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ’° FINANCIAL IMPACT ESTIMATE\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   Potential no-shows:       0\n",
      "   Potential loss:           $0\n",
      "   Interventions planned:    0\n",
      "   Expected preventions:     0\n",
      "   Intervention cost:        $0\n",
      "   Expected savings:         $0\n",
      "   Net savings:              $0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 27: Daily Operations Simulation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SIMULATION: Daily Appointment Processing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if check_api_status()[\"running\"]:\n",
    "    # Generate realistic daily appointments\n",
    "    np.random.seed(42)\n",
    "    n_appointments = 100\n",
    "    \n",
    "    print(f\"\\nğŸ“… Generating {n_appointments} appointments for today...\")\n",
    "    \n",
    "    # Create realistic age distribution\n",
    "    ages = np.concatenate([\n",
    "        np.random.randint(5, 18, 10),     # Children\n",
    "        np.random.randint(18, 35, 25),    # Young adults\n",
    "        np.random.randint(35, 55, 35),    # Adults\n",
    "        np.random.randint(55, 75, 20),    # Middle-aged\n",
    "        np.random.randint(75, 90, 10),    # Elderly\n",
    "    ])\n",
    "    np.random.shuffle(ages)\n",
    "    ages = ages[:n_appointments]\n",
    "    \n",
    "    # Generate appointments\n",
    "    appointments = []\n",
    "    for age in ages:\n",
    "        appt = {\n",
    "            \"age\": int(age),\n",
    "            \"gender\": np.random.choice([\"M\", \"F\"], p=[0.4, 0.6]),\n",
    "            \"lead_days\": max(0, int(np.random.exponential(10))),\n",
    "            \"sms_received\": int(np.random.choice([0, 1], p=[0.15, 0.85])),\n",
    "            \"scholarship\": int(np.random.choice([0, 1], p=[0.88, 0.12])),\n",
    "            \"hypertension\": int(np.random.choice([0, 1], p=[0.75, 0.25]) if age > 40 else 0),\n",
    "            \"diabetes\": int(np.random.choice([0, 1], p=[0.85, 0.15]) if age > 45 else 0),\n",
    "        }\n",
    "        appointments.append(appt)\n",
    "    \n",
    "    # Get predictions\n",
    "    print(\"ğŸ”® Getting predictions from API...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_URL}/api/v1/predict/batch\",\n",
    "        json={\"appointments\": appointments}\n",
    "    )\n",
    "    \n",
    "    elapsed_ms = (time.time() - start_time) * 1000\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        summary = result[\"summary\"]\n",
    "        \n",
    "        # Display operations summary\n",
    "        print(f\"\\n{'â”€' * 50}\")\n",
    "        print(\"ğŸ“Š DAILY OPERATIONS SUMMARY\")\n",
    "        print(f\"{'â”€' * 50}\")\n",
    "        print(f\"   Total Appointments: {summary['total']}\")\n",
    "        print(f\"   Processing Time: {elapsed_ms:.0f}ms\")\n",
    "        print(f\"{'â”€' * 50}\")\n",
    "        print(f\"   Expected No-Shows: {summary['predicted_noshows']}\")\n",
    "        print(f\"   Expected Attendance: {summary['predicted_shows']}\")\n",
    "        print(f\"   No-Show Rate: {summary['predicted_noshows']/summary['total']:.1%}\")\n",
    "        print(f\"   Average Risk Score: {summary['avg_probability']:.1%}\")\n",
    "        \n",
    "        # Risk distribution\n",
    "        print(f\"\\n{'â”€' * 50}\")\n",
    "        print(\"ğŸ“ˆ RISK DISTRIBUTION\")\n",
    "        print(f\"{'â”€' * 50}\")\n",
    "        \n",
    "        risk_dist = summary['risk_distribution']\n",
    "        for tier in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'MINIMAL']:\n",
    "            count = risk_dist.get(tier, 0)\n",
    "            pct = count / summary['total'] * 100\n",
    "            bar_length = int(pct / 2)\n",
    "            bar = 'â–ˆ' * bar_length\n",
    "            print(f\"   {tier:10} â”‚{bar:25}â”‚ {count:3} ({pct:5.1f}%)\")\n",
    "        \n",
    "        # Intervention plan\n",
    "        critical = risk_dist.get('CRITICAL', 0)\n",
    "        high = risk_dist.get('HIGH', 0)\n",
    "        medium = risk_dist.get('MEDIUM', 0)\n",
    "        \n",
    "        print(f\"\\n{'â”€' * 50}\")\n",
    "        print(\"ğŸ’¡ INTERVENTION PLAN\")\n",
    "        print(f\"{'â”€' * 50}\")\n",
    "        print(f\"   ğŸ“ Phone calls needed:    {critical + high}\")\n",
    "        print(f\"   ğŸ“± Extra SMS reminders:   {critical + high + medium}\")\n",
    "        print(f\"   ğŸ’° Deposits to request:   {critical}\")\n",
    "        print(f\"   â­ Priority scheduling:   {critical}\")\n",
    "        \n",
    "        # Financial impact\n",
    "        cost_per_noshow = 150\n",
    "        intervention_success_rate = 0.30\n",
    "        phone_call_cost = 5\n",
    "        \n",
    "        expected_noshows = summary['predicted_noshows']\n",
    "        calls_to_make = critical + high\n",
    "        prevented = int(calls_to_make * intervention_success_rate)\n",
    "        savings = prevented * cost_per_noshow\n",
    "        intervention_cost = calls_to_make * phone_call_cost\n",
    "        net_savings = savings - intervention_cost\n",
    "        \n",
    "        print(f\"\\n{'â”€' * 50}\")\n",
    "        print(\"ğŸ’° FINANCIAL IMPACT ESTIMATE\")\n",
    "        print(f\"{'â”€' * 50}\")\n",
    "        print(f\"   Potential no-shows:       {expected_noshows}\")\n",
    "        print(f\"   Potential loss:           ${expected_noshows * cost_per_noshow:,}\")\n",
    "        print(f\"   Interventions planned:    {calls_to_make}\")\n",
    "        print(f\"   Expected preventions:     {prevented}\")\n",
    "        print(f\"   Intervention cost:        ${intervention_cost:,}\")\n",
    "        print(f\"   Expected savings:         ${savings:,}\")\n",
    "        print(f\"   Net savings:              ${net_savings:,}\")\n",
    "        print(f\"{'â”€' * 50}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ Error: {response.text}\")\n",
    "else:\n",
    "    print(\"âš ï¸ API not running - skipping simulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304711b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WEEK 7 SUMMARY: MODEL DEPLOYMENT\n",
      "============================================================\n",
      "\n",
      "âœ… COMPLETED TASKS:\n",
      "   1. Prepared production model with metadata\n",
      "   2. Explored API architecture and schemas\n",
      "   3. Tested all API endpoints\n",
      "   4. Benchmarked API performance\n",
      "   5. Demonstrated Python client usage\n",
      "   6. Reviewed Docker deployment options\n",
      "   7. Simulated real-world integration\n",
      "\n",
      "ğŸ“ PRODUCTION FILES CREATED:\n",
      "   models/production/\n",
      "   â”œâ”€â”€ model.joblib           # Production model\n",
      "   â”œâ”€â”€ preprocessor.joblib    # Preprocessor (if available)\n",
      "   â””â”€â”€ model_metadata.json    # Model metadata\n",
      "\n",
      "ğŸŒ API ENDPOINTS:\n",
      "   Health & Monitoring:\n",
      "   â”œâ”€â”€ GET  /health              â†’ Health check\n",
      "   â”œâ”€â”€ GET  /ready               â†’ Readiness probe\n",
      "   â””â”€â”€ GET  /live                â†’ Liveness probe\n",
      "\n",
      "   Predictions:\n",
      "   â”œâ”€â”€ POST /api/v1/predict      â†’ Single prediction\n",
      "   â”œâ”€â”€ POST /api/v1/predict/batch â†’ Batch predictions\n",
      "   â”œâ”€â”€ POST /api/v1/predict/quick â†’ Quick prediction\n",
      "   â””â”€â”€ GET  /api/v1/predict/thresholds â†’ Threshold info\n",
      "\n",
      "   Model Info:\n",
      "   â”œâ”€â”€ GET  /api/v1/model        â†’ Model information\n",
      "   â”œâ”€â”€ GET  /api/v1/model/features â†’ Feature info\n",
      "   â””â”€â”€ POST /api/v1/model/reload â†’ Reload model\n",
      "\n",
      "ğŸ³ DEPLOYMENT OPTIONS:\n",
      "   â€¢ Direct:     python serve_model.py\n",
      "   â€¢ Docker:     docker-compose up -d\n",
      "   â€¢ Production: docker-compose -f ... -f docker-compose.prod.yaml up\n",
      "\n",
      "ğŸ“Š TYPICAL PERFORMANCE:\n",
      "   â€¢ Single prediction:    10-50ms\n",
      "   â€¢ Batch (100 items):    100-200ms\n",
      "   â€¢ Concurrent requests:  50-100 req/sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 28: Week 7 Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WEEK 7 SUMMARY: MODEL DEPLOYMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary = \"\"\"\n",
    "âœ… COMPLETED TASKS:\n",
    "   1. Prepared production model with metadata\n",
    "   2. Explored API architecture and schemas\n",
    "   3. Tested all API endpoints\n",
    "   4. Benchmarked API performance\n",
    "   5. Demonstrated Python client usage\n",
    "   6. Reviewed Docker deployment options\n",
    "   7. Simulated real-world integration\n",
    "\n",
    "ğŸ“ PRODUCTION FILES CREATED:\n",
    "   models/production/\n",
    "   â”œâ”€â”€ model.joblib           # Production model\n",
    "   â”œâ”€â”€ preprocessor.joblib    # Preprocessor (if available)\n",
    "   â””â”€â”€ model_metadata.json    # Model metadata\n",
    "\n",
    "ğŸŒ API ENDPOINTS:\n",
    "   Health & Monitoring:\n",
    "   â”œâ”€â”€ GET  /health              â†’ Health check\n",
    "   â”œâ”€â”€ GET  /ready               â†’ Readiness probe\n",
    "   â””â”€â”€ GET  /live                â†’ Liveness probe\n",
    "   \n",
    "   Predictions:\n",
    "   â”œâ”€â”€ POST /api/v1/predict      â†’ Single prediction\n",
    "   â”œâ”€â”€ POST /api/v1/predict/batch â†’ Batch predictions\n",
    "   â”œâ”€â”€ POST /api/v1/predict/quick â†’ Quick prediction\n",
    "   â””â”€â”€ GET  /api/v1/predict/thresholds â†’ Threshold info\n",
    "   \n",
    "   Model Info:\n",
    "   â”œâ”€â”€ GET  /api/v1/model        â†’ Model information\n",
    "   â”œâ”€â”€ GET  /api/v1/model/features â†’ Feature info\n",
    "   â””â”€â”€ POST /api/v1/model/reload â†’ Reload model\n",
    "\n",
    "ğŸ³ DEPLOYMENT OPTIONS:\n",
    "   â€¢ Direct:     python serve_model.py\n",
    "   â€¢ Docker:     docker-compose up -d\n",
    "   â€¢ Production: docker-compose -f ... -f docker-compose.prod.yaml up\n",
    "\n",
    "ğŸ“Š TYPICAL PERFORMANCE:\n",
    "   â€¢ Single prediction:    10-50ms\n",
    "   â€¢ Batch (100 items):    100-200ms\n",
    "   â€¢ Concurrent requests:  50-100 req/sec\n",
    "\"\"\"\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc863992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ \n",
      "\n",
      "                    MONTH 2 COMPLETE!\n",
      "          Applied ML & MLOps Lite - FINISHED\n",
      "\n",
      "ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ \n",
      "\n",
      "\n",
      "Congratulations! You have successfully completed Month 2.\n",
      "\n",
      "ğŸ“š WHAT YOU'VE LEARNED:\n",
      "\n",
      "   Week 5: Supervised Learning 1\n",
      "   â”œâ”€â”€ ML problem framing\n",
      "   â”œâ”€â”€ Train/test splitting\n",
      "   â”œâ”€â”€ Baseline model training\n",
      "   â””â”€â”€ Model evaluation metrics\n",
      "\n",
      "   Week 6: Supervised Learning 2\n",
      "   â”œâ”€â”€ sklearn pipelines\n",
      "   â”œâ”€â”€ Hyperparameter tuning\n",
      "   â”œâ”€â”€ SHAP interpretability\n",
      "   â””â”€â”€ Threshold optimization\n",
      "\n",
      "   Week 7: MLOps Lite\n",
      "   â”œâ”€â”€ FastAPI development\n",
      "   â”œâ”€â”€ REST API design\n",
      "   â”œâ”€â”€ Docker containerization\n",
      "   â””â”€â”€ API testing & documentation\n",
      "\n",
      "ğŸš€ YOUR COMPLETE SYSTEM:\n",
      "\n",
      "   Data â†’ Pipeline â†’ Training â†’ Tuning â†’ API â†’ Deployment\n",
      "            â†‘                                      â†“\n",
      "        (Month 1)                           (Production)\n",
      "\n",
      "ğŸ¯ NEXT STEPS:\n",
      "   â€¢ Deploy to cloud (AWS/GCP/Azure)\n",
      "   â€¢ Add authentication & authorization\n",
      "   â€¢ Set up CI/CD pipeline\n",
      "   â€¢ Implement monitoring & alerting\n",
      "   â€¢ Add A/B testing framework\n",
      "\n",
      "You are now ready for real-world ML projects!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 29: Month 2 Completion\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"ğŸ‰ \" * 20)\n",
    "print(\"\\n\" + \" \" * 20 + \"MONTH 2 COMPLETE!\")\n",
    "print(\" \" * 10 + \"Applied ML & MLOps Lite - FINISHED\")\n",
    "print(\"\\n\" + \"ğŸ‰ \" * 20)\n",
    "\n",
    "completion_message = \"\"\"\n",
    "\n",
    "Congratulations! You have successfully completed Month 2.\n",
    "\n",
    "ğŸ“š WHAT YOU'VE LEARNED:\n",
    "\n",
    "   Week 5: Supervised Learning 1\n",
    "   â”œâ”€â”€ ML problem framing\n",
    "   â”œâ”€â”€ Train/test splitting\n",
    "   â”œâ”€â”€ Baseline model training\n",
    "   â””â”€â”€ Model evaluation metrics\n",
    "\n",
    "   Week 6: Supervised Learning 2\n",
    "   â”œâ”€â”€ sklearn pipelines\n",
    "   â”œâ”€â”€ Hyperparameter tuning\n",
    "   â”œâ”€â”€ SHAP interpretability\n",
    "   â””â”€â”€ Threshold optimization\n",
    "\n",
    "   Week 7: MLOps Lite\n",
    "   â”œâ”€â”€ FastAPI development\n",
    "   â”œâ”€â”€ REST API design\n",
    "   â”œâ”€â”€ Docker containerization\n",
    "   â””â”€â”€ API testing & documentation\n",
    "\n",
    "ğŸš€ YOUR COMPLETE SYSTEM:\n",
    "\n",
    "   Data â†’ Pipeline â†’ Training â†’ Tuning â†’ API â†’ Deployment\n",
    "            â†‘                                      â†“\n",
    "        (Month 1)                           (Production)\n",
    "\n",
    "ğŸ¯ NEXT STEPS:\n",
    "   â€¢ Deploy to cloud (AWS/GCP/Azure)\n",
    "   â€¢ Add authentication & authorization\n",
    "   â€¢ Set up CI/CD pipeline\n",
    "   â€¢ Implement monitoring & alerting\n",
    "   â€¢ Add A/B testing framework\n",
    "\n",
    "You are now ready for real-world ML projects!\n",
    "\n",
    "\"\"\"\n",
    "print(completion_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANUP INSTRUCTIONS\n",
      "============================================================\n",
      "\n",
      "If you started the API server, remember to stop it:\n",
      "\n",
      "OPTION 1: Terminal\n",
      "   Press Ctrl+C in the terminal running serve_model.py\n",
      "\n",
      "OPTION 2: Docker\n",
      "   docker-compose down\n",
      "\n",
      "OPTION 3: Find and Kill Process\n",
      "\n",
      "   Linux/Mac:\n",
      "   $ lsof -i :8000 | grep python | awk '{print $2}' | xargs kill\n",
      "\n",
      "   Windows (PowerShell):\n",
      "   > Get-Process -Id (Get-NetTCPConnection -LocalPort 8000).OwningProcess | Stop-Process\n",
      "\n",
      "CLEANUP COMMANDS:\n",
      "\n",
      "   # Remove Docker containers and images\n",
      "   docker-compose down --rmi all\n",
      "\n",
      "   # Clean Python cache\n",
      "   find . -type d -name __pycache__ -exec rm -rf {} +\n",
      "   find . -type f -name \"*.pyc\" -delete\n",
      "\n",
      "   # Clean output directories (optional)\n",
      "   rm -rf outputs/experiments/*\n",
      "   rm -rf logs/*\n",
      "\n",
      "\n",
      "============================================================\n",
      "END OF WEEK 7 NOTEBOOK\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 30: Cleanup Instructions\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLEANUP INSTRUCTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cleanup_text = \"\"\"\n",
    "If you started the API server, remember to stop it:\n",
    "\n",
    "OPTION 1: Terminal\n",
    "   Press Ctrl+C in the terminal running serve_model.py\n",
    "\n",
    "OPTION 2: Docker\n",
    "   docker-compose down\n",
    "\n",
    "OPTION 3: Find and Kill Process\n",
    "   \n",
    "   Linux/Mac:\n",
    "   $ lsof -i :8000 | grep python | awk '{print $2}' | xargs kill\n",
    "   \n",
    "   Windows (PowerShell):\n",
    "   > Get-Process -Id (Get-NetTCPConnection -LocalPort 8000).OwningProcess | Stop-Process\n",
    "\n",
    "CLEANUP COMMANDS:\n",
    "\n",
    "   # Remove Docker containers and images\n",
    "   docker-compose down --rmi all\n",
    "   \n",
    "   # Clean Python cache\n",
    "   find . -type d -name __pycache__ -exec rm -rf {} +\n",
    "   find . -type f -name \"*.pyc\" -delete\n",
    "   \n",
    "   # Clean output directories (optional)\n",
    "   rm -rf outputs/experiments/*\n",
    "   rm -rf logs/*\n",
    "\"\"\"\n",
    "print(cleanup_text)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"END OF WEEK 7 NOTEBOOK\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
