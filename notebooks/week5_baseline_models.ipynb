{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2325e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "ML Configuration loaded!\n",
      "Target column: no_show\n",
      "Primary metric: roc_auc\n",
      "Data shape: (110527, 52)\n",
      "\n",
      "Target distribution:\n",
      "no_show\n",
      "0    0.798\n",
      "1    0.202\n",
      "Name: proportion, dtype: float64\n",
      "==================================================\n",
      "TARGET VARIABLE ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Target: no_show\n",
      "Class distribution:\n",
      "no_show\n",
      "0    88208\n",
      "1    22319\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class imbalance ratio: 1:4.0\n",
      "==================================================\n",
      "FEATURE AVAILABILITY CHECK\n",
      "==================================================\n",
      "\n",
      "Numeric features: 8/8\n",
      "  Available: ['age', 'lead_days', 'patient_total_appointments', 'patient_previous_noshows', 'patient_historical_noshow_rate', 'neighborhood_noshow_rate', 'neighborhood_avg_age', 'schedule_hour']\n",
      "\n",
      "Categorical features: 6/6\n",
      "  Available: ['gender', 'age_group', 'lead_time_category', 'appointment_weekday', 'neighborhood_risk', 'health_risk_category']\n",
      "\n",
      "Binary features: 16/16\n",
      "  Available: ['scholarship', 'hypertension', 'diabetes', 'alcoholism', 'sms_received', 'is_first_appointment', 'is_monday', 'is_friday', 'is_weekend', 'has_chronic_condition', 'has_disability', 'young_long_lead', 'monday_long_lead', 'first_young', 'high_risk_no_sms', 'elderly_chronic']\n",
      "\n",
      "üìä Data Split Summary:\n",
      "  Training samples: 88,421\n",
      "  Test samples: 22,106\n",
      "  Features: 30\n",
      "\n",
      "üîÑ After Preprocessing:\n",
      "  Training shape: (88421, 44)\n",
      "  Test shape: (22106, 44)\n",
      "  Number of features: 44\n",
      "\n",
      "üìã Sample Feature Names (after encoding):\n",
      "  1. numeric__age\n",
      "  2. numeric__lead_days\n",
      "  3. numeric__patient_total_appointments\n",
      "  4. numeric__patient_previous_noshows\n",
      "  5. numeric__patient_historical_noshow_rate\n",
      "  6. numeric__neighborhood_noshow_rate\n",
      "  7. numeric__neighborhood_avg_age\n",
      "  8. numeric__schedule_hour\n",
      "  9. categorical__gender_M\n",
      "  10. categorical__age_group_Child\n",
      "  11. categorical__age_group_Middle Age\n",
      "  12. categorical__age_group_Senior\n",
      "  13. categorical__age_group_Teen\n",
      "  14. categorical__age_group_Young Adult\n",
      "  15. categorical__lead_time_category_15-30 days\n",
      "  ... and 29 more\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 182\u001b[39m\n\u001b[32m    179\u001b[39m trainer = ModelTrainer(ml_config)\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# Train all baseline models with cross-validation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m models = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_baseline_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# Compare models based on cross-validation\u001b[39;00m\n\u001b[32m    186\u001b[39m comparison = trainer.compare_models()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\src\\ml\\train.py:269\u001b[39m, in \u001b[36mModelTrainer.train_baseline_models\u001b[39m\u001b[34m(self, X_train, y_train, cv_folds)\u001b[39m\n\u001b[32m    265\u001b[39m start_time = datetime.now()\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    268\u001b[39m     \u001b[38;5;66;03m# Run cross-validation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     cv_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Fit on full training data\u001b[39;00m\n\u001b[32m    272\u001b[39m     model.fit(X_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\src\\ml\\train.py:207\u001b[39m, in \u001b[36mModelTrainer._run_cross_validation\u001b[39m\u001b[34m(self, model, X, y, cv)\u001b[39m\n\u001b[32m    197\u001b[39m scoring_map = {\n\u001b[32m    198\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    199\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m     \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    203\u001b[39m }\n\u001b[32m    205\u001b[39m sklearn_scoring = {k: scoring_map.get(k, k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m scoring}\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43msklearn_scoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    213\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\model_selection\\_validation.py:399\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "\"\"\"\n",
    "# Week 5: Baseline ML Models for No-Show Prediction\n",
    "\n",
    "## Learning Objectives\n",
    "- Frame ML problems for business applications\n",
    "- Split data with stratification\n",
    "- Train baseline classification models\n",
    "- Evaluate models with appropriate metrics\n",
    "- Compare models and select the best\n",
    "\n",
    "## Business Context\n",
    "We're building on our Month 1 analysis to create ML models that predict\n",
    "which patients are likely to miss their appointments (no-show).\n",
    "\n",
    "**Key Business Questions:**\n",
    "1. Which patients should we prioritize for intervention?\n",
    "2. How accurately can we predict no-shows?\n",
    "3. What is the potential business impact of accurate predictions?\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 1. Setup and Data Loading\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Our modules\n",
    "from src.ml.preprocessing import NoShowPreprocessor\n",
    "from src.ml.train import ModelTrainer\n",
    "from src.ml.evaluate import ModelEvaluator\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "\n",
    "# %%\n",
    "# Load configuration\n",
    "with open('../config/ml_config.yaml', 'r') as f:\n",
    "    ml_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"ML Configuration loaded!\")\n",
    "print(f\"Target column: {ml_config['ml_project']['target_column']}\")\n",
    "print(f\"Primary metric: {ml_config['evaluation']['primary_metric']}\")\n",
    "\n",
    "# %%\n",
    "# Load processed data from Month 1\n",
    "data_path = '../data/processed/appointments_features.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['no_show'].value_counts(normalize=True).round(3))\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 2. Data Exploration for ML\n",
    "\n",
    "Before training models, let's understand our data from an ML perspective.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Check for our target variable and key features\n",
    "print(\"=\" * 50)\n",
    "print(\"TARGET VARIABLE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "target_col = 'no_show'\n",
    "print(f\"\\nTarget: {target_col}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(df[target_col].value_counts())\n",
    "print(f\"\\nClass imbalance ratio: 1:{(1 - df[target_col].mean()) / df[target_col].mean():.1f}\")\n",
    "\n",
    "# %%\n",
    "# Check available features\n",
    "print(\"=\" * 50)\n",
    "print(\"FEATURE AVAILABILITY CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "feature_config = ml_config['features']\n",
    "\n",
    "# Check numeric features\n",
    "numeric_available = [f for f in feature_config['numeric'] if f.lower() in [c.lower() for c in df.columns]]\n",
    "print(f\"\\nNumeric features: {len(numeric_available)}/{len(feature_config['numeric'])}\")\n",
    "print(f\"  Available: {numeric_available}\")\n",
    "\n",
    "# Check categorical features  \n",
    "categorical_available = [f for f in feature_config['categorical'] if f.lower() in [c.lower() for c in df.columns]]\n",
    "print(f\"\\nCategorical features: {len(categorical_available)}/{len(feature_config['categorical'])}\")\n",
    "print(f\"  Available: {categorical_available}\")\n",
    "\n",
    "# Check binary features\n",
    "binary_available = [f for f in feature_config['binary'] if f.lower() in [c.lower() for c in df.columns]]\n",
    "print(f\"\\nBinary features: {len(binary_available)}/{len(feature_config['binary'])}\")\n",
    "print(f\"  Available: {binary_available}\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 3. Data Preprocessing\n",
    "\n",
    "We'll use our `NoShowPreprocessor` class to:\n",
    "1. Select features based on configuration\n",
    "2. Split into train/test sets with stratification\n",
    "3. Build sklearn preprocessing pipeline\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Initialize preprocessor\n",
    "preprocessor = NoShowPreprocessor(ml_config)\n",
    "\n",
    "# Prepare data (select features and split)\n",
    "X_train, X_test, y_train, y_test = preprocessor.prepare_data(df)\n",
    "\n",
    "print(f\"\\nüìä Data Split Summary:\")\n",
    "print(f\"  Training samples: {len(X_train):,}\")\n",
    "print(f\"  Test samples: {len(X_test):,}\")\n",
    "print(f\"  Features: {X_train.shape[1]}\")\n",
    "\n",
    "# %%\n",
    "# Fit and transform training data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train, y_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"\\nüîÑ After Preprocessing:\")\n",
    "print(f\"  Training shape: {X_train_transformed.shape}\")\n",
    "print(f\"  Test shape: {X_test_transformed.shape}\")\n",
    "print(f\"  Number of features: {len(preprocessor.feature_names_)}\")\n",
    "\n",
    "# %%\n",
    "# Show some transformed feature names\n",
    "print(\"\\nüìã Sample Feature Names (after encoding):\")\n",
    "for i, name in enumerate(preprocessor.feature_names_[:15]):\n",
    "    print(f\"  {i+1}. {name}\")\n",
    "if len(preprocessor.feature_names_) > 15:\n",
    "    print(f\"  ... and {len(preprocessor.feature_names_) - 15} more\")\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 4. Train Baseline Models\n",
    "\n",
    "Now we'll train several baseline models:\n",
    "- **Logistic Regression**: Interpretable linear model\n",
    "- **Decision Tree**: Simple non-linear model\n",
    "- **Random Forest**: Ensemble of decision trees\n",
    "- **Gradient Boosting**: Sequential ensemble method\n",
    "- **XGBoost**: Optimized gradient boosting (if available)\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Initialize trainer\n",
    "trainer = ModelTrainer(ml_config)\n",
    "\n",
    "# Train all baseline models with cross-validation\n",
    "models = trainer.train_baseline_models(X_train_transformed, y_train)\n",
    "\n",
    "# %%\n",
    "# Compare models based on cross-validation\n",
    "comparison = trainer.compare_models()\n",
    "print(\"\\nüìä Model Comparison (Cross-Validation Results):\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 5. Evaluate on Test Set\n",
    "\n",
    "Now let's evaluate our trained models on the held-out test set.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluator(ml_config)\n",
    "\n",
    "# Evaluate all models on test set\n",
    "results = evaluator.evaluate_all(models, X_test_transformed, y_test)\n",
    "\n",
    "# %%\n",
    "# Get comparison table\n",
    "eval_table = evaluator.get_comparison_table()\n",
    "print(\"\\nüìä Test Set Performance:\")\n",
    "print(eval_table.to_string(index=False))\n",
    "\n",
    "# %%\n",
    "# Visualize ROC curves\n",
    "fig = evaluator.plot_roc_curves(save=False)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Visualize Precision-Recall curves\n",
    "fig = evaluator.plot_precision_recall_curves(save=False)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Visualize confusion matrices\n",
    "fig = evaluator.plot_confusion_matrices(save=False)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Metrics comparison bar chart\n",
    "fig = evaluator.plot_metrics_comparison(save=False)\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 6. Feature Importance Analysis\n",
    "\n",
    "Understanding which features are most predictive helps with:\n",
    "- Model interpretability\n",
    "- Feature engineering insights\n",
    "- Business understanding\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Get best model\n",
    "best_name, best_model = trainer.get_best_model()\n",
    "print(f\"Best model: {best_name}\")\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = trainer.get_feature_importance(best_name, preprocessor.feature_names_)\n",
    "\n",
    "# Plot top 20 features\n",
    "fig = evaluator.plot_feature_importance(importance_df, best_name, top_n=20, save=False)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Print top 10 features\n",
    "print(f\"\\nüîù Top 10 Most Important Features ({best_name}):\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 7. Business Impact Analysis\n",
    "\n",
    "Let's translate our model performance into business terms.\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Calculate business impact\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "impact = evaluator.calculate_business_impact(y_test.values, y_pred, best_name)\n",
    "\n",
    "# %%\n",
    "# Visualize business impact\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix with business context\n",
    "ax1 = axes[0]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "            xticklabels=['Show', 'No-Show'],\n",
    "            yticklabels=['Show', 'No-Show'])\n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('Actual')\n",
    "ax1.set_title(f'{best_name} - Confusion Matrix')\n",
    "\n",
    "# Cost comparison\n",
    "ax2 = axes[1]\n",
    "costs = [\n",
    "    ('Baseline\\n(No Model)', impact['baseline_cost']),\n",
    "    ('Model Cost', impact['model_cost']),\n",
    "    ('Savings', impact['gross_savings'])\n",
    "]\n",
    "ax2.bar([c[0] for c in costs], [c[1] for c in costs], \n",
    "        color=['red', 'orange', 'green'])\n",
    "ax2.set_ylabel('Cost ($)')\n",
    "ax2.set_title('Business Impact Analysis')\n",
    "for i, (_, val) in enumerate(costs):\n",
    "    ax2.text(i, val + 500, f'${val:,.0f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## 8. Summary and Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Print summary\n",
    "print(\"=\" * 60)\n",
    "print(\"WEEK 5 SUMMARY: BASELINE MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Best Model: {best_name}\")\n",
    "best_result = results[best_name]\n",
    "print(f\"\\nüìà Performance Metrics:\")\n",
    "print(f\"  ‚Ä¢ ROC-AUC: {best_result.roc_auc:.4f}\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {best_result.accuracy:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {best_result.precision:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall: {best_result.recall:.4f}\")\n",
    "print(f\"  ‚Ä¢ F1 Score: {best_result.f1:.4f}\")\n",
    "\n",
    "print(f\"\\nüí∞ Business Impact:\")\n",
    "print(f\"  ‚Ä¢ Appointments in test set: {len(y_test):,}\")\n",
    "print(f\"  ‚Ä¢ True No-Shows identified: {impact['true_positives']}\")\n",
    "print(f\"  ‚Ä¢ Missed No-Shows: {impact['false_negatives']}\")\n",
    "print(f\"  ‚Ä¢ Estimated prevented no-shows: {impact['prevented_noshows']}\")\n",
    "print(f\"  ‚Ä¢ Estimated net savings: ${impact['net_savings']:,.0f}\")\n",
    "\n",
    "print(\"\\nüîù Top 5 Predictive Features:\")\n",
    "for i, row in importance_df.head(5).iterrows():\n",
    "    print(f\"  {i+1}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NEXT STEPS (Week 6):\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. Hyperparameter tuning with GridSearchCV\n",
    "2. Feature engineering based on importance analysis\n",
    "3. Model interpretability with SHAP\n",
    "4. Cross-validation strategy refinement\n",
    "5. Threshold optimization for business objectives\n",
    "\"\"\")\n",
    "\n",
    "# %%\n",
    "# Save models and results\n",
    "output_dir = Path('../models/baseline')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save preprocessor\n",
    "preprocessor.save(output_dir / 'preprocessor.joblib')\n",
    "\n",
    "# Save models\n",
    "trainer.save_models(output_dir)\n",
    "\n",
    "# Save evaluation results\n",
    "results_dir = Path('../outputs/experiments') / trainer.experiment_id\n",
    "evaluator.save_results(results_dir)\n",
    "\n",
    "print(f\"\\n‚úÖ All artifacts saved!\")\n",
    "print(f\"  Models: {output_dir}\")\n",
    "print(f\"  Results: {results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
