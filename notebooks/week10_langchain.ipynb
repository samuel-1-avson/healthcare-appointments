{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e2a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Executable: c:\\Python314\\python.exe\n",
      "Python Version: 3.14.0 (tags/v3.14.0:ebf955d, Oct  7 2025, 10:15:03) [MSC v.1944 64 bit (AMD64)]\n",
      "LangChain Version: 0.3.0\n",
      "OpenAI API Key: ‚ùå\n",
      "Anthropic API Key: ‚ùå\n",
      "LangChain imports: ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Roaming\\Python\\Python314\\site-packages\\langchain_core\\utils\\pydantic.py:79: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1  # type: ignore[assignment]\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Environment Check\n",
    "print(f\"Python Executable: {sys.executable}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import langchain\n",
    "    print(f\"LangChain Version: {langchain.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è LangChain not found. Installing dependencies...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(project_root / \"requirements.txt\")])\n",
    "    print(\"Dependencies installed. Please restart the kernel.\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Verify setup\n",
    "print(\"OpenAI API Key:\", \"‚úÖ\" if os.getenv(\"OPENAI_API_KEY\") else \"‚ùå\")\n",
    "print(\"Anthropic API Key:\", \"‚úÖ\" if os.getenv(\"ANTHROPIC_API_KEY\") else \"‚ùå\")\n",
    "\n",
    "# LangChain imports\n",
    "try:\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_core.runnables import RunnablePassthrough\n",
    "    print(\"LangChain imports: ‚úÖ\")\n",
    "except ImportError as e:\n",
    "    print(f\"LangChain imports failed: {e}\")\n",
    "    print(\"Please ensure you are running in the correct virtual environment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Model: llama3\n",
      "Tracing Enabled: False\n",
      "\n",
      "Model Type: ChatOllama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\src\\llm\\langchain_config.py:85: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  return ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Initialize LangChain Config\n",
    "\"\"\"\n",
    "## Part 1: LangChain Fundamentals\n",
    "\n",
    "Let's start with basic LangChain concepts.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.langchain_config import get_langchain_settings, get_chat_model\n",
    "\n",
    "settings = get_langchain_settings()\n",
    "print(f\"Default Model: {settings.default_model}\")\n",
    "print(f\"Tracing Enabled: {settings.langchain.tracing_enabled}\")\n",
    "\n",
    "# Create a model\n",
    "model = get_chat_model()\n",
    "print(f\"\\nModel Type: {type(model).__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Chain Output:\n",
      "Here are three reasons why a high-risk patient might miss an appointment:\n",
      "\n",
      "‚Ä¢ **Transportation issues**: Patients who are at high risk may not have access to reliable transportation, such as a car or public transportation, which can make it difficult for them to get to appointments. This is particularly true for patients with mobility impairments or those living in rural areas where public transportation options may be limited.\n",
      "\n",
      "‚Ä¢ **Complex health needs and appointment overload**: Patients who are high-risk often have multiple chronic conditions that require ongoing care. As a result, they may have a heavy schedule of appointments with various healthcare providers, which can lead to feelings of overwhelm and fatigue. This can cause them to miss or cancel appointments if they feel like they're being pulled in too many directions.\n",
      "\n",
      "‚Ä¢ **Social determinants of health**: Patients who are high-risk often face significant social and economic challenges that can impact their ability to keep appointments. For example, they may be struggling with food insecurity, housing instability, or unemployment, which can make it difficult for them to take time off work or find childcare to attend an appointment. These underlying issues can create a sense of urgency and priority around other aspects of life, causing healthcare appointments to fall by the wayside.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Simple Chain with LCEL\n",
    "\"\"\"\n",
    "### LangChain Expression Language (LCEL)\n",
    "\n",
    "LCEL uses the pipe operator (|) to chain components.\n",
    "\"\"\"\n",
    "\n",
    "# Simple prompt -> model -> output chain\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explain why a {risk_level} risk patient might miss their appointment. \"\n",
    "    \"Give 3 reasons in bullet points.\"\n",
    ")\n",
    "\n",
    "# Build chain with LCEL\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# Test it\n",
    "result = chain.invoke({\"risk_level\": \"high\"})\n",
    "print(\"Simple Chain Output:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Explanation:\n",
      "==================================================\n",
      "**Summary**: This patient has a HIGH risk of not showing up to their appointment (72% probability), indicating that proactive outreach is recommended.\n",
      "\n",
      "**Top Factors Increasing No-show Risk**:\n",
      "\n",
      "1. The patient has a history of no-shows, with a previous rate of 20%.\n",
      "2. They have diabetes, which may require more complex care and potentially lead to scheduling conflicts.\n",
      "3. There is no SMS reminder enabled for this appointment, which could contribute to the patient forgetting or not receiving timely reminders.\n",
      "\n",
      "**Protective Factors Reducing Risk**: The patient has a scholarship/welfare program, which may indicate that they are actively seeking healthcare services and have a vested interest in attending appointments.\n",
      "\n",
      "**Actionable Recommendations**:\n",
      "\n",
      "1. Send a SMS reminder 3-5 days prior to the appointment to ensure the patient receives timely reminders.\n",
      "2. Consider offering flexible scheduling options or accommodations for patients with diabetes to reduce potential conflicts.\n",
      "3. Proactively reach out to the patient via phone or email to confirm their attendance and address any concerns they may have.\n",
      "\n",
      "**Prediction Confidence**: The model's confidence level is moderate, indicating that while there are several factors contributing to the high risk of no-shows, there is still some uncertainty involved.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Using Our Custom Chains\n",
    "\"\"\"\n",
    "## Part 2: Healthcare Chains\n",
    "\n",
    "Using our pre-built chains for healthcare tasks.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.chains import RiskExplanationChain, InterventionChain\n",
    "\n",
    "# Create explanation chain\n",
    "explanation_chain = RiskExplanationChain()\n",
    "\n",
    "# Explain a prediction\n",
    "explanation = explanation_chain.explain(\n",
    "    probability=0.72,\n",
    "    risk_tier=\"HIGH\",\n",
    "    patient_data={\n",
    "        \"age\": 35,\n",
    "        \"gender\": \"F\",\n",
    "        \"lead_days\": 14,\n",
    "        \"sms_received\": 0,\n",
    "        \"appointment_weekday\": \"Monday\",\n",
    "        \"hypertension\": 0,\n",
    "        \"diabetes\": 1,\n",
    "        \"scholarship\": 1\n",
    "    },\n",
    "    patient_history={\n",
    "        \"total_appointments\": 5,\n",
    "        \"noshow_rate\": 0.20\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Prediction Explanation:\")\n",
    "print(\"=\" * 50)\n",
    "print(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention Recommendation:\n",
      "==================================================\n",
      "Here is a comprehensive intervention plan for this appointment:\n",
      "\n",
      "**PRIMARY ACTION**: Phone call + double SMS reminder\n",
      "\n",
      "**TIMELINE**: Call today before 2pm, and send the first SMS reminder at 10am, with the second SMS reminder at 8pm.\n",
      "\n",
      "**PHONE SCRIPT**:\n",
      "\"Hi [Patient's Name], this is [Your Name] from [Clinic/Hospital]. I just wanted to touch base and confirm that you're still planning on coming in for your appointment tomorrow. We've had a few no-shows recently, and I want to make sure we can accommodate you if needed. If there are any changes or concerns, please let me know as soon as possible. We're looking forward to seeing you tomorrow!\"\n",
      "\n",
      "**SMS MESSAGE**: \"Hi [Patient's Name], just a friendly reminder that your appointment is tomorrow at [time]. Please confirm if everything is still on track. Looking forward to seeing you then! - [Your Name]\"\n",
      "\n",
      "**BACKUP PLAN**: If the patient doesn't respond, schedule a confirmation call for 9am the next day and have a staff member make the call.\n",
      "\n",
      "**SUCCESS INDICATOR**: The intervention is considered successful if the patient confirms their attendance or responds to one of the phone calls/SMS reminders.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Intervention Chain\n",
    "\"\"\"\n",
    "### Intervention Recommendations\n",
    "\"\"\"\n",
    "\n",
    "intervention_chain = InterventionChain()\n",
    "\n",
    "recommendation = intervention_chain.recommend(\n",
    "    probability=0.78,\n",
    "    risk_tier=\"HIGH\",\n",
    "    patient_data={\n",
    "        \"age\": 28,\n",
    "        \"lead_days\": 21,\n",
    "        \"is_first_appointment\": False,\n",
    "        \"previous_noshows\": 2,\n",
    "        \"sms_received\": 1,\n",
    "        \"neighbourhood\": \"CENTRO\"\n",
    "    },\n",
    "    constraints={\n",
    "        \"staff_availability\": \"Limited (2 staff members today)\",\n",
    "        \"phone_slots\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Intervention Recommendation:\")\n",
    "print(\"=\" * 50)\n",
    "print(recommendation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: predict_noshow\n",
      "Tool Description: \n",
      "    Predict whether a patient will miss their healthcare appointment.\n",
      "    \n",
      "    Use this tool when you need to:\n",
      "    - Get a no-show risk prediction for a patient\n",
      "    - Assess appointment risk levels\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Using Tools\n",
    "\"\"\"\n",
    "## Part 3: Tools\n",
    "\n",
    "Tools allow the LLM to take actions, like calling your prediction API.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.tools import PredictionTool\n",
    "\n",
    "# Create the prediction tool\n",
    "prediction_tool = PredictionTool(api_base_url=\"http://localhost:8000\")\n",
    "\n",
    "print(\"Tool Name:\", prediction_tool.name)\n",
    "print(\"Tool Description:\", prediction_tool.description[:200])\n",
    "\n",
    "# Test the tool (requires API to be running)\n",
    "# Uncomment if your API is running:\n",
    "# result = prediction_tool._run(age=45, gender=\"M\", lead_days=10, sms_received=1)\n",
    "# print(\"\\nTool Result:\")\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created session: a14410b6-9b6c-4670-a25a-64b075233cfc\n",
      "\n",
      "Conversation History (4 messages):\n",
      "  User: What makes a patient high risk?...\n",
      "  AI: High risk patients typically have: long lead times, history ...\n",
      "  User: How should I contact them?...\n",
      "  AI: For high-risk patients, I recommend a phone call 48-72 hours...\n",
      "\n",
      "Memory Stats: {'active_sessions': 1, 'memory_type': 'buffer_window', 'max_messages_per_session': 10, 'session_timeout_minutes': 60.0}\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Conversation Memory\n",
    "\"\"\"\n",
    "## Part 4: Conversation Memory\n",
    "\n",
    "Memory allows multi-turn conversations with context.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.memory import ConversationMemoryManager\n",
    "\n",
    "# Create memory manager\n",
    "memory_manager = ConversationMemoryManager(\n",
    "    memory_type=\"buffer_window\",\n",
    "    max_messages=10\n",
    ")\n",
    "\n",
    "# Create a session\n",
    "session_id = memory_manager.create_session()\n",
    "print(f\"Created session: {session_id}\")\n",
    "\n",
    "# Add some conversation turns\n",
    "memory_manager.add_exchange(\n",
    "    session_id,\n",
    "    user_message=\"What makes a patient high risk?\",\n",
    "    ai_message=\"High risk patients typically have: long lead times, history of no-shows, and no SMS reminders enabled.\"\n",
    ")\n",
    "\n",
    "memory_manager.add_exchange(\n",
    "    session_id,\n",
    "    user_message=\"How should I contact them?\",\n",
    "    ai_message=\"For high-risk patients, I recommend a phone call 48-72 hours before the appointment.\"\n",
    ")\n",
    "\n",
    "# View history\n",
    "history = memory_manager.get_conversation_messages(session_id)\n",
    "print(f\"\\nConversation History ({len(history)} messages):\")\n",
    "for msg in history:\n",
    "    role = \"User\" if msg.type == \"human\" else \"AI\"\n",
    "    print(f\"  {role}: {msg.content[:60]}...\")\n",
    "\n",
    "# Get stats\n",
    "print(\"\\nMemory Stats:\", memory_manager.get_stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-turn Conversation:\n",
      "==================================================\n",
      "\n",
      "User: What is a no-show in healthcare?\n",
      "Assistant: In the healthcare setting, a no-show refers to a patient who fails to attend an appointment without prior cancellation or rescheduling. This can be frustrating and wasteful, as it takes time and resou...\n",
      "\n",
      "User: Why is it a problem?\n",
      "Assistant: No-shows can be problematic for several reasons:\n",
      "\n",
      "1. **Wasted resources**: Healthcare providers invest time, staff, and facilities in preparing for each appointment. When a patient doesn't show up, th...\n",
      "\n",
      "User: What can we do about high-risk patients?\n",
      "Assistant: High-risk patients are a great concern when it comes to reducing no-shows! As your healthcare appointment assistant, I'd recommend the following strategies:\n",
      "\n",
      "1. **Proactive outreach**: Reach out to th...\n",
      "\n",
      "\n",
      "Total exchanges: 3\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Conversation Chain with Memory\n",
    "\"\"\"\n",
    "### Conversation Chain\n",
    "\n",
    "Chain that maintains context across messages.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.chains import ConversationChain\n",
    "\n",
    "conv_chain = ConversationChain()\n",
    "\n",
    "# Create session\n",
    "session = conv_chain.create_session()\n",
    "\n",
    "# Multi-turn conversation\n",
    "responses = []\n",
    "\n",
    "messages = [\n",
    "    \"What is a no-show in healthcare?\",\n",
    "    \"Why is it a problem?\",\n",
    "    \"What can we do about high-risk patients?\"\n",
    "]\n",
    "\n",
    "print(\"Multi-turn Conversation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for msg in messages:\n",
    "    response = conv_chain.chat(session, msg)\n",
    "    responses.append(response)\n",
    "    print(f\"\\nUser: {msg}\")\n",
    "    print(f\"Assistant: {response[:200]}...\")\n",
    "\n",
    "# View full history\n",
    "history = conv_chain.get_history(session)\n",
    "print(f\"\\n\\nTotal exchanges: {len(history) // 2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tool calling not supported (), falling back to ReAct agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent initialized with tools: ['predict_noshow', 'batch_predict_noshows']\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Healthcare Agent\n",
    "\"\"\"\n",
    "## Part 5: Agents\n",
    "\n",
    "Agents can autonomously decide when to use tools.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.agents import HealthcareAgent, create_healthcare_agent\n",
    "\n",
    "# Create agent (with verbose mode to see tool calls)\n",
    "agent = create_healthcare_agent(verbose=True)\n",
    "\n",
    "# Create session\n",
    "agent_session = agent.create_session()\n",
    "\n",
    "print(\"Agent initialized with tools:\", [t.name for t in agent.tools])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Interactions:\n",
      "==================================================\n",
      "\n",
      "üìù User: What's a no-show?\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agent error: 3 validation errors for PredictionInput\n",
      "age\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='age, gender, lead_days', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing\n",
      "gender\n",
      "  Field required [type=missing, input_value={'age': 'age, gender, lead_days'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "lead_days\n",
      "  Field required [type=missing, input_value={'age': 'age, gender, lead_days'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mLet's start by thinking about what a no-show is.\n",
      "\n",
      "Action: predict_noshow\n",
      "Action Input: age, gender, lead_days\u001b[0m   ‚ö†Ô∏è Error (API might not be running): 3 validation errors for PredictionInput\n",
      "age\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='age, gender, lead_days', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing\n",
      "gender\n",
      "  Field required [type=missing, input_value={'age': 'age, gender, lead_days'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "lead_days\n",
      "  Field required [type=missing, input_value={'age': 'age, gender, lead_days'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "\n",
      "üìù User: A 55-year-old male patient has an appointment in 3 weeks. He's missed 2 appointments before. What's his risk?\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agent error: 3 validation errors for PredictionInput\n",
      "age\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value=\"age=55, gender=male, lea...d previous_no_shows=2\\n\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing\n",
      "gender\n",
      "  Field required [type=missing, input_value={'age': \"age=55, gender=m... previous_no_shows=2\\n\"}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "lead_days\n",
      "  Field required [type=missing, input_value={'age': \"age=55, gender=m... previous_no_shows=2\\n\"}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mLet's get started!\n",
      "\n",
      "Thought: To determine this patient's no-show risk, I'll use the predict_noshow tool.\n",
      "\n",
      "Action: predict_noshow\n",
      "Action Input: age=55, gender=male, lead_days=21 (since it's 3 weeks until the appointment), and previous_no_shows=2\n",
      "\u001b[0m   ‚ö†Ô∏è Error (API might not be running): 3 validation errors for PredictionInput\n",
      "age\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value=\"age=55, gender=male, lea...d previous_no_shows=2\\n\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing\n",
      "gender\n",
      "  Field required [type=missing, input_value={'age': \"age=55, gender=m... previous_no_shows=2\\n\"}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "lead_days\n",
      "  Field required [type=missing, input_value={'age': \"age=55, gender=m... previous_no_shows=2\\n\"}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "\n",
      "üìù User: What should we do for high-risk patients?\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agent error: 3 validation errors for PredictionInput\n",
      "age\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='age, gender, lead_days (...able for the patient)\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing\n",
      "gender\n",
      "  Field required [type=missing, input_value={'age': 'age, gender, lea...ble for the patient)\\n'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "lead_days\n",
      "  Field required [type=missing, input_value={'age': 'age, gender, lea...ble for the patient)\\n'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI think we need to identify which patients are at a higher risk of missing their appointments and then take steps to mitigate that risk. To do this, I'll use the `predict_noshow` tool.\n",
      "\n",
      "Action: predict_noshow\n",
      "Action Input: age, gender, lead_days (assuming these are available for the patient)\n",
      "\u001b[0m   ‚ö†Ô∏è Error (API might not be running): 3 validation errors for PredictionInput\n",
      "age\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='age, gender, lead_days (...able for the patient)\\n', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing\n",
      "gender\n",
      "  Field required [type=missing, input_value={'age': 'age, gender, lea...ble for the patient)\\n'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "lead_days\n",
      "  Field required [type=missing, input_value={'age': 'age, gender, lea...ble for the patient)\\n'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/missing\n",
      "\n",
      "\n",
      "Agent Stats: {'total_calls': 0, 'total_tool_calls': 0, 'tools_available': ['predict_noshow', 'batch_predict_noshows'], 'active_sessions': 2}\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Agent Interaction (Requires Running API)\n",
    "\"\"\"\n",
    "### Agent Conversation\n",
    "\n",
    "The agent will decide when to call the prediction tool.\n",
    "\"\"\"\n",
    "\n",
    "# Note: This requires your prediction API to be running at localhost:8000\n",
    "\n",
    "# Test messages (some will trigger tool use, some won't)\n",
    "test_messages = [\n",
    "    \"What's a no-show?\",  # General question - no tool needed\n",
    "    \"A 55-year-old male patient has an appointment in 3 weeks. He's missed 2 appointments before. What's his risk?\",  # Will use prediction tool\n",
    "    \"What should we do for high-risk patients?\",  # General advice\n",
    "]\n",
    "\n",
    "print(\"Agent Interactions:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"\\nüìù User: {msg}\\n\")\n",
    "    \n",
    "    try:\n",
    "        result = agent.chat(agent_session, msg)\n",
    "        print(f\"ü§ñ Agent: {result['output'][:300]}...\")\n",
    "        \n",
    "        if result.get('tool_calls'):\n",
    "            print(f\"\\n   üîß Tools used: {[tc['tool'] for tc in result['tool_calls']]}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Error (API might not be running): {e}\")\n",
    "\n",
    "# Agent stats\n",
    "print(\"\\n\\nAgent Stats:\", agent.get_stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Classification:\n",
      "==================================================\n",
      "'What's the risk for a 40-year-old patien...' -> predict\n",
      "'Explain why lead time matters...' -> explain\n",
      "'How should I contact high-risk patients?...' -> intervene\n",
      "'What's the cancellation policy?...' -> policy\n",
      "'Hello, how are you?...' -> general\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Chain Orchestrator\n",
    "\"\"\"\n",
    "## Part 6: Chain Orchestration\n",
    "\n",
    "The orchestrator routes requests to the appropriate chain.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.chains.orchestrator import HealthcareOrchestrator, IntentType\n",
    "\n",
    "orchestrator = HealthcareOrchestrator()\n",
    "\n",
    "# Test intent classification\n",
    "test_queries = [\n",
    "    \"What's the risk for a 40-year-old patient?\",  # PREDICT\n",
    "    \"Explain why lead time matters\",  # EXPLAIN\n",
    "    \"How should I contact high-risk patients?\",  # INTERVENE\n",
    "    \"What's the cancellation policy?\",  # POLICY\n",
    "    \"Hello, how are you?\",  # GENERAL\n",
    "]\n",
    "\n",
    "print(\"Intent Classification:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in test_queries:\n",
    "    intent = orchestrator.classify_intent(query)\n",
    "    print(f\"'{query[:40]}...' -> {intent.value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orchestrated Responses:\n",
      "==================================================\n",
      "\n",
      "üìù Query: What's the risk for a 40-year-old patient?\n",
      "üéØ Intent: predict\n",
      "üí¨ Response: To make a prediction, I need some patient information:\n",
      "\n",
      "**Required:**\n",
      "- Patient age\n",
      "- Days until appointment (lead time)\n",
      "- Gender (M/F)\n",
      "\n",
      "**Optional (improves accuracy):**\n",
      "- SMS reminder enabled?\n",
      "- Pre...\n",
      "\n",
      "üìù Query: Explain why lead time matters\n",
      "üéØ Intent: explain\n",
      "üí¨ Response: Lead time is the amount of time between when an appointment is scheduled and when it actually takes place. In the context of reducing no-shows, lead time is crucial because it allows healthcare staff ...\n",
      "\n",
      "üìù Query: How should I contact high-risk patients?\n",
      "üéØ Intent: intervene\n",
      "üí¨ Response: I can provide intervention recommendations when you share:\n",
      "\n",
      "1. **Risk Level**: HIGH, MEDIUM, or LOW\n",
      "2. **Days until appointment**\n",
      "3. **Patient history** (optional)\n",
      "\n",
      "For batch prioritization, share mul...\n",
      "\n",
      "\n",
      "Orchestrator Stats: {'total_requests': 3, 'intent_distribution': {'predict': 1, 'explain': 1, 'intervene': 1}, 'chains': {'explanation': {'chain_name': 'RiskExplanationChain', 'call_count': 0, 'created_at': '2025-12-04T05:04:16.349466', 'uptime_seconds': 13.940959}, 'intervention': {'chain_name': 'InterventionChain', 'call_count': 0, 'created_at': '2025-12-04T05:04:16.349735', 'uptime_seconds': 13.940698}, 'conversation': {'chain_name': 'EnhancedConversationChain', 'call_count': 0, 'created_at': '2025-12-04T05:04:16.349943', 'uptime_seconds': 13.940495}}}\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Orchestrator in Action\n",
    "\"\"\"\n",
    "### Orchestrated Responses\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nOrchestrated Responses:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in test_queries[:3]:  # First 3 queries\n",
    "    print(f\"\\nüìù Query: {query}\")\n",
    "    \n",
    "    result = orchestrator.process(\n",
    "        message=query,\n",
    "        session_id=\"test-session\"\n",
    "    )\n",
    "    \n",
    "    print(f\"üéØ Intent: {result['intent']}\")\n",
    "    print(f\"üí¨ Response: {result['output'][:200]}...\")\n",
    "\n",
    "# Orchestrator stats\n",
    "print(\"\\n\\nOrchestrator Stats:\", orchestrator.get_stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Metrics Summary:\n",
      "{'total_requests': 0, 'total_tokens': 0, 'prompt_tokens': 0, 'completion_tokens': 0, 'estimated_cost_usd': 0.0, 'avg_latency_ms': 0, 'errors': 0, 'error_rate': 0.0, 'cache_hits': 0, 'cache_hit_rate': 0.0, 'by_model': {}, 'by_chain': {}}\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Tracing and Metrics\n",
    "\"\"\"\n",
    "## Part 7: Tracing & Observability\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.tracing import get_metrics, HealthcareTracingHandler\n",
    "\n",
    "# Get metrics\n",
    "metrics = get_metrics()\n",
    "print(\"LLM Metrics Summary:\")\n",
    "print(metrics.get_summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Testing the API Endpoints\n",
    "\"\"\"\n",
    "## Part 8: API Integration\n",
    "\n",
    "Test the LLM endpoints (requires API to be running).\n",
    "\"\"\"\n",
    "\n",
    "import httpx\n",
    "\n",
    "API_BASE = \"http://localhost:8000\"\n",
    "\n",
    "# Test chat endpoint\n",
    "async def test_chat_endpoint():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.post(\n",
    "            f\"{API_BASE}/api/v1/llm/chat\",\n",
    "            json={\n",
    "                \"message\": \"What factors increase no-show risk?\",\n",
    "                \"session_id\": \"test-api-session\"\n",
    "            }\n",
    "        )\n",
    "        return response.json()\n",
    "\n",
    "# Test explanation endpoint\n",
    "async def test_explain_endpoint():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.post(\n",
    "            f\"{API_BASE}/api/v1/llm/explain\",\n",
    "            json={\n",
    "                \"probability\": 0.65,\n",
    "                \"risk_tier\": \"MEDIUM\",\n",
    "                \"patient_data\": {\n",
    "                    \"age\": 42,\n",
    "                    \"gender\": \"M\",\n",
    "                    \"lead_days\": 10,\n",
    "                    \"sms_received\": 1\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        return response.json()\n",
    "\n",
    "# Uncomment to test (requires running API):\n",
    "# import asyncio\n",
    "# result = asyncio.run(test_chat_endpoint())\n",
    "# print(\"Chat API Response:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Exercise - Custom Chain\n",
    "\"\"\"\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Create a Patient Communication Chain\n",
    "\n",
    "Create a chain that generates patient-friendly appointment reminders.\n",
    "The chain should:\n",
    "- Take appointment details as input\n",
    "- Generate a warm, professional reminder message\n",
    "- Include rescheduling instructions\n",
    "- NOT mention risk predictions\n",
    "\n",
    "Template to complete:\n",
    "\"\"\"\n",
    "\n",
    "REMINDER_TEMPLATE = \"\"\"\n",
    "Create a friendly appointment reminder for this patient.\n",
    "\n",
    "Appointment Details:\n",
    "- Date: {date}\n",
    "- Time: {time}\n",
    "- Provider: {provider}\n",
    "- Location: {location}\n",
    "\n",
    "Patient Name: {patient_name}\n",
    "\n",
    "Write a warm, professional reminder that:\n",
    "1. Confirms the appointment details\n",
    "2. Tells them what to bring\n",
    "3. Provides rescheduling instructions (call {phone})\n",
    "4. Is under 150 words\n",
    "\n",
    "DO NOT mention any risk assessment or predictions.\n",
    "\"\"\"\n",
    "\n",
    "# Your code here:\n",
    "# reminder_prompt = ChatPromptTemplate.from_template(REMINDER_TEMPLATE)\n",
    "# reminder_chain = reminder_prompt | model | StrOutputParser()\n",
    "# \n",
    "# result = reminder_chain.invoke({\n",
    "#     \"date\": \"January 25, 2024\",\n",
    "#     \"time\": \"2:30 PM\",\n",
    "#     \"provider\": \"Dr. Smith\",\n",
    "#     \"location\": \"Main Clinic, Room 204\",\n",
    "#     \"patient_name\": \"John\",\n",
    "#     \"phone\": \"555-0123\"\n",
    "# })\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patient History for P001:\n",
      "- Total Appointments: 10\n",
      "- No-Shows: 2 (20.0%)\n",
      "- Last No-Show: 2023-11-15\n",
      "\n",
      "\n",
      "Patient History for P003:\n",
      "- Total Appointments: 8\n",
      "- No-Shows: 4 (50.0%)\n",
      "- Last No-Show: 2024-01-02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_3528\\416360694.py:43: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(get_patient_history(\"P001\"))\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Exercise - Custom Tool\n",
    "\"\"\"\n",
    "### Exercise 2: Create a Patient History Tool\n",
    "\n",
    "Create a tool that (simulates) looking up patient history.\n",
    "This would connect to your database in production.\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_patient_history(patient_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Look up a patient's appointment history.\n",
    "    \n",
    "    Args:\n",
    "        patient_id: The patient's ID number\n",
    "    \n",
    "    Returns:\n",
    "        Patient history summary including past appointments and no-show rate\n",
    "    \"\"\"\n",
    "    # Simulated database lookup\n",
    "    # In production, this would query your actual database\n",
    "    mock_data = {\n",
    "        \"P001\": {\"total\": 10, \"noshows\": 2, \"last_noshow\": \"2023-11-15\"},\n",
    "        \"P002\": {\"total\": 5, \"noshows\": 0, \"last_noshow\": None},\n",
    "        \"P003\": {\"total\": 8, \"noshows\": 4, \"last_noshow\": \"2024-01-02\"},\n",
    "    }\n",
    "    \n",
    "    if patient_id in mock_data:\n",
    "        data = mock_data[patient_id]\n",
    "        rate = data[\"noshows\"] / data[\"total\"] * 100\n",
    "        return f\"\"\"\n",
    "Patient History for {patient_id}:\n",
    "- Total Appointments: {data['total']}\n",
    "- No-Shows: {data['noshows']} ({rate:.1f}%)\n",
    "- Last No-Show: {data['last_noshow'] or 'Never'}\n",
    "\"\"\"\n",
    "    else:\n",
    "        return f\"No history found for patient {patient_id}\"\n",
    "\n",
    "# Test the tool\n",
    "print(get_patient_history(\"P001\"))\n",
    "print(get_patient_history(\"P003\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### Exercise 3: Create an Enhanced Agent\\n\\nCreate an agent with multiple tools:\\n1. Prediction tool\\n2. Patient history tool\\n3. Intervention recommendation tool\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 17: Exercise - Enhanced Agent\n",
    "\"\"\"\n",
    "### Exercise 3: Create an Enhanced Agent\n",
    "\n",
    "Create an agent with multiple tools:\n",
    "1. Prediction tool\n",
    "2. Patient history tool\n",
    "3. Intervention recommendation tool\n",
    "\"\"\"\n",
    "\n",
    "# Your code here:\n",
    "# tools = [\n",
    "#     PredictionTool(),\n",
    "#     get_patient_history,\n",
    "#     # Add more tools\n",
    "# ]\n",
    "# \n",
    "# enhanced_agent = HealthcareAgent(tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 10 Complete! üéâ\n",
      "\n",
      "Final Metrics:\n",
      "{'total_requests': 0, 'total_tokens': 0, 'prompt_tokens': 0, 'completion_tokens': 0, 'estimated_cost_usd': 0.0, 'avg_latency_ms': 0, 'errors': 0, 'error_rate': 0.0, 'cache_hits': 0, 'cache_hit_rate': 0.0, 'by_model': {}, 'by_chain': {}}\n"
     ]
    }
   ],
   "source": [
    "# Cell 18: Summary and Deliverables\n",
    "\"\"\"\n",
    "## Summary\n",
    "\n",
    "This week you learned:\n",
    "\n",
    "1. **LCEL (LangChain Expression Language)**\n",
    "   - Pipe operator for chaining components\n",
    "   - Prompt | Model | OutputParser pattern\n",
    "\n",
    "2. **Chains**\n",
    "   - RiskExplanationChain: Explains predictions\n",
    "   - InterventionChain: Recommends actions\n",
    "   - ConversationChain: Multi-turn with memory\n",
    "\n",
    "3. **Tools**\n",
    "   - PredictionTool: Calls your ML API\n",
    "   - Custom tools with @tool decorator\n",
    "\n",
    "4. **Memory**\n",
    "   - ConversationMemoryManager\n",
    "   - Buffer and window memory types\n",
    "   - Session management\n",
    "\n",
    "5. **Agents**\n",
    "   - Autonomous tool selection\n",
    "   - HealthcareAgent implementation\n",
    "\n",
    "6. **Orchestration**\n",
    "   - Intent classification\n",
    "   - Routing to appropriate chains\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. ‚úÖ Working explanation chain\n",
    "2. ‚úÖ Working intervention chain  \n",
    "3. ‚úÖ Prediction tool integration\n",
    "4. ‚úÖ Conversation memory\n",
    "5. ‚úÖ Healthcare agent\n",
    "6. üìù Complete exercises 1-3\n",
    "7. üìù Test API endpoints\n",
    "n\n",
    "## Next Week: RAG\n",
    "\n",
    "Week 11 will add:\n",
    "- Document loading and chunking\n",
    "- Vector embeddings\n",
    "- FAISS vector store\n",
    "- Retrieval-augmented generation\n",
    "- Policy Q&A with real documents\n",
    "\"\"\"\n",
    "\n",
    "print(\"Week 10 Complete! üéâ\")\n",
    "print(\"\\nFinal Metrics:\")\n",
    "print(get_metrics().get_summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
