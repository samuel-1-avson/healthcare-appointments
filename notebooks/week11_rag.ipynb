{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3337cedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ‚ùå\n",
      "Found 3 markdown documents\n",
      "  - appointment_policy.md\n",
      "  - intervention_guidelines.md\n",
      "  - reminder_procedures.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Roaming\\Python\\Python314\\site-packages\\langchain_core\\_api\\deprecation.py:27: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "Failed to create embeddings for openai: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n",
      "Falling back to simple hash embeddings\n",
      "Using SimpleHashEmbeddings - NOT suitable for production! Install openai or sentence-transformers for real embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 3 documents\n",
      "Loading stats: {'total_files': 3, 'successful': 3, 'failed': 0, 'by_type': {'markdown': 3}, 'total_documents': 3}\n",
      "\n",
      "--- First Document Preview ---\n",
      "Source: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\data\\documents\\appointment_policy.md\n",
      "Content: data/documents/appointment_policy.md\n",
      "\n",
      "Healthcare Clinic Appointment Policy\n",
      "\n",
      "Effective Date: January 1, 2024 Last Updated: January 15, 2024 Policy Number: AP-2024-001\n",
      "\n",
      "1. Scheduling Appointments\n",
      "\n",
      "1.1 Booking Methods\n",
      "\n",
      "Patients may schedule appointments through the following channels: - Online Portal: Available 24/7 at patient.clinic.com - Phone: Call (555) 123-4567, Monday-Friday 8am-6pm - In Person: Visit our front desk during business hours - Mobile App: Download \"HealthClinic\" from app stores\n",
      "\n",
      "...\n",
      "Created 8 chunks from 3 documents\n",
      "\n",
      "Chunk Analysis:\n",
      "  total_chunks: 8\n",
      "  total_characters: 6679\n",
      "  avg_chunk_size: 834.875\n",
      "  min_chunk_size: 578\n",
      "  max_chunk_size: 977\n",
      "  sources: ['c:\\\\Users\\\\samue\\\\Desktop\\\\NSP\\\\healthcare-appointments\\\\data\\\\documents\\\\reminder_procedures.md', 'c:\\\\Users\\\\samue\\\\Desktop\\\\NSP\\\\healthcare-appointments\\\\data\\\\documents\\\\appointment_policy.md', 'c:\\\\Users\\\\samue\\\\Desktop\\\\NSP\\\\healthcare-appointments\\\\data\\\\documents\\\\intervention_guidelines.md']\n",
      "\n",
      "--- Sample Chunks ---\n",
      "\n",
      "Chunk 1:\n",
      "  Size: 974 chars\n",
      "  Source: appointment_policy.md\n",
      "  Section: N/A\n",
      "  Content: data/documents/appointment_policy.md\n",
      "\n",
      "Healthcare Clinic Appointment Policy\n",
      "\n",
      "Effective Date: January 1, 2024 Last Updated: January 15, 2024 Policy Numb...\n",
      "\n",
      "Chunk 2:\n",
      "  Size: 977 chars\n",
      "  Source: appointment_policy.md\n",
      "  Section: N/A\n",
      "  Content: Same-day appointments are available on a limited basis\n",
      "\n",
      "Urgent care slots are reserved for same-day medical needs\n",
      "\n",
      "2. Cancellation Policy\n",
      "\n",
      "2.1 Cancell...\n",
      "\n",
      "Chunk 3:\n",
      "  Size: 802 chars\n",
      "  Source: appointment_policy.md\n",
      "  Section: N/A\n",
      "  Content: 3.2 Consequences\n",
      "\n",
      "No-Show Count (12 months) Action 1st no-show Verbal reminder of policy 2nd no-show Written warning letter 3rd no-show $75 fee, pre-p...\n",
      "Embeddings Model: {'provider': 'simple', 'model': 'text-embedding-3-small', 'dimension': 'unknown', 'max_tokens': 'unknown', 'cost_per_1k_tokens': 0, 'description': ''}\n",
      "\n",
      "Generated 3 embeddings\n",
      "Embedding dimension: 384\n",
      "\n",
      "Similarity between questions:\n",
      "  'What is the cancellation polic...' vs 'How do I reschedule an appoint...': -0.015\n",
      "  'What is the cancellation polic...' vs 'What happens if I miss my appo...': -0.109\n",
      "  'How do I reschedule an appoint...' vs 'What happens if I miss my appo...': 0.035\n",
      "Vector store created: {'initialized': True, 'store_type': 'faiss', 'metadata': {'created_at': '2025-12-04T05:39:00.379475', 'document_count': 3, 'chunk_count': 8, 'store_type': 'faiss', 'embeddings_model': 'text-embedding-3-small'}, 'embeddings': {'total_embeddings': 3, 'cache_hits': 0, 'api_calls': 1, 'total_tokens_estimated': 26, 'estimated_cost_usd': 0.0, 'errors': 0, 'cache_size': 3, 'cache_hit_rate': 0.0, 'uptime_seconds': 0.072451, 'model_info': {'provider': 'simple', 'model': 'text-embedding-3-small', 'dimension': 'unknown', 'max_tokens': 'unknown', 'cost_per_1k_tokens': 0, 'description': ''}, 'providers_available': {'openai': True, 'azure': True, 'local': True}}}\n",
      "Vector store saved!\n",
      "Query: What happens if a patient misses their appointment?\n",
      "\n",
      "Top 3 Results:\n",
      "--------------------------------------------------\n",
      "\n",
      "1. appointment_policy.md\n",
      "   Section: N/A\n",
      "   Content: 3.2 Consequences\n",
      "\n",
      "No-Show Count (12 months) Action 1st no-show Verbal reminder of policy 2nd no-show Written warning letter 3rd no-show $75 fee, pre-payment required for future visits 4th no-show Revi...\n",
      "\n",
      "2. intervention_guidelines.md\n",
      "   Section: N/A\n",
      "   Content: data/documents/intervention_guidelines.md\n",
      "\n",
      "No-Show Intervention Guidelines\n",
      "\n",
      "Purpose: Reduce patient no-shows through targeted interventions Audience: Patient Access Staff, Care Coordinators Last Updat...\n",
      "\n",
      "3. intervention_guidelines.md\n",
      "   Section: N/A\n",
      "   Content: 2. Intervention Procedures by Risk Level\n",
      "\n",
      "2.1 MINIMAL/LOW Risk (0-40%)\n",
      "\n",
      "Goal: Standard process, maintain good habits\n",
      "\n",
      "Actions: 1. Send standard SMS reminders (48h and 24h) 2. Send email reminder (7 da...\n",
      "Query: What happens if a patient misses their appointment?\n",
      "\n",
      "Results with scores:\n",
      "  Score: 1.9445 - appointment_policy.md\n",
      "  Score: 2.0109 - intervention_guidelines.md\n",
      "  Score: 2.0174 - intervention_guidelines.md\n",
      "  Score: 2.0248 - appointment_policy.md\n",
      "  Score: 2.0470 - reminder_procedures.md\n",
      "Query: What happens if a patient misses their appointment?\n",
      "\n",
      "MMR Results (diverse):\n",
      "\n",
      "1. Unknown section\n",
      "   3.2 Consequences\n",
      "\n",
      "No-Show Count (12 months) Action 1st no-show Verbal reminder of policy 2nd no-show Written warning letter 3rd no-show $75 fee, pre-p...\n",
      "\n",
      "2. Unknown section\n",
      "   data/documents/reminder_procedures.md\n",
      "\n",
      "Appointment Reminder Procedures\n",
      "\n",
      "Document Type: Standard Operating Procedure Department: Patient Access Version...\n",
      "\n",
      "3. Unknown section\n",
      "   data/documents/intervention_guidelines.md\n",
      "\n",
      "No-Show Intervention Guidelines\n",
      "\n",
      "Purpose: Reduce patient no-shows through targeted interventions Audience: ...\n",
      "\n",
      "4. Unknown section\n",
      "   Same-day appointments are available on a limited basis\n",
      "\n",
      "Urgent care slots are reserved for same-day medical needs\n",
      "\n",
      "2. Cancellation Policy\n",
      "\n",
      "2.1 Cancell...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\src\\llm\\langchain_config.py:85: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  return ChatOllama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Chain Responses:\n",
      "============================================================\n",
      "\n",
      "üìù Q: What is the no-show policy?\n",
      "\n",
      "üí¨ A: According to the provided policy context, a \"no-show\" occurs when a patient:\n",
      "\n",
      "* Fails to arrive for their scheduled appointment (Document 3: appointment_policy.md, section 3.1 Definition)\n",
      "* Arrives more than 15 minutes late without prior notice (Document 3: appointment_policy.md, section 3.1 Definition)\n",
      "* Does not cancel or reschedule before the appointment time (Document 3: appointment_policy.md,...\n",
      "\n",
      "üìö Sources: 4 documents\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Q: How many reminders do patients receive before their appointment?\n",
      "\n",
      "üí¨ A: I don't have information about that in the available policies. The provided context only discusses appointment scheduling, rescheduling, and no-show policies, but it does not mention the number of reminders patients receive before their appointment....\n",
      "\n",
      "üìö Sources: 4 documents\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Q: What should staff do for high-risk patients?\n",
      "\n",
      "üí¨ A: According to the provided policy context, for high-risk patients, staff should:\n",
      "\n",
      "* Add a phone call at 72 hours before appointment (Reminder Schedule > High-Risk Patient Protocol)\n",
      "* Increase SMS reminders to include a 72-hour reminder (Reminder Schedule > High-Risk Patient Protocol)\n",
      "* Enable a 2-hour reminder automatically (Reminder Schedule > High-Risk Patient Protocol)\n",
      "* Flag for staff follow-up...\n",
      "\n",
      "üìö Sources: 4 documents\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Q: Can no-show fees be waived?\n",
      "\n",
      "üí¨ A: According to the provided policy context, there is no explicit mention of waiving no-show fees. However, it does specify that a $75 fee will be charged for the 3rd no-show (Section 3.2 Consequences).\n",
      "\n",
      "It's possible that patients may appeal no-show determinations and request a waiver, but this would require submitting a written appeal within 14 days, providing supporting documentation, meeting with...\n",
      "\n",
      "üìö Sources: 4 documents\n",
      "------------------------------------------------------------\n",
      "Session created: a1739976-75a9-40da-970f-cc6426156b60\n",
      "\n",
      "Conversational RAG:\n",
      "============================================================\n",
      "\n",
      "üë§ User: What is the cancellation policy?\n",
      "\n",
      "ü§ñ Assistant: Based on the provided policy context, specifically section 2.1 Cancellation Timeline and 2.2 How to Cancel, the cancellation policy is as follows:\n",
      "\n",
      "* For appointments with 24+ hours notice, patients can cancel without penalty and reschedule at their convenience.\n",
      "* For appointments with 12-24 hours n...\n",
      "\n",
      "   [Rewritten: What is the cancellation policy?]\n",
      "----------------------------------------\n",
      "\n",
      "üë§ User: What if I need to cancel same-day?\n",
      "\n",
      "ü§ñ Assistant: Based on the provided policy context, specifically section 5.2 Rescheduling Late Arrivals from [4] appointment_policy.md, if a patient needs to cancel same-day, they can:\n",
      "\n",
      "* Reception will assess provider availability\n",
      "* Patient may be offered a later slot same day\n",
      "* If no slots available, next avail...\n",
      "\n",
      "   [Rewritten: What are the consequences of cancelling an appointment with less than 12 hours' notice, and what options do I have for cancelling a same-day appointment?]\n",
      "----------------------------------------\n",
      "\n",
      "üë§ User: Are there any exceptions to these rules?\n",
      "\n",
      "ü§ñ Assistant: Based on the provided policy context and our conversation history, I'd like to clarify that there are exceptions to the cancellation policy. According to section 3.3 Exceptions, certain situations may qualify for no-show forgiveness, such as:\n",
      "\n",
      "* Medical emergency (documentation required)\n",
      "* Hospitali...\n",
      "\n",
      "   [Rewritten: Are there any exceptions to the standard cancellation policies outlined in section 2.1 Cancellation Timeline and 5.2 Rescheduling Late Arrivals, including same-day cancellations?]\n",
      "----------------------------------------\n",
      "\n",
      "üë§ User: How do I appeal a no-show fee?\n",
      "\n",
      "ü§ñ Assistant: I understand that you're asking about appealing a no-show fee. Based on the provided policy context, specifically section 3.2 Consequences of [1] appointment_policy.md, it appears that there is no specific process outlined for appealing a no-show fee.\n",
      "\n",
      "However, I'd like to clarify that the policy do...\n",
      "\n",
      "   [Rewritten: How do I appeal a no-show fee? (Assuming the context is that the user has already been charged with a no-show fee and wants to understand the process for appealing it)]\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Conversation History:\n",
      "üë§: What is the cancellation policy?...\n",
      "ü§ñ: Based on the provided policy context, specifically section 2.1 Cancellation Timeline and 2.2 How to ...\n",
      "üë§: What if I need to cancel same-day?...\n",
      "ü§ñ: Based on the provided policy context, specifically section 5.2 Rescheduling Late Arrivals from [4] a...\n",
      "üë§: Are there any exceptions to these rules?...\n",
      "ü§ñ: Based on the provided policy context and our conversation history, I'd like to clarify that there ar...\n",
      "üë§: How do I appeal a no-show fee?...\n",
      "ü§ñ: I understand that you're asking about appealing a no-show fee. Based on the provided policy context,...\n",
      "Citation RAG Response:\n",
      "============================================================\n",
      "\n",
      "Answer:\n",
      "According to the provided policy documents, specifically [1] Source: appointment_policy.md, Section: 3. No-Show Policy, a \"no-show\" occurs when a patient:\n",
      "\n",
      "* Fails to arrive for their scheduled appointment\n",
      "* Arrives more than 15 minutes late without prior notice\n",
      "* Does not cancel or reschedule before the appointment time\n",
      "\n",
      "As stated in [1] Source: appointment_policy.md, Section: 3. No-Show Policy, the consequences of multiple no-shows are:\n",
      "\n",
      "* First late cancellation: Warning only\n",
      "* Second late cancellation: $25 fee may apply\n",
      "* Third late cancellation within 12 months: $50 fee and counseling\n",
      "\n",
      "Please note that these consequences are based on the provided policy documents and may not reflect any additional or modified policies outside of this context.\n",
      "\n",
      "Citations:\n",
      "  [1] intervention_guidelines.md - \n",
      "  [2] appointment_policy.md - \n",
      "  [3] reminder_procedures.md - \n",
      "  [4] appointment_policy.md - \n",
      "  [5] appointment_policy.md - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ragas not installed. Install with: pip install ragas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: transportation help for appointments\n",
      "\n",
      "Expanded search found 4 documents\n",
      "\n",
      "Context preview:\n",
      "[Document 1] (Source: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\data\\documents\\intervention_guidelines.md)\n",
      "\n",
      "data/documents/intervention_guidelines.md\n",
      "\n",
      "No-Show Intervention Guidelines\n",
      "\n",
      "Purpose: Reduce patient no-shows through targeted interventions Audience: Patient Access Staff, Care Coordinators Last Updated: January 2024\n",
      "\n",
      "1. Risk-Based Intervention Framework\n",
      "\n",
      "1.1 Risk Tier Definitions\n",
      "\n",
      "Risk Tier Probability Description MINIMAL 0-20% Very likely to attend LOW 20-40% Probably will atten...\n",
      "Golden set has 7 questions\n",
      "\n",
      "Running evaluation on 5 questions...\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Evaluator: basic\n",
      "Samples: 5\n",
      "Passed: 0\n",
      "Pass Rate: 0.0%\n",
      "\n",
      "Metric Summary:\n",
      "  answer_length: mean=0.622, range=[0.260, 0.960]\n",
      "  context_used: mean=0.172, range=[0.082, 0.212]\n",
      "  keyword_overlap: mean=0.452, range=[0.200, 0.833]\n",
      "Evaluation saved to: c:\\Users\\samue\\Desktop\\NSP\\healthcare-appointments\\evals\\rag_eval_results\\eval_20251204_054023.json\n",
      "Week 11 Complete! üéâ\n",
      "RAG Pipeline Stats:\n",
      "----------------------------------------\n",
      "Documents loaded: 3\n",
      "Chunks created: 8\n",
      "Vector store: {'initialized': True, 'store_type': 'faiss', 'metadata': {'created_at': '2025-12-04T05:39:00.379475', 'document_count': 3, 'chunk_count': 8, 'store_type': 'faiss', 'embeddings_model': 'text-embedding-3-small'}, 'embeddings': {'total_embeddings': 3, 'cache_hits': 0, 'api_calls': 1, 'total_tokens_estimated': 26, 'estimated_cost_usd': 0.0, 'errors': 0, 'cache_size': 3, 'cache_hit_rate': 0.0, 'uptime_seconds': 82.723304, 'model_info': {'provider': 'simple', 'model': 'text-embedding-3-small', 'dimension': 'unknown', 'max_tokens': 'unknown', 'cost_per_1k_tokens': 0, 'description': ''}, 'providers_available': {'openai': True, 'azure': True, 'local': True}}}\n",
      "Embeddings: {'total_embeddings': 3, 'cache_hits': 0, 'api_calls': 1, 'total_tokens_estimated': 26, 'estimated_cost_usd': 0.0, 'errors': 0, 'cache_size': 3, 'cache_hit_rate': 0.0, 'uptime_seconds': 82.723366, 'model_info': {'provider': 'simple', 'model': 'text-embedding-3-small', 'dimension': 'unknown', 'max_tokens': 'unknown', 'cost_per_1k_tokens': 0, 'description': ''}, 'providers_available': {'openai': True, 'azure': True, 'local': True}}\n"
     ]
    }
   ],
   "source": [
    "# notebooks/week11_rag.ipynb\n",
    "\n",
    "\"\"\"\n",
    "# Week 11: RAG & Vector Databases\n",
    "## Healthcare Policy Q&A System\n",
    "\n",
    "### Learning Objectives\n",
    "1. Load and process documents for RAG\n",
    "2. Implement text chunking strategies\n",
    "3. Create and query vector stores\n",
    "4. Build complete RAG pipelines\n",
    "5. Evaluate RAG quality\n",
    "\n",
    "### Setup\n",
    "\"\"\"\n",
    "\n",
    "# Cell 1: Setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"OpenAI API Key:\", \"‚úÖ\" if os.getenv(\"OPENAI_API_KEY\") else \"‚ùå\")\n",
    "\n",
    "\n",
    "# Cell 2: Create Sample Documents\n",
    "\"\"\"\n",
    "## Part 1: Document Preparation\n",
    "\n",
    "First, let's ensure we have policy documents to work with.\n",
    "\"\"\"\n",
    "\n",
    "# Create documents directory\n",
    "docs_dir = project_root / \"data\" / \"documents\"\n",
    "docs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check for existing documents\n",
    "existing_docs = list(docs_dir.glob(\"*.md\"))\n",
    "print(f\"Found {len(existing_docs)} markdown documents\")\n",
    "\n",
    "for doc in existing_docs:\n",
    "    print(f\"  - {doc.name}\")\n",
    "\n",
    "\n",
    "# Cell 3: Load Documents\n",
    "\"\"\"\n",
    "## Part 2: Document Loading\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.rag import DocumentLoader, load_policy_documents\n",
    "\n",
    "# Create loader\n",
    "loader = DocumentLoader(base_path=str(docs_dir))\n",
    "\n",
    "# Load all documents\n",
    "documents = loader.load_directory()\n",
    "\n",
    "print(f\"\\nLoaded {len(documents)} documents\")\n",
    "print(f\"Loading stats: {loader.get_stats()}\")\n",
    "\n",
    "# Preview first document\n",
    "if documents:\n",
    "    print(\"\\n--- First Document Preview ---\")\n",
    "    print(f\"Source: {documents[0].metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"Content: {documents[0].page_content[:500]}...\")\n",
    "\n",
    "\n",
    "# Cell 4: Text Chunking\n",
    "\"\"\"\n",
    "## Part 3: Text Chunking\n",
    "\n",
    "Split documents into manageable chunks for embedding.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.rag import TextChunker, ChunkingStrategy, analyze_chunks\n",
    "\n",
    "# Create chunker\n",
    "chunker = TextChunker(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    strategy=ChunkingStrategy.RECURSIVE\n",
    ")\n",
    "\n",
    "# Chunk documents\n",
    "chunks = chunker.chunk_documents(documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(f\"\\nChunk Analysis:\")\n",
    "analysis = analyze_chunks(chunks)\n",
    "for key, value in analysis.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Preview chunks\n",
    "print(\"\\n--- Sample Chunks ---\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"  Size: {len(chunk.page_content)} chars\")\n",
    "    print(f\"  Source: {chunk.metadata.get('filename', 'Unknown')}\")\n",
    "    print(f\"  Section: {chunk.metadata.get('section', 'N/A')}\")\n",
    "    print(f\"  Content: {chunk.page_content[:150]}...\")\n",
    "\n",
    "\n",
    "# Cell 5: Embeddings\n",
    "\"\"\"\n",
    "## Part 4: Embeddings\n",
    "\n",
    "Convert text chunks to vector embeddings.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.rag import EmbeddingsManager\n",
    "\n",
    "# Create embeddings manager\n",
    "embeddings_manager = EmbeddingsManager(\n",
    "    provider=\"openai\",\n",
    "    model_name=\"text-embedding-3-small\",\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "print(f\"Embeddings Model: {embeddings_manager.get_model_info()}\")\n",
    "\n",
    "# Test embedding\n",
    "sample_texts = [\n",
    "    \"What is the cancellation policy?\",\n",
    "    \"How do I reschedule an appointment?\",\n",
    "    \"What happens if I miss my appointment?\"\n",
    "]\n",
    "\n",
    "embeddings = embeddings_manager.embed_texts(sample_texts)\n",
    "\n",
    "print(f\"\\nGenerated {len(embeddings)} embeddings\")\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "\n",
    "# Check similarity\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "print(\"\\nSimilarity between questions:\")\n",
    "for i in range(len(sample_texts)):\n",
    "    for j in range(i+1, len(sample_texts)):\n",
    "        sim = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        print(f\"  '{sample_texts[i][:30]}...' vs '{sample_texts[j][:30]}...': {sim:.3f}\")\n",
    "\n",
    "\n",
    "# Cell 6: Vector Store\n",
    "\"\"\"\n",
    "## Part 5: Vector Store\n",
    "\n",
    "Create and query a FAISS vector store.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.rag import VectorStoreManager\n",
    "\n",
    "# Create vector store\n",
    "vector_store = VectorStoreManager(\n",
    "    store_type=\"faiss\",\n",
    "    embeddings_manager=embeddings_manager\n",
    ")\n",
    "\n",
    "# Index documents\n",
    "vector_store.create_from_documents(\n",
    "    documents,\n",
    "    chunk=True,\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "print(f\"Vector store created: {vector_store.get_stats()}\")\n",
    "\n",
    "# Save for later use\n",
    "vector_store.save(\"healthcare_policies\")\n",
    "print(\"Vector store saved!\")\n",
    "\n",
    "\n",
    "# Cell 7: Basic Search\n",
    "\"\"\"\n",
    "### Basic Similarity Search\n",
    "\"\"\"\n",
    "\n",
    "# Search\n",
    "query = \"What happens if a patient misses their appointment?\"\n",
    "results = vector_store.search(query, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Top 3 Results:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n{i+1}. {doc.metadata.get('filename', 'Unknown')}\")\n",
    "    print(f\"   Section: {doc.metadata.get('section', 'N/A')}\")\n",
    "    print(f\"   Content: {doc.page_content[:200]}...\")\n",
    "\n",
    "\n",
    "# Cell 8: Search with Scores\n",
    "\"\"\"\n",
    "### Search with Similarity Scores\n",
    "\"\"\"\n",
    "\n",
    "results_with_scores = vector_store.search_with_scores(query, k=5)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Results with scores:\")\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"  Score: {score:.4f} - {doc.metadata.get('filename', 'Unknown')}\")\n",
    "\n",
    "\n",
    "# Cell 9: MMR Search\n",
    "\"\"\"\n",
    "### Maximum Marginal Relevance (MMR) Search\n",
    "\n",
    "MMR provides diverse results, not just the most similar.\n",
    "\"\"\"\n",
    "\n",
    "mmr_results = vector_store.mmr_search(\n",
    "    query,\n",
    "    k=4,\n",
    "    fetch_k=10,\n",
    "    lambda_mult=0.5  # 0 = max diversity, 1 = max relevance\n",
    ")\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"MMR Results (diverse):\")\n",
    "for i, doc in enumerate(mmr_results):\n",
    "    print(f\"\\n{i+1}. {doc.metadata.get('section', 'Unknown section')}\")\n",
    "    print(f\"   {doc.page_content[:150]}...\")\n",
    "\n",
    "\n",
    "# Cell 10: RAG Chain\n",
    "\"\"\"\n",
    "## Part 6: RAG Chains\n",
    "\n",
    "Build complete question-answering pipelines.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.rag.chains import RAGChain, ConversationalRAGChain\n",
    "\n",
    "# Create RAG chain\n",
    "rag = RAGChain(\n",
    "    vector_store=vector_store,\n",
    "    temperature=0.2,\n",
    "    retriever_k=4\n",
    ")\n",
    "\n",
    "# Test questions\n",
    "test_questions = [\n",
    "    \"What is the no-show policy?\",\n",
    "    \"How many reminders do patients receive before their appointment?\",\n",
    "    \"What should staff do for high-risk patients?\",\n",
    "    \"Can no-show fees be waived?\"\n",
    "]\n",
    "\n",
    "print(\"RAG Chain Responses:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for question in test_questions:\n",
    "    result = rag.ask(question, return_sources=True)\n",
    "    \n",
    "    print(f\"\\nüìù Q: {question}\")\n",
    "    print(f\"\\nüí¨ A: {result['answer'][:400]}...\")\n",
    "    print(f\"\\nüìö Sources: {len(result.get('sources', []))} documents\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# Cell 11: Conversational RAG\n",
    "\"\"\"\n",
    "### Conversational RAG\n",
    "\n",
    "Maintains context across multiple questions.\n",
    "\"\"\"\n",
    "\n",
    "conv_rag = ConversationalRAGChain(\n",
    "    vector_store=vector_store,\n",
    "    max_history=5\n",
    ")\n",
    "\n",
    "# Create session\n",
    "session_id = conv_rag.create_session()\n",
    "print(f\"Session created: {session_id}\\n\")\n",
    "\n",
    "# Multi-turn conversation\n",
    "conversation = [\n",
    "    \"What is the cancellation policy?\",\n",
    "    \"What if I need to cancel same-day?\",\n",
    "    \"Are there any exceptions to these rules?\",\n",
    "    \"How do I appeal a no-show fee?\"\n",
    "]\n",
    "\n",
    "print(\"Conversational RAG:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for question in conversation:\n",
    "    result = conv_rag.ask(session_id, question)\n",
    "    \n",
    "    print(f\"\\nüë§ User: {question}\")\n",
    "    print(f\"\\nü§ñ Assistant: {result['answer'][:300]}...\")\n",
    "    \n",
    "    if result.get('standalone_question'):\n",
    "        print(f\"\\n   [Rewritten: {result['standalone_question']}]\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# View history\n",
    "print(\"\\n\\nConversation History:\")\n",
    "history = conv_rag.get_history(session_id)\n",
    "for msg in history:\n",
    "    role = \"üë§\" if msg[\"role\"] == \"user\" else \"ü§ñ\"\n",
    "    print(f\"{role}: {msg['content'][:100]}...\")\n",
    "\n",
    "\n",
    "# Cell 12: Citation RAG\n",
    "\"\"\"\n",
    "### RAG with Citations\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.rag.chains import CitationRAGChain\n",
    "\n",
    "citation_rag = CitationRAGChain(vector_store=vector_store)\n",
    "\n",
    "result = citation_rag.ask(\"What are the consequences of multiple no-shows?\")\n",
    "\n",
    "print(\"Citation RAG Response:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nAnswer:\\n{result['answer']}\")\n",
    "print(f\"\\nCitations:\")\n",
    "for cite in result['citations']:\n",
    "    print(f\"  [{cite['number']}] {cite['filename']} - {cite['section']}\")\n",
    "\n",
    "\n",
    "# Cell 13: Advanced Retriever\n",
    "\"\"\"\n",
    "## Part 7: Advanced Retrieval\n",
    "\n",
    "Using query expansion and reranking.\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.rag.retriever import PolicyRetriever, RetrievalConfig\n",
    "\n",
    "# Configure advanced retrieval\n",
    "config = RetrievalConfig(\n",
    "    top_k=4,\n",
    "    search_type=\"mmr\",\n",
    "    use_query_expansion=True,\n",
    "    expansion_count=2\n",
    ")\n",
    "\n",
    "advanced_retriever = PolicyRetriever(\n",
    "    vector_store=vector_store,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Test\n",
    "query = \"transportation help for appointments\"\n",
    "results = advanced_retriever.search_with_context(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nExpanded search found {len(results['documents'])} documents\")\n",
    "print(f\"\\nContext preview:\\n{results['context'][:500]}...\")\n",
    "\n",
    "\n",
    "# Cell 14: RAG Evaluation\n",
    "\"\"\"\n",
    "## Part 8: RAG Evaluation\n",
    "\"\"\"\n",
    "\n",
    "from src.llm.rag.evaluation import RAGEvaluator, create_healthcare_golden_set\n",
    "\n",
    "# Create evaluator\n",
    "evaluator = RAGEvaluator(\n",
    "    thresholds={\n",
    "        \"faithfulness\": 0.7,\n",
    "        \"answer_relevancy\": 0.7,\n",
    "        \"context_used\": 0.5\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create golden set\n",
    "golden = create_healthcare_golden_set()\n",
    "print(f\"Golden set has {len(golden.questions)} questions\")\n",
    "\n",
    "# Add samples by running through RAG\n",
    "questions, ground_truths = golden.to_eval_format()\n",
    "\n",
    "# Limit for demo\n",
    "demo_questions = questions[:5]\n",
    "demo_truths = ground_truths[:5]\n",
    "\n",
    "print(\"\\nRunning evaluation on 5 questions...\")\n",
    "evaluator.add_samples_from_chain(rag, demo_questions, demo_truths)\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluator.evaluate()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nEvaluator: {results['evaluator']}\")\n",
    "print(f\"Samples: {results['sample_count']}\")\n",
    "print(f\"Passed: {results['passed_count']}\")\n",
    "print(f\"Pass Rate: {results['pass_rate']:.1%}\")\n",
    "\n",
    "print(\"\\nMetric Summary:\")\n",
    "for metric, values in results.get('summary', {}).items():\n",
    "    print(f\"  {metric}: mean={values['mean']:.3f}, range=[{values['min']:.3f}, {values['max']:.3f}]\")\n",
    "\n",
    "\n",
    "# Cell 15: Save Evaluation Results\n",
    "\"\"\"\n",
    "### Save Evaluation Results\n",
    "\"\"\"\n",
    "\n",
    "eval_dir = project_root / \"evals\" / \"rag_eval_results\"\n",
    "eval_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from datetime import datetime\n",
    "eval_file = eval_dir / f\"eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "\n",
    "evaluator.save_results(str(eval_file))\n",
    "print(f\"Evaluation saved to: {eval_file}\")\n",
    "\n",
    "\n",
    "# Cell 16: Testing with API\n",
    "\"\"\"\n",
    "## Part 9: API Testing\n",
    "\n",
    "Test the RAG endpoints (requires API to be running).\n",
    "\"\"\"\n",
    "\n",
    "import httpx\n",
    "\n",
    "API_BASE = \"http://localhost:8000/api/v1\"\n",
    "\n",
    "async def test_rag_api():\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        # Create index\n",
    "        print(\"Creating index...\")\n",
    "        response = await client.post(\n",
    "            f\"{API_BASE}/rag/index/create\",\n",
    "            params={\"documents_path\": \"data/documents\"}\n",
    "        )\n",
    "        print(f\"Index creation: {response.json()}\")\n",
    "        \n",
    "        # Ask question\n",
    "        print(\"\\nAsking question...\")\n",
    "        response = await client.post(\n",
    "            f\"{API_BASE}/rag/ask\",\n",
    "            json={\n",
    "                \"question\": \"What is the no-show policy?\",\n",
    "                \"include_sources\": True\n",
    "            }\n",
    "        )\n",
    "        print(f\"Answer: {response.json()['answer'][:200]}...\")\n",
    "        \n",
    "        # Search\n",
    "        print(\"\\nSearching...\")\n",
    "        response = await client.get(\n",
    "            f\"{API_BASE}/rag/search\",\n",
    "            params={\"query\": \"cancellation\", \"k\": 3}\n",
    "        )\n",
    "        print(f\"Found {response.json()['count']} results\")\n",
    "\n",
    "# Uncomment to run:\n",
    "# import asyncio\n",
    "# asyncio.run(test_rag_api())\n",
    "\n",
    "\n",
    "# Cell 17: Exercises\n",
    "\"\"\"\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Chunking Comparison\n",
    "Compare different chunking strategies and their impact on retrieval.\n",
    "\"\"\"\n",
    "\n",
    "# Your code here:\n",
    "# chunking_strategies = [\n",
    "#     {\"strategy\": \"fixed\", \"size\": 500},\n",
    "#     {\"strategy\": \"recursive\", \"size\": 1000},\n",
    "#     {\"strategy\": \"markdown\", \"size\": 1000}\n",
    "# ]\n",
    "# \n",
    "# for config in chunking_strategies:\n",
    "#     # Create chunker with config\n",
    "#     # Count chunks\n",
    "#     # Evaluate retrieval quality\n",
    "#     pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "### Exercise 2: Custom Evaluation Set\n",
    "Create your own evaluation questions specific to your use case.\n",
    "\"\"\"\n",
    "\n",
    "# Your code here:\n",
    "# custom_golden = GoldenDataset(\"evals/custom_golden.json\")\n",
    "# \n",
    "# custom_golden.add_question(\n",
    "#     question=\"...\",\n",
    "#     expected_answer=\"...\",\n",
    "#     category=\"...\"\n",
    "# )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "### Exercise 3: Hybrid Retrieval\n",
    "Implement a hybrid retriever that combines keyword and semantic search.\n",
    "\"\"\"\n",
    "\n",
    "# Your code here:\n",
    "# class HybridRetriever:\n",
    "#     def __init__(self, vector_store, keyword_weight=0.3):\n",
    "#         pass\n",
    "#     \n",
    "#     def search(self, query, k=4):\n",
    "#         # Combine keyword and semantic results\n",
    "#         pass\n",
    "\n",
    "\n",
    "# Cell 18: Summary\n",
    "\"\"\"\n",
    "## Summary\n",
    "\n",
    "This week you learned:\n",
    "\n",
    "1. **Document Loading**\n",
    "   - Load markdown, text, and other documents\n",
    "   - Extract metadata for better retrieval\n",
    "\n",
    "2. **Text Chunking**\n",
    "   - Recursive splitting respects document structure\n",
    "   - Overlap prevents information loss at boundaries\n",
    "   - Chunk size affects retrieval precision\n",
    "\n",
    "3. **Embeddings**\n",
    "   - Convert text to vectors for similarity search\n",
    "   - OpenAI and local embedding options\n",
    "   - Caching for efficiency\n",
    "\n",
    "4. **Vector Stores**\n",
    "   - FAISS for fast local similarity search\n",
    "   - Persistence for reloading indices\n",
    "   - MMR for diverse results\n",
    "\n",
    "5. **RAG Chains**\n",
    "   - Basic Q&A with retrieval\n",
    "   - Conversational RAG with history\n",
    "   - Citation-aware responses\n",
    "\n",
    "6. **Evaluation**\n",
    "   - Ragas metrics for quality assessment\n",
    "   - Golden datasets for regression testing\n",
    "   - Custom evaluation thresholds\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "1. ‚úÖ Working document loader\n",
    "2. ‚úÖ Chunking pipeline\n",
    "3. ‚úÖ Vector store with FAISS\n",
    "4. ‚úÖ RAG chain for Q&A\n",
    "5. ‚úÖ Conversational RAG\n",
    "6. ‚úÖ Evaluation framework\n",
    "7. üìù Complete exercises\n",
    "8. üìù Custom golden set\n",
    "\"\"\"\n",
    "\n",
    "print(\"Week 11 Complete! üéâ\")\n",
    "\n",
    "\n",
    "# Cell 19: Stats\n",
    "\"\"\"\n",
    "### Final Statistics\n",
    "\"\"\"\n",
    "\n",
    "print(\"RAG Pipeline Stats:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Documents loaded: {len(documents)}\")\n",
    "print(f\"Chunks created: {len(chunks)}\")\n",
    "print(f\"Vector store: {vector_store.get_stats()}\")\n",
    "print(f\"Embeddings: {embeddings_manager.get_stats()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
