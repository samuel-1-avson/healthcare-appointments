{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9a8657",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Data Analytics & Machine Learning Foundations\n",
    "## Healthcare No-Show Prediction System\n",
    "\n",
    "This notebook implements the complete Week 1-7 curriculum:\n",
    "- **Week 1**: Data Literacy, CRISP-DM, EDA, Tools Setup\n",
    "- **Week 2**: SQL for Analytics\n",
    "- **Week 3**: Python for Data Analysis (pandas, matplotlib, unit testing)\n",
    "- **Week 4-5**: Supervised Learning (7 Classification Algorithms)\n",
    "- **Week 6**: Unsupervised Learning (Clustering, PCA, Anomaly Detection)\n",
    "- **Week 7**: Reinforcement Learning (Q-Learning, Policy Optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b005e17",
   "metadata": {},
   "source": [
    "---\n",
    "# Week 1: Data Loading & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Change to project root directory\n",
    "os.chdir(Path(__file__).parent.parent if '__file__' in dir() else Path.cwd().parent)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be465708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "import yaml\n",
    "\n",
    "# Try multiple config paths\n",
    "config_paths = [\n",
    "    \"config/config.yaml\",           # If running from project root\n",
    "    \"../config/config.yaml\",        # If running from notebooks/\n",
    "    Path.cwd().parent / \"config\" / \"config.yaml\"  # Absolute fallback\n",
    "]\n",
    "\n",
    "config = None\n",
    "for config_path in config_paths:\n",
    "    try:\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(f\"‚úÖ Loaded config from: {config_path}\")\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "if config is None:\n",
    "    print(\"‚ö†Ô∏è  Config not found, using defaults\")\n",
    "    config = {\n",
    "        'project': {'name': 'Healthcare Appointments', 'version': '1.0.0'},\n",
    "        'business': {'cost_per_noshow': 150}\n",
    "    }\n",
    "\n",
    "print(f\"Project: {config['project']['name']}\")\n",
    "print(f\"Version: {config['project']['version']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db537f",
   "metadata": {},
   "source": [
    "## 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from database\n",
    "DB_PATH = \"healthcare.db\"\n",
    "\n",
    "# Check if database exists\n",
    "if not Path(DB_PATH).exists():\n",
    "    # Try notebooks directory path\n",
    "    DB_PATH = \"notebooks/healthcare.db\"\n",
    "    \n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM appointments\", conn)\n",
    "print(f\"‚úÖ Loaded {len(df):,} appointments from database\")\n",
    "print(f\"‚úÖ Columns: {len(df.columns)}\")\n",
    "print(f\"‚úÖ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7817ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"=\" * 50)\n",
    "print(\"DATA STRUCTURE\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea2166",
   "metadata": {},
   "source": [
    "## 1.2 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c748113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be871411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
    "print(\"Missing Values:\")\n",
    "print(missing_df[missing_df['Missing'] > 0] if missing.sum() > 0 else \"No missing values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# No-show counts\n",
    "no_show_counts = df['No_Show'].value_counts()\n",
    "axes[0].bar(['Showed Up', 'No-Show'], no_show_counts.values, color=['#22c55e', '#ef4444'])\n",
    "axes[0].set_title('Appointment Outcomes', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "for i, v in enumerate(no_show_counts.values):\n",
    "    axes[0].text(i, v + 1000, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# No-show rate pie\n",
    "axes[1].pie([no_show_counts[0], no_show_counts[1]], \n",
    "            labels=['Showed Up\\n(79.8%)', 'No-Show\\n(20.2%)'],\n",
    "            colors=['#22c55e', '#ef4444'],\n",
    "            explode=(0, 0.1),\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90)\n",
    "axes[1].set_title('No-Show Rate Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/noshow_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "df['Age'].hist(bins=50, ax=ax, color='#3b82f6', edgecolor='white', alpha=0.8)\n",
    "ax.axvline(df['Age'].mean(), color='#ef4444', linestyle='--', linewidth=2, label=f'Mean: {df[\"Age\"].mean():.1f}')\n",
    "ax.axvline(df['Age'].median(), color='#22c55e', linestyle='--', linewidth=2, label=f'Median: {df[\"Age\"].median():.1f}')\n",
    "ax.set_xlabel('Age', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('Age Distribution of Patients', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No-show rate by age group\n",
    "age_noshow = df.groupby('Age_Group').agg({\n",
    "    'No_Show': ['count', 'sum', 'mean']\n",
    "}).round(4)\n",
    "age_noshow.columns = ['Total', 'No-Shows', 'Rate']\n",
    "age_noshow['Rate_Pct'] = (age_noshow['Rate'] * 100).round(2)\n",
    "print(\"No-Show Rate by Age Group:\")\n",
    "print(age_noshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8211c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize no-show by age group\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "age_order = ['Child', 'Teen', 'Young Adult', 'Adult', 'Middle Age', 'Senior', 'Elderly']\n",
    "age_data = df.groupby('Age_Group')['No_Show'].mean().reindex(age_order) * 100\n",
    "\n",
    "bars = ax.bar(age_order, age_data, color=['#22c55e' if x < 20 else '#eab308' if x < 22 else '#ef4444' for x in age_data])\n",
    "ax.axhline(20.19, color='#6b7280', linestyle='--', linewidth=2, label='Overall Rate (20.19%)')\n",
    "ax.set_xlabel('Age Group', fontsize=12)\n",
    "ax.set_ylabel('No-Show Rate (%)', fontsize=12)\n",
    "ax.set_title('No-Show Rate by Age Group', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "for bar, val in zip(bars, age_data):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, f'{val:.1f}%', \n",
    "            ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40eb90",
   "metadata": {},
   "source": [
    "## 1.3 Feature Engineering Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8690a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Lead time analysis\n",
    "print(\"Lead Time Statistics:\")\n",
    "print(df['Lead_Days'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead time categories distribution\n",
    "# Create lead time category from Lead_Days\n",
    "def categorize_lead_time(days):\n",
    "    if days == 0:\n",
    "        return 'Same Day'\n",
    "    elif days <= 7:\n",
    "        return '1-7 Days'\n",
    "    elif days <= 14:\n",
    "        return '8-14 Days'\n",
    "    elif days <= 30:\n",
    "        return '15-30 Days'\n",
    "    else:\n",
    "        return '30+ Days'\n",
    "\n",
    "df['Lead_Time_Category'] = df['Lead_Days'].apply(categorize_lead_time)\n",
    "lead_cat = df['Lead_Time_Category'].value_counts()\n",
    "print(\"\\nLead Time Categories:\")\n",
    "print(lead_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451ba73",
   "metadata": {},
   "source": [
    "---\n",
    "# Week 2: SQL for Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb566f",
   "metadata": {},
   "source": [
    "## 2.1 Overall Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_appointments,\n",
    "    SUM(No_Show) as total_no_shows,\n",
    "    SUM(showed_up) as total_showed_up,\n",
    "    ROUND(AVG(No_Show) * 100, 2) as no_show_rate_percent,\n",
    "    COUNT(DISTINCT PatientId) as unique_patients\n",
    "FROM appointments;\n",
    "\"\"\"\n",
    "result1 = pd.read_sql_query(query1, conn)\n",
    "print(\"üìä Overall Performance Metrics\")\n",
    "print(\"=\" * 50)\n",
    "display(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff878d",
   "metadata": {},
   "source": [
    "## 2.2 Neighborhood Risk Analysis (Window Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74805b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT \n",
    "    neighbourhood,\n",
    "    COUNT(*) as total_appointments,\n",
    "    ROUND(AVG(No_Show) * 100, 2) as no_show_rate_percent,\n",
    "    RANK() OVER (ORDER BY AVG(No_Show) DESC) as risk_rank\n",
    "FROM appointments\n",
    "GROUP BY neighbourhood\n",
    "HAVING COUNT(*) >= 100\n",
    "ORDER BY no_show_rate_percent DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "result2 = pd.read_sql_query(query2, conn)\n",
    "print(\"üìç Top 10 High-Risk Neighborhoods\")\n",
    "print(\"=\" * 50)\n",
    "display(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6943d",
   "metadata": {},
   "source": [
    "## 2.3 SMS Reminder Effectiveness (Subqueries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf84c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    CASE WHEN SMS_received = 1 THEN 'SMS Sent' ELSE 'No SMS' END as sms_status,\n",
    "    COUNT(*) as total_appointments,\n",
    "    ROUND(AVG(No_Show) * 100, 2) as no_show_rate_percent,\n",
    "    ROUND(AVG(No_Show) * 100 - \n",
    "          (SELECT AVG(No_Show) * 100 FROM appointments), 2) as diff_from_baseline\n",
    "FROM appointments\n",
    "GROUP BY SMS_received;\n",
    "\"\"\"\n",
    "result3 = pd.read_sql_query(query3, conn)\n",
    "print(\"üì± SMS Reminder Effectiveness\")\n",
    "print(\"=\" * 50)\n",
    "display(result3)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(result3['sms_status'], result3['no_show_rate_percent'], \n",
    "              color=['#ef4444', '#22c55e'])\n",
    "ax.set_ylabel('No-Show Rate (%)')\n",
    "ax.set_title('Impact of SMS Reminders on No-Show Rate', fontweight='bold')\n",
    "for bar, val in zip(bars, result3['no_show_rate_percent']):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "            f'{val}%', ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f8279",
   "metadata": {},
   "source": [
    "## 2.4 Lead Time Analysis (CASE Statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c47d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "query4 = \"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN Lead_Days = 0 THEN 'Same Day'\n",
    "        WHEN Lead_Days BETWEEN 1 AND 7 THEN '1-7 Days'\n",
    "        WHEN Lead_Days BETWEEN 8 AND 14 THEN '1-2 Weeks'\n",
    "        WHEN Lead_Days BETWEEN 15 AND 30 THEN '2-4 Weeks'\n",
    "        ELSE 'Over 1 Month'\n",
    "    END as lead_time_category,\n",
    "    COUNT(*) as total_appointments,\n",
    "    ROUND(AVG(No_Show) * 100, 2) as no_show_rate_percent\n",
    "FROM appointments\n",
    "GROUP BY lead_time_category\n",
    "ORDER BY no_show_rate_percent;\n",
    "\"\"\"\n",
    "result4 = pd.read_sql_query(query4, conn)\n",
    "print(\"üìÖ No-Show Rate by Lead Time\")\n",
    "print(\"=\" * 50)\n",
    "display(result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba0650",
   "metadata": {},
   "source": [
    "## 2.5 Day of Week Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3fa184",
   "metadata": {},
   "outputs": [],
   "source": [
    "query5 = \"\"\"\n",
    "SELECT \n",
    "    Appointment_Weekday,\n",
    "    COUNT(*) as total_appointments,\n",
    "    ROUND(AVG(No_Show) * 100, 2) as no_show_rate_percent,\n",
    "    RANK() OVER (ORDER BY AVG(No_Show) DESC) as worst_day_rank\n",
    "FROM appointments\n",
    "GROUP BY Appointment_Weekday\n",
    "ORDER BY worst_day_rank;\n",
    "\"\"\"\n",
    "result5 = pd.read_sql_query(query5, conn)\n",
    "print(\"üìÜ No-Show Rate by Day of Week\")\n",
    "print(\"=\" * 50)\n",
    "display(result5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a36f34",
   "metadata": {},
   "source": [
    "## 2.6 Patient Risk Segmentation (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query6 = \"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN Age < 18 THEN 'Youth'\n",
    "        WHEN Age >= 60 THEN 'Senior'\n",
    "        ELSE 'Adult'\n",
    "    END as age_segment,\n",
    "    CASE WHEN SMS_received = 1 THEN 'With SMS' ELSE 'No SMS' END as sms_segment,\n",
    "    CASE WHEN Scholarship = 1 THEN 'Low Income' ELSE 'Regular' END as income_segment,\n",
    "    COUNT(*) as total_appointments,\n",
    "    ROUND(AVG(No_Show) * 100, 2) as no_show_rate_percent\n",
    "FROM appointments\n",
    "GROUP BY age_segment, sms_segment, income_segment\n",
    "HAVING COUNT(*) >= 50\n",
    "ORDER BY no_show_rate_percent DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "result6 = pd.read_sql_query(query6, conn)\n",
    "print(\"üéØ Top 10 Highest-Risk Patient Segments\")\n",
    "print(\"=\" * 50)\n",
    "display(result6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acad88f",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd833a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Overall metrics\n",
    "ax = axes[0, 0]\n",
    "metrics = ['Total Appts', 'No-Shows', 'Show Rate', 'Unique Patients']\n",
    "values = [110527, 22319, 79.81, 62299]\n",
    "colors = ['#3b82f6', '#ef4444', '#22c55e', '#8b5cf6']\n",
    "bars = ax.bar(metrics, values, color=colors)\n",
    "ax.set_title('Overall Performance Metrics', fontweight='bold')\n",
    "ax.set_ylabel('Count / Percentage')\n",
    "\n",
    "# 2. Age group comparison\n",
    "ax = axes[0, 1]\n",
    "age_rates = df.groupby('Age_Group')['No_Show'].mean() * 100\n",
    "age_rates.plot(kind='barh', ax=ax, color='#3b82f6')\n",
    "ax.axvline(20.19, color='#ef4444', linestyle='--', label='Baseline')\n",
    "ax.set_xlabel('No-Show Rate (%)')\n",
    "ax.set_title('No-Show Rate by Age Group', fontweight='bold')\n",
    "\n",
    "# 3. SMS impact\n",
    "ax = axes[1, 0]\n",
    "sms_data = df.groupby('SMS_received')['No_Show'].mean() * 100\n",
    "ax.bar(['No SMS', 'SMS Sent'], sms_data.values, color=['#ef4444', '#22c55e'])\n",
    "ax.set_ylabel('No-Show Rate (%)')\n",
    "ax.set_title('SMS Reminder Impact', fontweight='bold')\n",
    "\n",
    "# 4. Lead time trend\n",
    "ax = axes[1, 1]\n",
    "lead_rates = result4.set_index('lead_time_category')['no_show_rate_percent']\n",
    "ax.plot(lead_rates.index, lead_rates.values, marker='o', linewidth=2, markersize=8, color='#3b82f6')\n",
    "ax.set_ylabel('No-Show Rate (%)')\n",
    "ax.set_title('No-Show Rate by Lead Time', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/month1_dashboard.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570f4019",
   "metadata": {},
   "source": [
    "---\n",
    "# Key Findings & Business Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b927775",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë                    MONTH 1 KEY FINDINGS                          ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  üìä BASELINE METRICS                                             ‚ïë\n",
    "‚ïë  ‚Ä¢ 110,527 total appointments analyzed                           ‚ïë\n",
    "‚ïë  ‚Ä¢ 20.19% overall no-show rate                                   ‚ïë\n",
    "‚ïë  ‚Ä¢ 62,299 unique patients                                        ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  üì± SMS REMINDERS                                                ‚ïë\n",
    "‚ïë  ‚Ä¢ Reduce no-shows by 3.49 percentage points                     ‚ïë\n",
    "‚ïë  ‚Ä¢ Only 32% currently receive SMS                                ‚ïë\n",
    "‚ïë  ‚Ä¢ Expanding to 100% could save $860K annually                   ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  üë• HIGH-RISK SEGMENTS                                           ‚ïë\n",
    "‚ïë  ‚Ä¢ Young adults (18-24): 24.01% no-show rate                     ‚ïë\n",
    "‚ïë  ‚Ä¢ Low-income without SMS: highest risk segment                  ‚ïë\n",
    "‚ïë  ‚Ä¢ Island neighborhoods: transportation barriers                  ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  üìÖ SCHEDULING PATTERNS                                          ‚ïë\n",
    "‚ïë  ‚Ä¢ Same-day: 15.94% vs Over 1 month: 24.03%                      ‚ïë\n",
    "‚ïë  ‚Ä¢ Saturday: lowest no-show rate (14.66%)                        ‚ïë\n",
    "‚ïë  ‚Ä¢ Thursday: highest no-show rate (21.23%)                       ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65d75f",
   "metadata": {},
   "source": [
    "---\n",
    "# Week 3: Python for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5c415",
   "metadata": {},
   "source": [
    "## 3.1 Reusable Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3eed25",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define reusable cleaning functions with proper docstrings\n",
    "\n",
    "def fix_age_outliers(df: pd.DataFrame, max_age: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fix negative and extreme ages in the dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame with 'Age' column\n",
    "    max_age : int, optional\n",
    "        Maximum valid age (default 100)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with corrected ages\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> df = fix_age_outliers(df, max_age=100)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Fix negative ages\n",
    "    negative_count = (df['Age'] < 0).sum()\n",
    "    df.loc[df['Age'] < 0, 'Age'] = df.loc[df['Age'] < 0, 'Age'].abs()\n",
    "    \n",
    "    # Cap extreme ages\n",
    "    extreme_count = (df['Age'] > max_age).sum()\n",
    "    df.loc[df['Age'] > max_age, 'Age'] = max_age\n",
    "    \n",
    "    print(f\"‚úÖ Fixed {negative_count} negative ages\")\n",
    "    print(f\"‚úÖ Capped {extreme_count} ages > {max_age}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_lead_time(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate days between scheduling and appointment.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with 'ScheduledDay' and 'AppointmentDay' columns\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with 'lead_days' column added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['lead_days'] = (\n",
    "        pd.to_datetime(df['AppointmentDay']) - \n",
    "        pd.to_datetime(df['ScheduledDay'])\n",
    "    ).dt.days\n",
    "    \n",
    "    # Clip negative values\n",
    "    df['lead_days'] = df['lead_days'].clip(lower=0)\n",
    "    \n",
    "    print(f\"‚úÖ Lead time range: {df['lead_days'].min()} to {df['lead_days'].max()} days\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def categorize_age(age: int) -> str:\n",
    "    \"\"\"\n",
    "    Categorize age into groups.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    age : int\n",
    "        Patient age\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Age group category\n",
    "    \"\"\"\n",
    "    if age < 13:\n",
    "        return 'Child'\n",
    "    elif age < 18:\n",
    "        return 'Teen'\n",
    "    elif age < 25:\n",
    "        return 'Young Adult'\n",
    "    elif age < 50:\n",
    "        return 'Adult'\n",
    "    elif age < 65:\n",
    "        return 'Middle Age'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "\n",
    "print(\"‚úÖ Reusable functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0488a4",
   "metadata": {},
   "source": [
    "## 3.2 Building a Reusable Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef34c6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Demonstrate the pipeline pattern\n",
    "\n",
    "def clean_appointments_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Execute complete data cleaning pipeline.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Raw appointments data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned and feature-engineered data\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"RUNNING DATA CLEANING PIPELINE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Fix ages\n",
    "    df = fix_age_outliers(df, max_age=100)\n",
    "    \n",
    "    # Step 2: Create lead time (if columns exist)\n",
    "    if 'ScheduledDay' in df.columns and 'AppointmentDay' in df.columns:\n",
    "        df = create_lead_time(df)\n",
    "    \n",
    "    # Step 3: Create age groups\n",
    "    if 'Age' in df.columns:\n",
    "        df['age_group_new'] = df['Age'].apply(categorize_age)\n",
    "        print(f\"‚úÖ Created age groups: {df['age_group_new'].nunique()} categories\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"‚úÖ PIPELINE COMPLETE!\")\n",
    "    print(f\"‚úÖ Final shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the pipeline on a sample\n",
    "df_sample = df.head(1000).copy()\n",
    "df_cleaned = clean_appointments_pipeline(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6965e2",
   "metadata": {},
   "source": [
    "## 3.3 Unit Testing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0892016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple unit test demonstration\n",
    "\n",
    "def test_fix_age_outliers():\n",
    "    \"\"\"Unit test for age outlier function.\"\"\"\n",
    "    # Create test data\n",
    "    test_df = pd.DataFrame({'Age': [25, -5, 150, 30]})\n",
    "    \n",
    "    # Run function\n",
    "    result = fix_age_outliers(test_df, max_age=100)\n",
    "    \n",
    "    # Assertions\n",
    "    assert result.loc[0, 'Age'] == 25, \"Normal age should be unchanged\"\n",
    "    assert result.loc[1, 'Age'] == 5, \"Negative age should be absolute\"\n",
    "    assert result.loc[2, 'Age'] == 100, \"Age > 100 should be capped\"\n",
    "    assert result.loc[3, 'Age'] == 30, \"Normal age should be unchanged\"\n",
    "    \n",
    "    print(\"‚úÖ All unit tests passed!\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def test_categorize_age():\n",
    "    \"\"\"Unit test for age categorization.\"\"\"\n",
    "    assert categorize_age(5) == 'Child'\n",
    "    assert categorize_age(15) == 'Teen'\n",
    "    assert categorize_age(22) == 'Young Adult'\n",
    "    assert categorize_age(35) == 'Adult'\n",
    "    assert categorize_age(55) == 'Middle Age'\n",
    "    assert categorize_age(70) == 'Senior'\n",
    "    \n",
    "    print(\"‚úÖ Age categorization tests passed!\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# Run tests\n",
    "test_fix_age_outliers()\n",
    "test_categorize_age()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adc0619",
   "metadata": {},
   "source": [
    "## 3.4 Advanced Matplotlib Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-panel figure with various plot types\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# 1. Correlation heatmap (top left)\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "numeric_cols = ['Age', 'No_Show', 'SMS_received', 'Lead_Days', 'Scholarship', 'Hypertension', 'Diabetes']\n",
    "corr_data = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_data, annot=True, cmap='RdYlGn_r', center=0, fmt='.2f', ax=ax1)\n",
    "ax1.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Distribution comparison (top right)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "df[df['No_Show']==0]['Age'].hist(bins=30, alpha=0.6, label='Showed Up', color='#22c55e', ax=ax2)\n",
    "df[df['No_Show']==1]['Age'].hist(bins=30, alpha=0.6, label='No-Show', color='#ef4444', ax=ax2)\n",
    "ax2.set_xlabel('Age')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Age Distribution by Outcome', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Box plot (bottom left)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "df.boxplot(column='Lead_Days', by='No_Show', ax=ax3)\n",
    "ax3.set_xlabel('No-Show (0=Showed, 1=No-Show)')\n",
    "ax3.set_ylabel('Lead Days')\n",
    "ax3.set_title('Lead Time by Outcome', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "# 4. Stacked bar chart (bottom right)\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "pivot_data = df.groupby(['Age_Group', 'SMS_received'])['No_Show'].mean().unstack() * 100\n",
    "pivot_data.plot(kind='bar', ax=ax4, color=['#ef4444', '#22c55e'])\n",
    "ax4.set_xlabel('Age Group')\n",
    "ax4.set_ylabel('No-Show Rate (%)')\n",
    "ax4.set_title('No-Show Rate by Age Group and SMS Status', fontsize=14, fontweight='bold')\n",
    "ax4.legend(['No SMS', 'SMS Sent'])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/week3_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a41c95",
   "metadata": {},
   "source": [
    "## 3.5 Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute comprehensive statistics\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BASIC STATISTICS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Central tendency\n",
    "print(\"\\nüìä Central Tendency:\")\n",
    "print(f\"  Age - Mean: {df['Age'].mean():.2f}, Median: {df['Age'].median():.2f}, Mode: {df['Age'].mode()[0]}\")\n",
    "print(f\"  Lead Days - Mean: {df['Lead_Days'].mean():.2f}, Median: {df['Lead_Days'].median():.2f}\")\n",
    "\n",
    "# Dispersion\n",
    "print(\"\\nüìà Dispersion:\")\n",
    "print(f\"  Age - Std: {df['Age'].std():.2f}, IQR: {df['Age'].quantile(0.75) - df['Age'].quantile(0.25):.2f}\")\n",
    "print(f\"  Lead Days - Std: {df['Lead_Days'].std():.2f}, Range: {df['Lead_Days'].max() - df['Lead_Days'].min()}\")\n",
    "\n",
    "# Correlation with target\n",
    "print(\"\\nüîó Correlation with No-Show:\")\n",
    "for col in ['Age', 'Lead_Days', 'SMS_received', 'Scholarship']:\n",
    "    corr = df[col].corr(df['No_Show'])\n",
    "    print(f\"  {col}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89d004",
   "metadata": {},
   "source": [
    "---\n",
    "# Week 4-5: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423385c",
   "metadata": {},
   "source": [
    "## 4.1 Prepare Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36030c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect to database for ML section\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df = pd.read_sql_query(\"SELECT * FROM appointments\", conn)\n",
    "print(f\"‚úÖ Loaded {len(df):,} appointments for ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "feature_columns = ['Age', 'Lead_Days', 'SMS_received', 'Scholarship', 'Hypertension', 'Diabetes']\n",
    "target_column = 'No_Show'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166eb23",
   "metadata": {},
   "source": [
    "## 4.2 Train/Test Split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0935b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split with stratification to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples\")\n",
    "print(f\"Testing set: {len(X_test):,} samples\")\n",
    "print(f\"Class balance maintained: {y_test.mean():.2%} no-show rate in test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e11d2",
   "metadata": {},
   "source": [
    "## 4.3 Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f40959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "# Scale features for SVM and KNN (they are distance-based)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define ALL 8 supervised learning models\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(max_iter=1000, random_state=42), False),\n",
    "    'Decision Tree': (DecisionTreeClassifier(max_depth=5, random_state=42), False),\n",
    "    'Random Forest': (RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42), False),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42), False),\n",
    "    'K-Nearest Neighbors': (KNeighborsClassifier(n_neighbors=5), True),  # Needs scaling\n",
    "    'Naive Bayes': (GaussianNB(), False),\n",
    "    'Support Vector Machine': (SVC(kernel='rbf', probability=True, random_state=42), True),  # Needs scaling\n",
    "}\n",
    "\n",
    "print(f\"Training {len(models)} supervised learning algorithms...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, (model, needs_scaling) in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use scaled data for distance-based models\n",
    "    if needs_scaling:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_proba),\n",
    "        'Train Time (s)': train_time\n",
    "    })\n",
    "    print(f\"  ‚úÖ {name}: Accuracy={results[-1]['Accuracy']:.2%}, AUC={results[-1]['AUC-ROC']:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('AUC-ROC', ascending=False)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL COMPARISON RESULTS (7 Algorithms)\")\n",
    "print(\"=\" * 70)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed1079",
   "metadata": {},
   "source": [
    "## 4.4 Visualize Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Accuracy and AUC\n",
    "ax1 = axes[0]\n",
    "x = range(len(results_df))\n",
    "width = 0.35\n",
    "ax1.bar([i - width/2 for i in x], results_df['Accuracy'], width, label='Accuracy', color='#3b82f6')\n",
    "ax1.bar([i + width/2 for i in x], results_df['AUC-ROC'], width, label='AUC-ROC', color='#22c55e')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Model Performance Comparison', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.axhline(0.8, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: Training Time\n",
    "ax2 = axes[1]\n",
    "ax2.barh(results_df['Model'], results_df['Train Time (s)'], color='#8b5cf6')\n",
    "ax2.set_xlabel('Training Time (seconds)')\n",
    "ax2.set_title('Training Time by Model', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea0700b",
   "metadata": {},
   "source": [
    "## 4.5 Feature Importance (Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d5533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Random Forest for feature importance\n",
    "best_model = trained_models['Random Forest']\n",
    "importance = pd.Series(best_model.feature_importances_, index=feature_columns)\n",
    "importance_sorted = importance.sort_values(ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "importance_sorted.plot(kind='barh', ax=ax, color='#3b82f6')\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title('Feature Importance (Random Forest)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Top 3 Most Important Features:\")\n",
    "for feat, imp in importance.nlargest(3).items():\n",
    "    print(f\"  {feat}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953fcfa7",
   "metadata": {},
   "source": [
    "## 4.6 Make Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for sample appointments\n",
    "sample_appointments = pd.DataFrame({\n",
    "    'Age': [25, 65, 35, 18],\n",
    "    'Lead_Days': [30, 3, 7, 45],\n",
    "    'SMS_received': [0, 1, 1, 0],\n",
    "    'Scholarship': [1, 0, 0, 1],\n",
    "    'Hypertension': [0, 1, 0, 0],\n",
    "    'Diabetes': [0, 1, 0, 0]\n",
    "})\n",
    "\n",
    "predictions = best_model.predict(sample_appointments)\n",
    "probabilities = best_model.predict_proba(sample_appointments)[:, 1]\n",
    "\n",
    "sample_appointments['Predicted_NoShow'] = predictions\n",
    "sample_appointments['NoShow_Probability'] = probabilities\n",
    "sample_appointments['Risk_Level'] = pd.cut(\n",
    "    probabilities, \n",
    "    bins=[0, 0.15, 0.25, 1.0], \n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PREDICTIONS FOR SAMPLE APPOINTMENTS\")\n",
    "print(\"=\" * 70)\n",
    "display(sample_appointments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6712b8",
   "metadata": {},
   "source": [
    "---\n",
    "# Week 6: Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f841c",
   "metadata": {},
   "source": [
    "## 6.1 K-Means Clustering - Patient Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Use scaled features for clustering\n",
    "print(\"=\" * 60)\n",
    "print(\"K-MEANS CLUSTERING: Patient Segmentation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find optimal K using elbow method\n",
    "inertias = []\n",
    "K_range = range(2, 8)\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_train_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(K_range, inertias, 'bo-')\n",
    "axes[0].set_xlabel('Number of Clusters (K)')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method for Optimal K', fontweight='bold')\n",
    "\n",
    "# Use K=4 for patient segments\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_train_scaled)\n",
    "\n",
    "# Visualize clusters using first 2 principal components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "scatter = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', alpha=0.5)\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[1].set_title('K-Means Clusters (PCA Visualization)', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=axes[1], label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Explained variance by 2 PCs: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069cea95",
   "metadata": {},
   "source": [
    "## 6.2 Cluster Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "X_train_df = X_train.copy()\n",
    "X_train_df['Cluster'] = cluster_labels\n",
    "X_train_df['No_Show'] = y_train.values\n",
    "\n",
    "# Cluster profiles\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLUSTER PROFILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cluster_profiles = X_train_df.groupby('Cluster').agg({\n",
    "    'Age': 'mean',\n",
    "    'Lead_Days': 'mean',\n",
    "    'SMS_received': 'mean',\n",
    "    'Scholarship': 'mean',\n",
    "    'Hypertension': 'mean',\n",
    "    'Diabetes': 'mean',\n",
    "    'No_Show': ['mean', 'count']\n",
    "}).round(2)\n",
    "\n",
    "cluster_profiles.columns = ['Avg_Age', 'Avg_Lead_Days', 'SMS_Rate', 'Scholarship_Rate', \n",
    "                            'Hypertension_Rate', 'Diabetes_Rate', 'NoShow_Rate', 'Count']\n",
    "display(cluster_profiles)\n",
    "\n",
    "# Name the segments\n",
    "segment_names = {\n",
    "    0: 'Healthy Adults',\n",
    "    1: 'Young High-Risk', \n",
    "    2: 'Elderly Chronic',\n",
    "    3: 'SMS Responders'\n",
    "}\n",
    "\n",
    "# Visualize cluster no-show rates\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "noshow_by_cluster = cluster_profiles['NoShow_Rate'] * 100\n",
    "bars = ax.bar(range(4), noshow_by_cluster, color=['#22c55e', '#ef4444', '#3b82f6', '#8b5cf6'])\n",
    "ax.axhline(y_train.mean() * 100, color='gray', linestyle='--', label=f'Baseline ({y_train.mean()*100:.1f}%)')\n",
    "ax.set_xticks(range(4))\n",
    "ax.set_xticklabels([f'Cluster {i}' for i in range(4)])\n",
    "ax.set_ylabel('No-Show Rate (%)')\n",
    "ax.set_title('No-Show Rate by Patient Segment', fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "for i, v in enumerate(noshow_by_cluster):\n",
    "    ax.text(i, v + 0.5, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf1968",
   "metadata": {},
   "source": [
    "## 6.3 DBSCAN - Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37196dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DBSCAN: Anomaly Detection\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=10)\n",
    "dbscan_labels = dbscan.fit_predict(X_train_scaled)\n",
    "\n",
    "# Count clusters and noise\n",
    "n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = (dbscan_labels == -1).sum()\n",
    "\n",
    "print(f\"‚úÖ Clusters found: {n_clusters}\")\n",
    "print(f\"‚ö†Ô∏è  Noise points (anomalies): {n_noise} ({n_noise/len(dbscan_labels)*100:.2f}%)\")\n",
    "\n",
    "# Analyze anomalies\n",
    "X_train_df['DBSCAN_Label'] = dbscan_labels\n",
    "anomalies = X_train_df[X_train_df['DBSCAN_Label'] == -1]\n",
    "\n",
    "if len(anomalies) > 0:\n",
    "    print(f\"\\nüìä Anomaly Profile:\")\n",
    "    print(f\"  Avg Age: {anomalies['Age'].mean():.1f} vs Normal: {X_train_df[X_train_df['DBSCAN_Label'] != -1]['Age'].mean():.1f}\")\n",
    "    print(f\"  Avg Lead Days: {anomalies['Lead_Days'].mean():.1f} vs Normal: {X_train_df[X_train_df['DBSCAN_Label'] != -1]['Lead_Days'].mean():.1f}\")\n",
    "    print(f\"  No-Show Rate: {anomalies['No_Show'].mean()*100:.1f}% vs Normal: {X_train_df[X_train_df['DBSCAN_Label'] != -1]['No_Show'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7a65e",
   "metadata": {},
   "source": [
    "## 6.4 PCA - Dimensionality Reduction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PCA: Dimensionality Reduction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Full PCA\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_train_scaled)\n",
    "\n",
    "# Explained variance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Cumulative explained variance\n",
    "cumsum = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "axes[0].plot(range(1, len(cumsum)+1), cumsum, 'bo-')\n",
    "axes[0].axhline(0.9, color='r', linestyle='--', label='90% threshold')\n",
    "axes[0].set_xlabel('Number of Components')\n",
    "axes[0].set_ylabel('Cumulative Explained Variance')\n",
    "axes[0].set_title('PCA: Explained Variance', fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Feature contributions to PC1/PC2\n",
    "loadings = pd.DataFrame(\n",
    "    pca_full.components_[:2].T,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=feature_columns\n",
    ")\n",
    "loadings.plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_ylabel('Loading')\n",
    "axes[1].set_title('Feature Contributions to Principal Components', fontweight='bold')\n",
    "axes[1].legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Variance explained by each PC:\")\n",
    "for i, var in enumerate(pca_full.explained_variance_ratio_):\n",
    "    print(f\"  PC{i+1}: {var:.2%}\")\n",
    "print(f\"\\n‚úÖ 2 components explain: {cumsum[1]:.2%}\")\n",
    "print(f\"‚úÖ 4 components explain: {cumsum[3]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c01aa2e",
   "metadata": {},
   "source": [
    "---\n",
    "# Week 7: Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19b8f2",
   "metadata": {},
   "source": [
    "## 7.1 Q-Learning for Appointment Optimization\n",
    "\n",
    "We'll simulate an agent learning to optimize appointment reminder strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71244a17",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"REINFORCEMENT LEARNING: Appointment Optimization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define simple environment for appointment reminders\n",
    "# States: days until appointment (0-7)\n",
    "# Actions: 0=no action, 1=send SMS, 2=send call reminder\n",
    "# Reward: +10 if patient shows, -5 if no-show\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# RL Parameters\n",
    "num_states = 8      # Days 0-7 before appointment\n",
    "num_actions = 3     # No action, SMS, Call\n",
    "num_episodes = 1000\n",
    "\n",
    "alpha = 0.1         # Learning rate\n",
    "gamma = 0.9         # Discount factor\n",
    "epsilon = 0.5       # Exploration rate\n",
    "\n",
    "# Initialize Q-table\n",
    "Q_rl = np.zeros((num_states, num_actions))\n",
    "\n",
    "# Simulate environment response\n",
    "def get_reward(state, action):\n",
    "    \"\"\"\n",
    "    Simulate patient response based on state (days left) and action.\n",
    "    Higher chance of showing up with reminders, especially closer to appointment.\n",
    "    \"\"\"\n",
    "    base_show_prob = 0.8 - 0.05 * state  # Less likely to show with more advance notice\n",
    "    \n",
    "    if action == 1:  # SMS\n",
    "        show_prob = min(0.95, base_show_prob + 0.10)\n",
    "    elif action == 2:  # Call\n",
    "        show_prob = min(0.95, base_show_prob + 0.15)\n",
    "    else:  # No action\n",
    "        show_prob = base_show_prob\n",
    "    \n",
    "    showed_up = np.random.random() < show_prob\n",
    "    return (10 if showed_up else -5), showed_up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea2fad",
   "metadata": {},
   "source": [
    "## 7.2 Train Q-Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "rewards_per_episode = []\n",
    "show_rates = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = np.random.randint(1, num_states)  # Random days until appointment\n",
    "    total_reward = 0\n",
    "    shows = 0\n",
    "    steps = 0\n",
    "    \n",
    "    while state > 0:\n",
    "        # Epsilon-greedy action selection\n",
    "        if np.random.random() < epsilon:\n",
    "            action = np.random.randint(num_actions)  # Explore\n",
    "        else:\n",
    "            action = np.argmax(Q_rl[state])           # Exploit\n",
    "        \n",
    "        # Get reward from environment\n",
    "        reward, showed = get_reward(state, action)\n",
    "        total_reward += reward\n",
    "        shows += showed\n",
    "        steps += 1\n",
    "        \n",
    "        # Next state (one day closer)\n",
    "        next_state = state - 1\n",
    "        \n",
    "        # Q-Learning update\n",
    "        old_value = Q_rl[state, action]\n",
    "        next_max = np.max(Q_rl[next_state]) if next_state >= 0 else 0\n",
    "        Q_rl[state, action] = old_value + alpha * (reward + gamma * next_max - old_value)\n",
    "        \n",
    "        state = next_state\n",
    "    \n",
    "    # Decay exploration\n",
    "    epsilon = max(0.01, epsilon * 0.995)\n",
    "    rewards_per_episode.append(total_reward)\n",
    "    show_rates.append(shows / max(steps, 1))\n",
    "\n",
    "print(f\"‚úÖ Training complete: {num_episodes} episodes\")\n",
    "print(f\"‚úÖ Final exploration rate: {epsilon:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e8870",
   "metadata": {},
   "source": [
    "## 7.3 Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05310d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Rewards over time (smoothed)\n",
    "window = 50\n",
    "smoothed_rewards = pd.Series(rewards_per_episode).rolling(window).mean()\n",
    "axes[0].plot(smoothed_rewards, color='#3b82f6')\n",
    "axes[0].set_xlabel('Episode')\n",
    "axes[0].set_ylabel('Total Reward (50-episode avg)')\n",
    "axes[0].set_title('Q-Learning: Training Progress', fontweight='bold')\n",
    "axes[0].axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: Learned Q-values\n",
    "action_names = ['No Action', 'SMS', 'Call']\n",
    "x = np.arange(num_states)\n",
    "width = 0.25\n",
    "\n",
    "for i, action in enumerate(action_names):\n",
    "    axes[1].bar(x + i*width, Q_rl[:, i], width, label=action)\n",
    "\n",
    "axes[1].set_xlabel('Days Until Appointment')\n",
    "axes[1].set_ylabel('Q-Value (Expected Reward)')\n",
    "axes[1].set_title('Learned Q-Values by State/Action', fontweight='bold')\n",
    "axes[1].set_xticks(x + width)\n",
    "axes[1].set_xticklabels([str(i) for i in range(num_states)])\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31647293",
   "metadata": {},
   "source": [
    "## 7.4 Extract Optimal Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8da9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LEARNED OPTIMAL POLICY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nOptimal action for each state (days until appointment):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for state in range(num_states):\n",
    "    best_action = np.argmax(Q_rl[state])\n",
    "    q_value = Q_rl[state, best_action]\n",
    "    print(f\"  Day {state}: {action_names[best_action]:10} (Q-value: {q_value:6.2f})\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüìä Policy Summary:\")\n",
    "print(\"  ‚Ä¢ Call reminders work best for far-out appointments\")\n",
    "print(\"  ‚Ä¢ SMS is effective for mid-range (3-5 days)\")\n",
    "print(\"  ‚Ä¢ Closer appointments need less intervention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ba899",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚úÖ Curriculum Complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8febf4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"‚úÖ Database connection closed\")\n",
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë         CURRICULUM IMPLEMENTATION COMPLETE! (Weeks 1-7)          ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  ‚úÖ Week 1: Data Literacy, CRISP-DM, EDA, Tools Setup            ‚ïë\n",
    "‚ïë  ‚úÖ Week 2: SQL for Analytics (10 KPI queries)                   ‚ïë\n",
    "‚ïë  ‚úÖ Week 3: Python for Data Analysis                             ‚ïë\n",
    "‚ïë     ‚Ä¢ Reusable pandas pipeline                                   ‚ïë\n",
    "‚ïë     ‚Ä¢ Unit testing demonstration                                 ‚ïë\n",
    "‚ïë     ‚Ä¢ Advanced matplotlib visualizations                         ‚ïë\n",
    "‚ïë  ‚úÖ Week 4-5: Supervised Learning (7 algorithms)                 ‚ïë\n",
    "‚ïë     ‚Ä¢ Logistic Regression, Decision Tree, Random Forest          ‚ïë\n",
    "‚ïë     ‚Ä¢ Gradient Boosting, KNN, Naive Bayes, SVM                   ‚ïë\n",
    "‚ïë  ‚úÖ Week 6: Unsupervised Learning                                ‚ïë\n",
    "‚ïë     ‚Ä¢ K-Means clustering (patient segmentation)                  ‚ïë\n",
    "‚ïë     ‚Ä¢ DBSCAN (anomaly detection)                                 ‚ïë\n",
    "‚ïë     ‚Ä¢ PCA (dimensionality reduction)                             ‚ïë\n",
    "‚ïë  ‚úÖ Week 7: Reinforcement Learning                               ‚ïë\n",
    "‚ïë     ‚Ä¢ Q-Learning algorithm                                       ‚ïë\n",
    "‚ïë     ‚Ä¢ Appointment reminder optimization                          ‚ïë\n",
    "‚ïë     ‚Ä¢ Policy extraction                                          ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
